
本章介紹的子集似然法是處理多個參數模型的主要方法。前章介紹的**條件似然法**也是相當出色的方法，但是許多情況下我們無法找到合適的“條件”來輔助我們擺脫那些模型中不需要的，**障礙 (或者叫噪音) 參數 nuisance parameters**。

我們還是沿用上一節的例子。

兩個獨立的人羣追蹤樣本，在 $p_0, p_1$ 人年的隨訪中發生事件 A 的次數分別是 $k_0, k_1$。我們只關心兩組的事件 A 發生率的比 $\text{Rate ratio:} \theta=\frac{\lambda_1}{\lambda_0}$。兩個人羣的聯合對數似然函數如下：

$$
\ell(\lambda_0, \lambda_1) = k_0\text{log}\lambda_0 - \lambda_0p0 + k_1\text{log}\lambda_1 - \lambda_1p1
$$

- Step 1. 先用 $\lambda_1 = \lambda_0\theta$ 取代掉上面式子中的 $\lambda_1$。

$$
\begin{aligned}
\Rightarrow \ell(\lambda_0, \theta) & = k\text{log}\lambda_0 + k_1\text{log}\theta - \lambda_0(P_0 + \theta p_1) \\
\text{Where } k & = k_0 + k_1
\end{aligned}
(\#eq:infer10-1)
$$

這一步先是消滅了一個障礙參數 $\lambda_1$，獲得了一個我們關心的參數 $\theta$，和 $\lambda_0$ 的對數似然方程。接下來，我們尋找用 $\theta$ 表示 $\lambda_0$ (用 $\hat\lambda_0(\theta)$ 標記) 的似然方程，使得只包含一個參數 $\theta$ 的對數似然方程可以在每個 $\lambda_0$ 時取得極大值。此時我們定義 $\theta$ 的子集對數似然方程 profile log-likelihood是：

$$
\ell_p(\theta) = \ell(\hat\lambda_0(\theta),\theta)
$$

- Step 2. 爲了求 $\hat\lambda_0(\theta)$，先視 $\theta$ 爲不變的，對上式 \@ref(eq:infer10-1) 求 $\lambda_0$ 的微分：

$$
\frac{\partial\ell(\lambda_0,\theta)}{\partial\lambda_0}=\frac{k}{\lambda_0} - (p_0+\theta p_1)
$$

把該微分方程等於0，推導出 $\hat\lambda_0=\frac{k}{p_0+\theta p_1}$ 就是 $\theta$ 在取值範圍內所有能使對數似然方程 \@ref(eq:infer10-1) 取極大值的對應 $\lambda_0$。

- Step 3. 將這個 $\theta$ 表示的 $\lambda_0\text{ MLE}$ 代替 $\lambda_0$ 代入對數似然方程 \@ref(eq:infer10-1) 中去：

$$
\begin{aligned}
\ell_p(\theta) &= k\text{log}\frac{k}{p_0 + \theta p_1} + k_1 \text{log}\theta - k \\
\text{Ignoring} &\text{ items not involving } \theta\\
\Rightarrow &= k_1\text{log}\theta - k\text{log}(p_0+\theta p_1)
\end{aligned}
$$

這個用子集似然法推導的關於參數 $\theta$ 的似然方程和前一章用條件似然法 (Section \@ref(condilikeli)) 推導的結果是完全一致的 \@ref(eq:inference9-2)。

## 子集似然法推導的過程總結

1. 多個參數中區分出我們感興趣的參數 $\psi$ 和其餘的障礙(噪音)參數 $\lambda$；
2. 爲了從對數似然方程中消除噪音參數，把它們一一通過微分求極值的辦法表達成用 $\psi$ 標記的表達式，用這些包含了 $\psi$ 的 $\text{MLE}$ 代替所有的噪音參數；
3. 整理最終獲得的只有感興趣的參數的對數似然方程，記得把不包含參數的部分忽略掉。

### 子集對數似然方程的分佈

$$
-2pllr(\psi) = -2\{ \ell_p(\psi) - \ell(\hat\psi)\} \stackrel{\cdot}{\sim} \chi^2_r
$$

其中自由度 $r$ 是想要檢驗的零假設中受限制的參數的個數。Degree of freedom $r$ is the number of parameters restricted under the null hypothesis. 所以，如果 $\psi$ 是一個維度 (dimension) 爲 $p$ 的向量，如果零假設是 $\text{H}_0: \psi = \psi_0$，那麼自由度就是 $p$。

### 假設檢驗過程舉例

兩個獨立的二項分佈樣本：$K_0 \sim \text{Bin}(n_0, \pi_0), K_1 \sim \text{Bin}(n_1, \pi_1)$。它們的聯合對數似然爲：

$$
\ell(\pi_0, \pi_1) = \ell(\pi_0) + \ell(\pi_1)
$$

如果要檢驗的零假設和替代假設分別是 $\text{H}_0: \pi_0 = \pi_1 \text{ v.s. H}_1: \pi_0 \neq \pi_1$。

如果令 $\theta=\frac{\pi_1}{\pi_0}$，那麼要檢驗的零假設和替代假設就變成了：

$$
\text{H}_0: \theta = 1 \text{ v.s. H}_1: \theta \neq 1 \\
\Rightarrow -2 pllr \stackrel{\cdot}{\sim} \chi^2_1
$$

而且在零假設條件下，$\text{H}_0: K_0+K_1 \sim \text{Bin}(n_0+n_1, \pi)$，那麼自己對數似然比檢驗的統計量是：

$$
\begin{aligned}
-2 pllr & = -2\{ \text{max}[\underset{\text{H}_0}{\ell(\pi_0,\theta\pi_0)}] -\text{max}[\underset{\text{H}_1}{\ell(\pi_0,\theta\pi_0)}] \} \\
\Rightarrow -2 pllr & =  -2\{ \text{max}[\underset{\text{H}_0}{\ell(\pi,\theta\pi)}] -\text{max}[\underset{\text{H}_1}{\ell(\pi_0,\pi_1)}] \} \\
\Rightarrow -2 pllr & = -2\{ \ell{(\hat\pi)} - \ell{(\hat\pi_0, \hat\pi_1)} \}
\end{aligned}
$$

## 子集對數似然比的近似

假如有兩個獨立樣本數據，參數分別只有一個 $\beta_0, \beta_1$，我們關心他們二者之間的差是否有意義 $\gamma = \beta_1-\beta_0$。如果 $\beta_0$ 的對數似然比檢驗統計量的相應的 Wald 檢驗統計量 (二次方程近似法 Section \@ref(Wald)) 可以用 $\hat\beta_0, S_0$ 定義，其中 $\beta_0$ 是 $\text{MLE}$，$S_0$ 是標準誤差。類似的，$\beta_1$ 的 Wald 檢驗統計量可以用 $\hat\beta_1, S_1$ 定義。那麼，我們關心的參數，$\gamma = \beta_1 - \beta_0$ 的 Wald 檢驗統計量可以用 $\hat\gamma = \hat\beta_1 - \hat\beta_1, S=\sqrt{S^2_1 + S^2_0}$ 定義：

$$
\begin{aligned}
pllr(\gamma) & = -\frac{1}{2}(\frac{\gamma-\hat\gamma}{\sqrt{S^2_1+S^2_0}})^2 \\
& = -\frac{1}{2}(\frac{(\beta_1-\beta_0)-(\hat\beta_1-\hat\beta_0)}{\sqrt{S^2_1+S^2_0}})^2
\end{aligned}
$$

### 子集對數似然比近似的一般化

如果我們關心的參數，和模型參數的關係可以用下面的表達式來表示：

$$
\gamma = W_0\beta_0 + W_1\beta_1 + \cdots \\
\text{ Where } W_i \text{ are arbitrary cosntants}
$$

如果，模型中的每個參數 $\beta_0, \beta_1, \cdots$ 的 $\text{MLE}$ 是 $\hat\beta_0, \hat\beta_1, \cdots$，標準誤是 $S=\sqrt{(W_0S_0)^2+(W_1S_2)^2+\cdots}$

### 事件發生率之比的 Wald 檢驗統計量

事件發生率 (Possion rate ratio) $\theta = \frac{\lambda_1}{\lambda_0}$

令 $\beta_1 = \text{log}\lambda_1, \beta_0 = \text{log}\lambda_0, \gamma = \text{log}\theta$。

所以有 $\gamma=\beta_1-\beta_0$。

由於

$$
\begin{aligned}
\hat\beta_0 & = \text{log}(\frac{k_0}{p_0}), \\
\hat\beta_1 & = \text{log}(\frac{k_1}{p_1}) \\
\end{aligned}
$$


因而

$$
\begin{aligned}
\hat\gamma & = \text{log}\frac{k_1}{p_1} - \text{log}\frac{k_0}{p_0} \\
           & = \text{log}\frac{k_1/p_1}{k_0/p_0}
\end{aligned}
$$

又由於 $S_0 = \frac{1}{\sqrt{k_0}}, S_1 = \frac{1}{\sqrt{k_1}}$ (Section \@ref(Possion-log-transform))。

所以 $S=\sqrt{\frac{1}{k_0}+\frac{1}{k_1}}$。

綜上，事件發生率之比的 Wald 檢驗統計量爲


$$
\begin{aligned}
pllr(\gamma) & = -\frac{1}{2}(\frac{\gamma - \hat\gamma}{\sqrt{\frac{1}{k_0}+\frac{1}{k_1}}})^2 \\
             & = -\frac{1}{2}(\frac{\text{log}\theta - \text{log}\frac{k_1/p_1}{k_0/p_0}}{\sqrt{\frac{1}{k_0}+\frac{1}{k_1}}})^2
\end{aligned}
$$
