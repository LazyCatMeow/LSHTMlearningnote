
從前一章節我們可以深切體會到，貝葉斯統計是如何讓我們的先驗概率，在觀察到數據之後，更新信息，獲得事後概率 (這是一個通過數據自我學習，進化的過程)。(How a prior belief about an event can be updated, given data, to a posterior belief.)

所以說，在貝葉斯模型中，我們期待使用觀察數據來學習，以增加現有的對相關參數的知識和信息。本章我們把重點放在二項分佈，用二項分佈作爲單一參數模型來瞭解怎樣推導事後分佈。

## 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions

- $R$ 用來表示服從一個二項分佈的隨機變量， $R\sim Bin(n, \theta)$。
- $r$ 表示觀察到 $r$ 次成功實驗，實驗次數爲 $n$。
- 先驗概率分佈： $\pi_\Theta(\theta)$
- 應用貝葉斯定理：

$$
\begin{aligned}
\pi_{\Theta|R}(\theta|r) &= \frac{f_R(r|\theta)\pi_\Theta(\theta)}{\int_0^1f_R(r|\theta)\pi_\Theta(\theta)\text{ d}\theta}\\
&= \frac{f_R(r|\theta)\pi_\Theta(\theta)}{f_R(r)}
\end{aligned}
$$


如果我們的先驗概率分佈：

$$\begin{equation}
\pi_\Theta(\theta)=\begin{cases}
1 \text{ if } \theta=0.2\\
0 \text{ otherwise}
\end{cases}
\end{equation}$$

意思就是，我們 100% 相信 $\theta$ 絕對就等於 0.2，不相信 $\theta$ 竟然還能取任何其他值（霸道自大又狂妄的我們）。

如果先驗概率分佈：

$$\begin{equation}
\pi_\Theta(\theta)=\begin{cases}
0.4 \text{ if } \theta=0.2\\
0.6 \text{ if } \theta=0.7
\end{cases}
\end{equation}$$

意思就是，我們有 60% 的把握相信 $\theta=0.7$，有 40% 的把握相信 $\theta=0.2$，稍微傾向於 $\theta=0.7$。

假設進行10次實驗，觀察到3次成功。當 $\theta=0.2$ 時，觀察數據的似然 (likelihood) 爲：

$$f_R(3|\theta=0.2)=\binom{10}{3}0.2^3(1-0.2)^7$$

當 $\theta=0.7$ 時，觀察數據的似然爲：

$$f_R(3|\theta=0.7)=\binom{10}{3}0.7^3(1-0.7)^7$$

應用貝葉斯定理計算事後概率分佈：


$$
\begin{equation}
\pi_{\Theta|R}(\theta|3)=\begin{cases}
\frac{\binom{10}{3}0.2^3(1-0.2)^7\times0.4}{\binom{10}{3}0.2^3(1-0.2)^7\times0.4+\binom{10}{3}0.7^3(1-0.7)^7\times0.6}=0.937 \text{ if } \theta=0.2\\
\frac{\binom{10}{3}0.7^3(1-0.7)^7\times0.6}{\binom{10}{3}0.7^3(1-0.7)^7\times0.6+\binom{10}{3}0.2^3(1-0.2)^7\times0.4}=0.063 \text{ if }\theta=0.7
\end{cases}
\end{equation}
$$

所以，我們從一開始認爲只有40%的把握相信 $\theta=0.2$，觀察數據告訴我們 10 次實驗，3次獲得了成功。所以我們現在有 93.7% 的把握相信 $\theta=0.2$。也就是說，觀察數據讓我們對參數 $\theta$ 的取值可能性發生了質的變化，從原先的傾向於 $\theta=0.7$ 到現在幾乎接近 100% 的認爲 $\theta=0.2$。也就是，觀察數據獲得的信息改變了我們的立場。

上面的例子很直觀，但是有下面幾個問題：

1. 如果我們無法對參數 $\theta$ 賦予先驗概率的點估計時，該怎麼辦？
2. 如果事後概率不是一個離散的分佈時，該如何才能表達事後概率？

## $\theta$ 的先驗概率

一種選擇是，我們用均一分佈 (uniform distribution)，即我們對數據一無所知，認爲所有的 $\theta$ 的可能性都一樣，概率密度方程爲 $1$。在這一情況下，先驗概率爲 1： $\pi_\Theta(\theta)=1$，其事後概率分佈爲：

$$
\begin{equation}
\pi_{\Theta|R}(\theta|r)=\frac{\binom{n}{r}\theta^r(1-\theta)^{n-r}}{\int_0^1\binom{n}{r}\theta^r(1-\theta)^{n-r} \text{ d}\theta}
(\#eq:uniformBayes)
\end{equation}
$$

看到即使在如此簡單的先驗概率下，我們還是要使用複雜的微積分進行計算。幸運的是，像 \@ref(eq:uniformBayes) 的分母這樣的積分公式其實是有跡可循的。這就是 beta ($\beta$) 分佈。

### beta 分佈 the beta distribution {#beta-distribution-intro}


```{r beta-distr, echo=FALSE, fig.height=7, fig.width=6, fig.cap='Beta distribution functions for various values of a, b', fig.align='center', out.width='90%', cache=TRUE}
par(mfrow=c(3,2))
pi <- Vectorize(function(theta) dbeta(theta, 1,1))
curve(pi, xlab=~ theta, ylab="Density", main="Beta prior: a=1, b=1", frame=FALSE, lwd=2)
pi <- Vectorize(function(theta) dbeta(theta, 0.3,1))
curve(pi, xlab=~ theta, ylab="Density", main="Beta prior: a=0.3, b=1",frame=FALSE, lwd=2)
pi <- Vectorize(function(theta) dbeta(theta, 0.3,0.3))
curve(pi, xlab=~ theta, ylab="Density", main="Beta prior: a=0.3, b=0.3",frame=FALSE, lwd=2)
pi <- Vectorize(function(theta) dbeta(theta, 2,2))
curve(pi, xlab=~ theta, ylab="Density", main="Beta prior: a=2, b=2",frame=FALSE, lwd=2)
pi <- Vectorize(function(theta) dbeta(theta, 8,2))
curve(pi, xlab=~ theta, ylab="Density", main="Beta prior: a=8, b=2",frame=FALSE, lwd=2)
pi <- Vectorize(function(theta) dbeta(theta, 2,8))
curve(pi, xlab=~ theta, ylab="Density", main="Beta prior: a=2, b=8",frame=FALSE, lwd=2)
```


你會發現，beta分佈的圖形特徵由它的兩個超參數 (hyperparameter) `a, b` 決定。當相對地 `a` 比較大的時候，beta分佈的概率多傾向於較靠近橫軸右邊，也就是1的位置（較高概率），相對地 `b` 比較大的時候，beta分佈的曲線多傾向於靠近橫軸左邊，也就是0的位置（較低概率）。如果 `a` 和 `b`同時都在變大的話，beta分佈的曲線就變得比較“瘦”。這樣決定概率分佈形狀的參數，又被叫做**形狀參數 (shape parameters)**




我們定義 $a>0$ 時[伽馬方程](https://zh.wikipedia.org/wiki/%CE%93%E5%87%BD%E6%95%B0)爲

$$\Gamma(a)=\int_0^\infty x^{a-1}e^{-ax}\text{ d}x$$

當 $a$ 取正整數時， $\Gamma(a)$ 是 $(a-1)!$。例如，當 $a=4, \Gamma(a)=3\times2\times1=6$。

對於 $\theta\in[0,1]$ 時，beta 方程 $Beta(a,b)$ 被定義爲：

$$
\begin{aligned}
\pi\Theta(\theta|a,b) &= \theta^{a-1}(1-\theta)^{b-1}\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\\
&= \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)}
\end{aligned}
$$


其中 
$$B(a,b)=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)} = \int_0^1\theta^{a-1}(1-\theta)^{b-1}\text{d}\theta$$

**莫要混淆 B 函數和 Beta 方程。B 函數的性質和詳細定義可以參照[其維基百科頁面](https://zh.wikipedia.org/wiki/%CE%92%E5%87%BD%E6%95%B0)。**


利用 Beta 方程作爲先驗概率顯得十分便捷且靈活。圖 \@ref(fig:beta-distr) 展示的是 6 種不同的 $(a,b)$ 取值下的先驗概率分佈示意圖。其實我們可以看到，包括均一分佈在內的各種可能性都可以通過 Beta 分佈實現。其中 $(a,b)$ 被叫做超參數 (hyperparameter)。$(a,b)$ 取值越大，先驗概率分佈的方差越小。

關於 Beta 分佈的幾個性質：

1. 均值：$\text{mean}=\frac{a}{a+b}$；
2. 衆數：$\text{mode}=\frac{a-1}{a+b-2}$；
3. 方差：$\text{variance}=\frac{ab}{(a+b)^2(a+b+1)}$。

回到均一分佈的簡單例子 \@ref(eq:uniformBayes) 上：

$\pi_\Theta(\theta)=Beta(1,1)$ 是 $\theta\in[0,1]$ 上的均一分佈。所以事後概率 posterior 和下面的式子成正比：

$$\theta^r(1-\theta)^{n-r}$$

換句話說，事後概率分佈服從 $Beta(r+1,n-r+1)$ 分布，均值爲 $\frac{r+1}{n+2}$，方差爲 $\frac{(1+r)(n-r+1)}{(n+2)^2(n+3)}$。

由此可見，在貝葉斯統計思維下，先驗概率爲均一分佈的二項分佈數據，其事後概率分佈的均值和方差，和經典概率論下的極大似然估計 $r/n$ 不同，和它的漸進樣本方差 $r(n-r)/n^3$ 也不同。但是，當 $n$ 越來越大，獲得的觀察數據越多提供的信息越來越多以後，我們會發現事後概率分佈的均值和方差也會越來越趨近於經典概率論下的極大似然估計和它的方差。

於是這裏可以總結以下兩點：

1. 即使先驗概率對參數毫無用處（不能提供有效信息，或者我們對所觀察的數據一無所知），也可能會對事後概率分佈結果提供一些意外的信息。
2. 當樣本量增加，似然就主導了整個貝葉斯方程，在數學計算上，經典概率論和貝葉斯推理的估計結果將會十分接近。當然，其各自的意義還是截然不同的。

### 二項分佈數據事後概率分佈的一般化：共軛性 {#conjugate}

當 $r\sim \text{Binomial}(n,\theta)$ 時，如果先驗概率 $\pi_\Theta(\theta)=\text{Beta}(a,b)$。那麼參數 $\theta$ 的事後概率分佈的密度方程滿足：

$$\pi_{\Theta|r}(\theta|r)=\text{Beta}(a+r, b+n-r)$$

它的事後概率分佈均值爲：

$$E[\theta|r]=\frac{a+r}{a+b+n}$$

事後概率分佈的衆數爲：

$$\text{Mode}[\theta|r]=\frac{a+r-1}{n+a+b-2}$$

事後概率分佈方差爲：

$$\text{Var}[\theta|r]=\frac{(a+r)(b+n-r)}{(a+b+n)^2(a+b+n+1)}$$

因此，我們看到先驗概率服從 $\text{Beta}(a,b)$ 分佈，觀察數據爲二項分佈時，事後概率分佈還是服從 $\text{Beta}$ 分佈，僅僅只是超參數發生了轉變（更新）。這就是**共軛分佈**的實例。$\text{Beta}$ 分佈是二項分佈的共軛先驗概率分佈 (the $\text{Beta}(a,b)$ is the conjugate prior for the binomial likelihood)。

在經典概率論的框架下，參數 $\theta$ 的估計就是極大似然估計 (MLE)。在二項分佈的例子中， $\text{MLE}=\hat\theta=r/n$，當樣本量 $n\rightarrow\infty$ 時，事後概率分佈均值：

$$E[\theta|r]=\frac{a+r}{a+b+n}=\frac{\frac{r}{n}+\frac{a}{n}}{1+\frac{a+b}{n}}\approx\frac{r}{n}=\text{MLE}$$

事後概率分佈的衆數爲：

$$
\begin{aligned}
\text{Mode}[\theta|r] &=\frac{a+r-1}{n+a+b-2} \\
&= \frac{\frac{r}{n}+\frac{a-1}{n}}{1+\frac{a+b-2}{n}}\\
&\approx \frac{r}{n}
\end{aligned}
$$

事後概率分佈的方差爲：

$$\frac{(a+r)(b+n+r)}{(a+b+n)^2(a+b+n+1)}\approx0$$

當 $n$，樣本越來越大時，我們獲得更多的來自數據的信息，所以來自數據的信息逐漸主導 (dominate) 了整個貝葉斯推斷的過程，事後均值等衆多統計結果都越來越趨近於概率論統計思想下的極大似然估計等結論。

我們也可以注意到，當 $a\rightarrow0, b\rightarrow0$ 時，事後概率分佈的均值 $E[\theta|r] = \frac{a+r}{a+b+n} \rightarrow \frac{r}{n}$，方差也趨向於樣本漸進方差 (asymptotic sample variance)。但是當 $a\rightarrow 0, b\rightarrow0$ 時，先驗概率是沒有被定義的，可是此例下事後概率卻可以正常被定義。所以當先驗概率分佈無法被定義，或者被定義的不恰當時，事後概率分佈依然不受太大影響。所以特別是對於均值（或迴歸係數，regression coefficients）等參數，我們常常會使用均一分佈這樣的無信息先驗概率。


## 附贈--加量不加價

**當樣本數據服從二項分布時使用 $\text{Beta}(a,b)$ 作爲先驗概率分布，試推導事後概率分布。並且證明 Beta 分布是二項分布的共軛分布 (conjugate distribution)。**

- 當數據服從二項分布時，其似然方程 (或概率方程) 爲: <br> $$f(n,r|\theta) = \binom{n}{r}\theta^r(1-\theta)^{n-r}$$

- 用 $\text{Beta}(a,b)$ 做先驗概率分布 ($a,b$ 是 $\theta$ 的超參數)，那麼 <br>

$$
\begin{aligned}
\pi(\theta) &= \text{Beta}(\theta|a,b) \\
& =  \theta^{a-1}(1-\theta)^{b-1}\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} \\ 
& = \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)} \\
\text{Where } B(a,b) &=\frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)} = \int_0^1\theta^{a-1}(1-\theta)^{b-1}\text{d}\theta
\end{aligned}
$$

- 利用貝葉斯定理，後概率分布就可以推導爲 <br> 

$$
\begin{aligned}
\pi(\theta|n,r) & = \frac{f(n,r|\theta)\pi(\theta)}{\int f(n,r |\theta)\pi(\theta)\text{d}\theta}   \\
                & = \frac{\binom{n}{r}\theta^r(1-\theta)^{n-r}\pi(\theta)}{\int_0^1\binom{n}{r}\theta^r(1-\theta)^{n-r} \pi(\theta) \text{ d}\theta} \\
                & = \frac{\binom{n}{r}\theta^r(1-\theta)^{n-r}\frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)}}{\int_0^1\binom{n}{r}\theta^r(1-\theta)^{n-r} \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)} \text{ d}\theta} \\
                & = \frac{\binom{n}{r}\theta^{r+a-1}(1-\theta)^{n+b-r-1}}{\int_0^1\binom{n}{r}\theta^{r+a-1}(1-\theta)^{n+b-r-1} \text{ d}\theta} \\
                & = \frac{\theta^{r+a-1}(1-\theta)^{n+b-r-1}}{B(r+a, n+b-r)} \\
                & \sim \text{Beta}(r+a, n+b-r)
\end{aligned}
$$
這個推導的結果告訴我們，先驗概率 $\pi(\theta) =  \frac{\theta^{a-1}(1-\theta)^{b-1}}{B(a,b)}\sim \text{Beta}(a,b)$，通過和二項分布的似然方程相乘，獲得後驗概率 $\pi(\theta|n,r) = \frac{\theta^{r+a-1}(1-\theta)^{n+b-r-1}}{B(r+a, n+b-r)}\sim\text{Beta}(r+a, n+b-r)$。這兩個概率都服從 $\text{Beta}$ 分布，也就是證明了 $\text{Beta}$ 分布，是二項分布的共軛分布。新產生的事後概率的性質有: <br>

1. $\theta$ 的均值 mean $\mu= \frac{a+r}{a+b+n}$;
2. $\theta$ 的方差 variance $\sigma^2 = \frac{(a+r)(n+b-r)}{(a+b+n)^2(a+b+n+1)}$;
