
這裏我們來探討如何在密度估計 (density estimation) 中使用非參貝葉斯 (BNP) 模型。主要介紹狄雷克雷過程的先驗概率在 BNP 模型中的應用。狄雷克雷過程是目前最常見的BNP。它主要有兩種類型：狄雷克雷過程混合模型 Dirichlet process mixture modeling，和有限狄雷克雷過程 finite Dirichlet process。


密度估計是常見的需要對來自陌生分佈 $G$ 的獨立同分佈 (i.i.d) 樣本進行推斷時的過程：

$$
\begin{equation}
y_i | G \stackrel{i.i.d}{\sim} G, i = 1, \dots,n
(\#eq:DPsampling)
\end{equation}
$$

當我們需要對該過程使用貝葉斯理論推斷時，我們需要給 $G$ 補充一個先驗概率分佈 $\pi$。假設這個 $G$ 的先驗概率分佈需要無限維度參數，也就是需要一個 BNP 先驗概率。

## 狄雷克雷過程 Dirichlet process

### 定義 definition

狄雷克雷過程先驗概率 (DP prior) 是最常見的 BNP 模型。它最早由 @ferguson1973bayesian 作爲測量概率空間的先驗概率分佈提出 (as a prior on the space of probability measures)。

```{definition, label="DP", name = "Dirichlet process-DP"}
令 $M > 0$ 且 $G_0$ 是定義在空間 $S$ 上的概率測量 (probability measure)。一個 DP 過程的參數由 $(M, G_0)$ 構成。該過程是定義在空間 $S$ 上的一個隨機概率測量，對於任意一個可以測量的子集 $B$ 賦予對應的概率 $G(B)$。$\{ B_1, \dots, B_k \}$ 構成了整個空間 $S$。那麼這些子集的聯合概率分佈 joint distribution $(G(B_1), \dots, G(B_k))$ 是一個狄雷克雷分佈，它的參數表達如下：
$$
(MG_0(B_1), MG_0(B_2), \dots, MG_0(B_k))
$$
```



這個 DP 過程又可簡寫爲 **DP**$(MG_0)$，或者 **DP**$(M,G_0)$。其中參數 $M$ 叫做精確度 (precision) 或者總量參數 (total mass parameter)。參數 $G_0$ 則又叫做中心測量 (centering measure)，他們的乘積 $\alpha \equiv MG_0$ 被叫做狄雷克雷過程的基礎測量 (base measure)。

狄雷克雷過程一個重要性質是 $G$ 的離散特性 (discrete nature)。由於是一個離散型隨機概率測量，我們總是可以把 $G$ 改寫成是每個測量位點的權重之和 (sum of point masses)：$G(\cdot) = \sum_{h = 1}^\infty w_h \delta_{m_h}(\cdot)$。這個權重之和中，$w_1, w_2, \dots$ 就是概率權重，$\delta_x(\cdot)$ 標記的是 $x$ 的狄拉克位置測量 (Dirac measure at $x$)。狄雷克雷另一個重要性質是它強大的極微小支持 (largely weak support)。這意味着，在較爲溫和的條件下，任意的分佈都可以通過中心測量 $G_0$，和隨機概率測量模擬和近似 (well approximated)。

**掰棍子過程 (stick-breaking process)** 是利用狄雷克雷過程中 $G(\cdot)$ 的離散性質，即 $G(\cdot) = \sum_{h = 1}^\infty w_h \delta_{m_h} (\cdot)$。在掰棍子過程中，位置函數 $m_h$ 是從中心測量 $G_0$ 中隨機採集的 i.i.d 樣本。每一個權重 $w_h$ 是被定義爲剩餘長度棍子中的一部分 (a fraction of what is left after the proceeding point mass)：$\{ 1- \sum_{\ell < h} W_\ell \}$。令 $w_h = v_h \prod_{\ell < h}(1 - v_\ell)$，且 $v_h \stackrel{i.i.d}{\sim} \text{Beta}(1, M)$，$m_h \stackrel{i.i.d}{\sim} G_0$，$\{ v_h \}, \{ m_h \}$ 之間相互獨立。那麼就定義隨機概率測量 **DP**$(MG_0)$ 爲：

$$
\begin{equation}
G(\cdot) = \sum_{h = 1}^\infty w_h \delta_{m_h} (\cdot)
(\#eq:DPMG0)
\end{equation}
$$
 
這樣表達的話， $G \sim \mathbf{DP}(MG_0), m \sim G_0, W \sim \text{Beta}(1, M)$ 會使 $W\delta_m(\cdot) + (1 - W) G(\cdot)$ 本身仍然是一個 **DP**$(MG_0)$ 的分佈。



### 推導

假如有樣本量是 $N$ 的一組觀察數據 $x_1, x_2, x_3, \dots, x_i, \dots, x_N$，這個數據中國每一個元素，對應產生它的分佈的相應參數是 $\theta_1, \theta_2, \theta_3, \dots, \theta_i,  \dots, \theta_N$。如果 $\theta_i \sim H(\theta)$ 是一個連續分佈，那麼該過程產生的 $\theta$ 將不可能有相同的值，即 $\text{Pr}(\theta_1 = \theta_2) = 0$。

這時，我們思考，讓 $\theta_i \sim G$ 是一個離散型 (discrete) 分佈。

$$
G \sim \mathbf{DP} (\alpha, H)
$$

其中，$\alpha$ 是一個大於零的標量 (scalar)，$\alpha > 0$。$\alpha$ 決定了離散分佈 $G$ 本身和連續分佈 $H$ 之間相似程度，$\alpha$ 越小，$G$ 越離散，$\alpha$ 越大，$G$ 越接近 $H$，也就是越平滑（越連續）。當 $\alpha$ 等於零，$G$ 就離散到只剩下一個單一的值，也就是極端離散情況。反過來，$\alpha \rightarrow \infty$ 時，$G = H$。當然這兩種極端情況是我們在使用 DP 時不太會採用的。

$H$ 也可以使用離散分佈，並不一定非要是連續型分佈。

如果我們從某個分佈 $x_i \sim P(X | \theta)$ 中採集樣本，我們只能得到一系列的觀測點，只是一個實現的值。但是如果 $G \sim \mathbf{DP}(\alpha, H)$，它產生的則不是一個個的值，而是隨機採集整個離散型的分佈, random discrete probability measure。如圖 \@ref(fig:BNP02-fig1) 所示的那樣，我們從一個 $G \sim \mathbf{DP}(\alpha, H)$ 採集兩個 $G_1, G_2$ 離散分佈，每個離散分佈之間互不相同，它們有各自的點，和每個點上"棍子"的長度，由於他們都是一個完整的離散分佈，那麼很顯然，每一次採集的 $G$ 它的那些瑣碎的棍子的長度加起來都必須等於1。

```{r BNP02-fig1, cache=TRUE, echo=FALSE, fig.asp=.7, fig.width=6, fig.align='center', out.width='90%', fig.cap="Sampling through Dirichlet Process is sampling random discrete probability measures for us, each sample is a whole discrete distribution."}
knitr::include_graphics(paste0(bugpath, "/img/Gsampling.png"))
```



### 事後概率分佈和邊際分佈

**事後更新 posterior updating**：狄雷克雷過程本身是共軛的 (conjugate)。也就是說，只要是按照獨立同分佈原則從模型 (\@ref(eq:DPsampling)) 中進行 DP 採樣，獲得的事後概率分佈還是一個狄雷克雷 DP。


也就是說，如果令 $y_1, \dots, y_n | G \stackrel{i.i.d}{\sim} G$ 且 $G \sim \mathbf{DP}(M, G_0)$，那麼，事後概率分佈爲：

$$
\begin{equation}
G | y_1,\dots, y_n \sim \mathbf{DP}(M + n, \frac{MG_0 + \sum_{i = 1}^n \delta_{y_i}}{M + n})
\end{equation}
$$



```{example label="BNP-0201"}
**T細胞受體個數問題** @guindani2014bayesian 探討了計算T細胞受體個數和對應種類的問題。已知T細胞受體的種類和個數是免疫系統重要的指標之一。常見的分析該指標的方法是對受體集羣(clonal-size)計數，來評價其複雜程度 (diversity)。集羣分佈可以用統計表格計算集羣的頻率 $\hat{G}_y, y = 1, 2, \dots, n$。例如，$\hat{G}_2 = 11$，就表示有11個不同的T細胞受體集羣，每個集羣出現了2次。
```

下表展示了 $\hat{G}_y$ 的觀察頻率，及其對應的計數 counts $y_i = 1, 2, \dots$。

| Counts $y_i$ | 1   | 2   | 3   | 4   | $\geq$ 5 |
| :----------- | :-- | :-- | :-- | :-- | :------- |
| Frequencies  | 37  | 11  | 5   | 2   | 0        |


假如我們思考這樣一個模型 $y_i \sim G$，其中給集羣分佈(clonal size distribution)的先驗概率分佈是一個狄雷克雷過程分佈 $G\sim$**DP**$(MG_0)$。由於計數型數據必須爲正(positive counts)，我們使用均值等於 2 的泊松分佈作爲中心測量 centering measure $G_0 = \mathbf{Poi}(2)$。總量參數 (total mass parameter) 使用 $M =1$。


下列採樣過程的代碼來自 [https://rpubs.com/kaz_yos/dp1](https://rpubs.com/kaz_yos/dp1)，你也可以參考原作者的[網站](https://web.ma.utexas.edu/users/pmueller/bnp/R/DP/tcr/Tcell-ex3-DP.R) 

```{r BNP-02exp3, cache=TRUE}
library(MCMCpack)
library(tidyverse)
tcell <- tribble(
    ~count, ~frequency,
    1, 37,
    2, 11,
    3, 5,
    4, 2,
    ## >= 5, 0,
    )
tcell

# Prior

G0_vector <- function(lambda, min, max) {
    ## values below min are truncated
    ## values above max are collapsed

    ## Probabilities from Poisson(lambda) for min:max
    p_vec <- dpois(x = min:max, lambda = lambda)
    ## Probability for max+1 ...
    p_upper_tail <- 1 - ppois(q = max, lambda = lambda)
    ## Collapse to max
    p_vec[length(p_vec)] <- p_vec[length(p_vec)] + p_upper_tail
    ## Renormalize
    p_vec <- p_vec / sum(p_vec)
    ## Name
    names(p_vec) <- min:max
    ##
    return(p_vec)
}

## Collapse all values beyond 8 to 8+ bin
G0_vector(lambda = 2, min = 1, max = 8)
```



