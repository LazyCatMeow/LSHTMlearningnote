
我們用數據擬合廣義線性模型時其實有許多不同的目的和意義：

1. 估計某些因素的暴露和因變量之間的相關程度，同時調整其餘的混雜因素；
2. 確定能夠強有力的預測因變量變化的因子；
3. 用於預測未來的事件或者病人的預後等等。

但是一般情況下，我們拿到數據以後不可能立刻就能構建起來一個完美無缺的模型。我們常常會擬合兩三個甚至許多個模型，探索模型和數據的擬合程度，就成爲了比較哪個模型更優於其他模型的硬指標。本章的目的是介紹 GLM 嵌套式模型之間的兩兩比較方法，其中一個模型的預測變量是另一個模型的預測變量的子集。

對手裡的數據構建一個GLM的過程，其實就是在該數據的條件下(given the data)，對模型參數 $\mathbf{\beta}$ 定義其對數似然 (log-likelihood)，並尋找能給出極大值的那一系列極大似然估計 (maximum likelihood estimates, MLE) $\mathbf{\hat\beta}$ 的過程。每次構建一個模型，我們都會獲得該模型對應的極大對數似然，它其實是極爲依賴構建它的觀察數據的，意味着每次觀察數據發生變化，你即使用了相同的模型來擬合相同的GLM獲得的極大似然都會發生變化。所以其實我們並不會十分關心這個極大似然的絕對值大小。我們關心的其實是，當對相同數據，構建了包含不同變量的模型時，極大似然的**變化量**。因爲這個極大似然(或者常被略稱爲對數似然 log likelihood，甚至直接只叫做似然)的變化量本身確實會反應我們思考的模型，和觀察數據之間的擬合程度。一般來說，模型中變量較少的那個 (通常叫做更加一般化的模型 more general model)獲得的似然值和變量較多的那個模型獲得的似然值相比較都會比較小，我們關心的似然值在增加了新變量之後的複雜模型後獲得的**增量**，是否有價值，是否真的改善了模型的擬合度 (whether the difference in log likelihoods is large enough to indicate that the less general model provides a "real" improvement in fit)。

## 嵌套式模型的比較 nested models

假如我們用相同的數據擬合兩個 GLM，$\text{Model 1, Model 2}$。其中，當限制 $\text{Model 2}$ 中部分參數爲零之後會變成 $\text{Model 1}$時， 我們說 $\text{Model 1}$ 是 $\text{Model 2}$ 的嵌套模型。



- 例1：嵌套式模型 I
   <br> 模型 1 的線性預測方程爲 $$\eta_i = \alpha + \beta_1 x_{i1}$$
   <br> 模型 2 和模型 1 的因變量相同 (分佈相同)，使用相同的鏈接方程 (link function) 和尺度參數 (scale parameter, $\phi$)，但是它的線性預測方程爲 $$\eta_i = \alpha + \beta_1 x_{i1} + \beta_2 x_{i1} + \beta_3 x_{i3}$$
   <br> 此時我們說模型 1 是模型 2 的嵌套模型，因爲令 $\beta_2 = \beta_3 = 0$ 時，模型 2 就變成了 模型 1。
- 例2：嵌套式模型 II
   <br> 模型 1 的線性預測方程爲 (此處默認 $x_{i1}$ 是連續型預測變量) $$\eta_i = \alpha + \beta_1 x_{i1}$$
   <br> 模型 2 的線性預測方程如果是 $$\eta_i = \alpha + \beta_1 x_{i1} + \beta_2 x^2_{i1}$$
   <br> 此時我們依然認爲 模型 1 是模型 2 的嵌套模型， 因爲令 $\beta_2 = 0$ 時，模型 2 就變成了 模型 1。


關於嵌套式模型，更加一般性的定義是這樣的：**標記模型 2 的參數向量是 $\mathbf{(\psi, \lambda)}$，其中，當我們限制了參數向量的一部分例如 $\mathbf{\psi = 0}$，模型 2 就變成了 模型 1 的話，模型 1 就是嵌套於 模型 2 的**。所以比較嵌套模型之間的擬合度，我們可以比較較爲複雜的 模型 2 相較 模型 1 多出來的複雜的預測變量參數部分 $\mathbf{\psi}$ 是否是必要的。也就是說，比較嵌套模型哪個更優的情況下，零假設是 $\mathbf{\psi = 0}$。

這是典型的多變量的模型比較，需要用到子集似然比檢驗 \@ref(profile-log-likelihood)，log-likelihood ratio test：

$$
\begin{aligned}
-2pllr(\psi = 0) & = -2\{ \ell_p(\psi=0) - \ell_p(\hat\psi) \} \stackrel{\cdot}{\sim} \chi^2_{df}\\
\text{Where } \hat\psi & \text{ denotes the MLE of } \psi \text{ in Model 2} \\
\text{With } df & = \text{ the dimension of } \mathbf{\psi}
\end{aligned}
$$


$\ell_p(\psi=0)$，其實是 模型 1 的極大對數似然，記爲 $\ell_1$。$\ell_p(\hat\psi)$ 其實是 模型 2 的極大對數似然，記爲 $\ell_2$。所以這個似然比檢驗統計量就變成了：

$$
-2pllr(\psi = 0) = -2(\ell_1-\ell_2)
$$

這個統計量在零假設的條件下服從自由度爲兩個模型參數數量之差的卡方分佈。如果 $p$ 值小於提前定義好的顯著性水平，將會提示有足夠證據證明 模型 2 比 模型 1 更好地擬合數據。

## 嵌套式模型比較實例

回到之前用過的瘋牛病和牲畜羣的數據 \@ref(BSEinfection)。我們當時成功擬合了兩個 GLM 模型，模型 1 的預測變量只有 “飼料”，“羣”；模型 2 的預測變量在模型 1 的基礎上增加二者的交互作用項。並且我們當時發現交互作用項部分並無實際統計學意義 $p = 0.584$。現在用對數似然比檢驗來進行類似的假設檢驗。

先用 `logLik(Model)` 的方式提取兩個模型各自的對數似然，然後計算對數似然比，再去和自由度爲 1 (因爲兩個模型只差了 1 個預測變量) 的卡方分佈做比較：

```{r GLM-0401, cache=TRUE, message=FALSE}
Model1 <- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor, family = binomial(link = logit), data = Cattle)
Model2 <- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor + factor(group)*dfactor, family = binomial(link = logit), data = Cattle)
logLik(Model1)
logLik(Model2)
LLR <- -2*(logLik(Model1) - logLik(Model2))

1-pchisq(as.numeric(LLR), df=1) # p value for the LLR test
```

再和 `lmtest::lrtest` 的輸出結果作比較。

```{r GLM-0402, cache=TRUE,  message=FALSE}
lmtest::lrtest(Model1, Model2)
```

結果跟我們手計算的結果完全吻合。AWESOME !!!

值得注意的是，此時進行的似然比檢驗結果獲得的 p 值，和模型中 Wald 檢驗結果獲得的 p 值十分接近 (0.5801 v.s. 0.584)，這也充分顯示了這兩個檢驗方法其實是漸進相同的 (asymptotically equivalent)。

## 飽和模型，模型的偏差，擬合優度

在簡單線性迴歸中，殘差平方和提供了模型擬合數據好壞的指標 -- 決定係數 $R^2$ (Section \@ref(Rsquare))，並且在 偏 F 檢驗 (Section \@ref(partialF)) 中得到模型比較的應用。

廣義線性迴歸模型中事情雖然沒有這麼簡單，但是思想可以借鑑。先介紹飽和模型 (saturated model) 的概念，再介紹其用於模型偏差 (deviance) 比較的方法。前文中介紹過的嵌套模型之間的對數似然比檢驗，也是測量兩個模型之間偏差大小的方法。

### 飽和模型 saturated model

飽和模型 saturated model，是指一個模型中所有可能放入的參數都被放進去的時候，模型達到飽和，自由度爲零。其實就是模型中參數的數量和觀測值個數相等的情況。飽和模型的情況下，所有的擬合值和對應的觀測值相等。所以，對於給定的數據庫，飽和模型提供了所有模型中最 “完美” 的擬合值，因爲擬合值和觀測值完全一致，所以飽和模型的對數似然，比其他所有你建立的模型的對數似然都要大。但是多數情況下，飽和模型並不是合理的模型，不能用來預測也無法拿來解釋數據，因爲它本身就是數據。

### 模型偏差 deviance {#deviance}

令 $L_c$ 是目前擬合模型的對數似然，$L_s$ 是數據的飽和模型的對數似然，所以兩個模型的對數似然比是 $\frac{L_c}{L_s}$。那麼尺度化的模型偏差 (scaled deviance) $S$ 被定義爲：

$$
S=-2\text{ln}(\frac{L_c}{L_s}) = -2(\ell_c - \ell_s)
$$

值得注意的是，非尺度化偏差 (unscaled deviance) 被定義爲 $\phi S$，其中的 $\phi$ 是尺度參數，由於泊松分佈和二項分佈的尺度參數都等於 1 ($\phi = 1$)，所以尺度化偏差和非尺度化偏差才會在數值上相等。

這裏定義的模型偏差大小，可以反應一個模型擬合數據的程度，偏差越大，該模型對數據的擬合越差。"Deviance can be interpreted as Badness of fit".

**但是，模型偏差只適用於彙總後的二項分佈數據(aggregated)。當數據是個人的二進制數據時 (inidividual binary data)，模型的偏差值變得不再適用，無法用來比較模型對數據的擬合程度。** 這是因爲當你的觀測值 (個人數據) 有很多時，擬合飽和模型所需要的參數個數會趨向於無窮大，這違背了子集對數似然比檢驗的條件。

### 彙總型二項分佈數據 aggregated/grouped binary data

假如，觀察數據是互相獨立的，服從二項分佈的 $n$ 個觀測值: $Y_i \sim Bin(n_i, \pi_i), i=1,\dots,n$。用彙總型的數據表達方法來描述它，那麼獲得的數據就是一個個分類變量在各自組中的人數或者百分比的數據 (如下面的數據所示)。這樣的數據的飽和模型，其實允許了每個分類變量的組中百分比變化 (The saturated model for this data allows the probability of "success" to be different in each group, so that $\tilde{\pi} = \frac{y_i}{n_i}$)。也就是每組的模型擬合後百分比，等於觀察到的百分比。


```{r  GLM-040202, echo=FALSE, cache=TRUE}
Insect <- read.table("../backupfiles/INSECT.RAW", header =  FALSE, sep ="", col.names = c("dose", "n_deaths", "n_subjects"))
print(Insect)
```


那麼彙總型二項分佈數據，其飽和模型的對數似然其實就是

$$
\ell_s = \sum_{i = 1}^n\{ \log\binom{n_i}{y_i} + y_i\log(\tilde{\pi_i}) + (n_i - y_i)\log(1 - \tilde{\pi_i}) \}
$$

假設此時我們給這個數據擬合一個非飽和模型，該模型告訴我們每個分類組中的預測百分比是 $\hat\pi_i, i = 1, \dots, n$，那麼這個非飽和模型的對數似然其實是

$$
\ell_c = \sum_{i = 1}^n\{ \binom{n_i}{y_i} + y_i\log(\hat\pi_i) + (n_i - y_i)\log(1-\hat\pi_i)\}
$$


那麼這個非飽和模型的模型偏差 (deviance) 就等於 

$$
\begin{aligned}
S & = -2(\ell_c - \ell_s) \\
  & = 2\sum_{i = 1}^n\{ y_i\log(\frac{\tilde{\pi_i}}{\hat\pi_i}) + (n_i - y_i)\log(\frac{1-\tilde{\pi_i}}{1-\hat\pi_i}) \}
\end{aligned}
$$

從上面這個表達式不難看出，模型偏差值的大小，將會隨着模型預測值的變化而變化，如果它更加接近飽和模型的預測值 (飽和模型的預測值其實就等於觀測值)，那麼模型的偏差就會比較小。如果你的彙總型數據擬合了你認爲合適的模型以後，你發現它的模型偏差值很大，那麼就意味着你的模型預測值其實和觀測值相去甚遠，模型和觀測值的擬合度應該不理想。對於彙總型數據來說，模型偏差值，其實等價於將你擬合的模型和飽和模型之間做子集對數似然比檢驗 (profile log-likelihood ratio test)。漸進來說 (asymptotically)，這個子集對數似然比檢驗的結果，會服從自由度爲 $n-p$ 的 $\chi^2$ 分佈，其中 $n, p$ 分別是飽和模型和你擬合的模型中被估計參數的個數。


## 個人數據擬合模型的優度檢驗 {#gof}

在上文中已經提到了，當你的數據不再是彙總型二項分佈數據，而是個人二項分佈數據 (individual binary data) 時，模型偏差 (deviance) 無法用來評價你建立的模型。這樣的數據其實比彙總型二項分佈數據更加常見，當模型中一旦需要加入一個連續型變量時，數據就只能被表達爲個人二項分佈數據。對於個人二項分佈數據模型擬合度比較，最常用的方法是 [@hosmer1980goodness] 提出的模型擬合優度檢驗法 (goodness of fit)。該方法的主要思想是，把個人二項分佈數據模型獲得的個人預測值 (model predicted probabilities) $\hat\pi_i$ 進行人爲的分組，把預測值數據強行變成彙總型二項分佈數據，那麼觀測值的樣本量即使增加到無窮大，也不會使得模型中組別增加到無窮大，從而可以規避

在 R 裏面，進行邏輯迴歸模型的擬合優度檢驗的自定義方程如下，參考[網站](http://data.princeton.edu/wws509/r/c3s8.html)：

```{r  GLM-0403, cache=TRUE}
hosmer <- function(y, fv, groups=10, table=TRUE, type=2) {
 # A simple implementation of the Hosmer-Lemeshow test
   q <- quantile(fv, seq(0,1,1/groups), type=type)
   fv.g <- cut(fv, breaks=q, include.lowest=TRUE)
   obs <- xtabs( ~ fv.g + y)
   fit <- cbind( e.0 = tapply(1-fv, fv.g, sum), e.1 = tapply(fv, fv.g, sum))
   if(table) print(cbind(obs,fit))
   chi2 <- sum((obs-fit)^2/fit)
   pval <- pchisq(chi2, groups-2, lower.tail=FALSE)
   data.frame(test="Hosmer-Lemeshow",groups=groups,chi.sq=chi2,pvalue=pval)
 }
```

```{r lbw, cache=TRUE}
# lbw <- read_dta("http://www.stata-press.com/data/r12/lbw.dta")
lbw <- read_dta(file = "../backupfiles/lbw.dta")
lbw$race <- factor(lbw$race)
lbw$smoke <- factor(lbw$smoke)
lbw$ht <- factor(lbw$ht)
Modelgof <- glm(low ~ age + lwt + race + smoke + ptl + ht + ui, 
                data = lbw, family = binomial(link = logit))
hosmer(lbw$low, fitted(Modelgof))
hosmer(lbw$low, fitted(Modelgof), group=5)
```