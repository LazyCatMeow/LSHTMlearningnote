# (PART) 廣義線性迴歸模型 Generalised Linear Regression {-}

# 重要概念複習

> There are no routine statistical questions, only questionable statistical routines.
> ~ Sir David Cox

```{block2, note-thankChrisFrost, type='rmdnote'}
The Generalised Linear Regression lectures were orgainised and taught by Professor [Chris Frost](https://www.lshtm.ac.uk/aboutus/people/frost.chris).
```




## 概率論學派統計推斷要點複習

```{r Session01, child = '09-GLM/Session01.Rmd'}
```


## GLM-Practical 01

```{r Practical01, child = '09-GLM/Practical01.Rmd'}

```


# 廣義線性迴歸入門

```{r Session02, child = '09-GLM/Session02.Rmd'}

```


## GLM-Practical 02


```{r Practical02, child = '09-GLM/Practical02.Rmd'}

```


# 二項分佈數據的廣義線性迴歸模型 logistic regression model

二項分佈數據在醫學研究中很常見，例子有千千萬，下面這些只是作爲拋磚引玉：

1. 心臟搭橋手術和血管成形術兩組病人比較療效時，結果變量可以是：死亡 (是/否)；心肌梗死發作 (是/否)；
2. 機械心臟瓣膜手術結果：成功/失敗；
3. 用小鼠作不同劑量二硫化碳暴露下的毒理學實驗，結果變量是：小鼠死亡 (是/否)；
4. 隊列研究中追蹤對象中出現心肌梗死病例，結果變量是：心肌梗死發作 (是/否)。

## 彙總後/個人 (grouped / individual) 的二項分佈數據

下面的數據，來自某個毒理學實驗，不同劑量的二硫化碳暴露下小鼠的死亡數和總數的數據：

```{r  GLM-0301, echo=FALSE, cache=TRUE}
Insect <- read.table("backupfiles/INSECT.RAW", header =  FALSE, sep ="", col.names = c("dose", "n_deaths", "n_subjects"))
print(Insect)
```

很容易理解這是一個典型的彙總後二項分佈數據 (grouped binary data)。每組不同的劑量，第二列，第三列分別是死亡數和實驗總數。另外一種個人二項分佈數據 (individual binary data) 的形式是這樣的：

```{r  GLM-0302, echo=FALSE, cache=TRUE}
dose <- c(rep("49.06", 10), rep("." , 3))
death <- c(rep(1, 6), rep(0,4), rep(".", 3))
data.frame(dose, death)
```
個人二項分佈數據其實就是把每個觀察對象的事件發生與否的信息都呈現出來。通常個人二項分佈數據又被稱爲**伯努利數據**，分組型的二項分佈數據被稱爲**二項數據**。兩種表達形式，但是存儲的是一樣的數據。

## 二項分佈數據的廣義線性迴歸模型

而所有的 GLM 一樣，二項分佈的 GLM 包括三個部分：

1. 因變量的分佈 Distribution：因變量應相互獨立，且服從二項分佈 <br> $$\begin{aligned} Y_i &\sim \text{Bin}(n_i, \pi_i), i = 1, \cdots, n \\ E(Y_i) &= \mu_i = n_i\pi_i\end{aligned}$$
2. 線性預測方程 Linear predictor：第 $i$ 名觀測對象的預測變量的線性迴歸模型 <br> $$\eta_i = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}$$
3. 鏈接方程 Link function：鏈接方程連接的是 $\mu_i = n\pi_i$ 和線性預測方程。一個二項分佈因變量數據，可以有許多種鏈接方程：
    - $\mathbf{logit}:$ $$\text{logit}(\pi) = \text{ln}(\frac{\pi}{1-\pi})$$
    - $\mathbf{probit}:$ $$\text{probit}(\pi) = \Phi^{-1}(\pi)$$
    - $\mathbf{complementary\; log-log}:$ $$\text{cloglog}(\pi) = \text{ln}\{ - \text{ln}(1-\pi) \}$$
    - $\mathbf{log:}$ $$\text{log}(\pi) = \text{ln}(\pi)$$

## 注 {#logit-or-log}

1. 概率鏈接方程 $\text{probit}$，$\Phi$ 被定義爲標準正態分佈的累積概率方程 (Section \@ref(standardNormal))： $$\Phi(z) = \text{Pr}(Z \leqslant z), \text{ for } Z\sim N(0,1)$$
2. 二項分佈數據的標準參數 (canonical parameter) $\theta_i$ 的標準鏈接方程是 $\theta_i = \text{logit}(\pi_i)$。
3. $\text{logit, probit, complementary log-log}$ 三種鏈接方程都能達到把閾值僅限於 $0 \sim 1$ 之間的因變量概率映射到線性預測方程的全實數閾值 $(-\infty,+\infty)$ 的目的。但是最後一個 $\text{log}$ 鏈接方程只能映射全部的非零負實數 $(-\infty,0)$。
4. $\text{logit, probit}$ 鏈接方程都是以 $\pi= 0.5$ 爲對稱軸左右對稱的。但是 $\text{cloglog}$ 則沒有對稱的性質。
5. 鏈接方程 $\text{log}$ 具有可以直接被解讀爲對數危險度比 (log Risk Ratio) 的優點，所以也常常在應用中見到。對數鏈接方程還有其他的優點 (非塌陷性 non-collapsibility)，但是它的最大缺點是，有時候利用這個鏈接方程的模型無法收斂 (converge)。
6. $\text{logit}$ 鏈接方程是我們最常見的，也最直觀易於理解。利用這個鏈接方程擬合的模型的迴歸係數能夠直接被理解爲對數比值比 (log Odds Ratio)。
7. 如果是個人數據 (individual data)，那麼 $n_i = 1$，$i$ 是每一個觀測對象的編碼。那麼 $Y_i = 0\text{ or }1$，代表事件發生或沒發生/成功或者失敗。如果是分組數據 (grouped data)，$i$ 是每個組的編號，$n_i$ 指的是第 $i$ 組中觀測對象的人數，$Y_i$ 是第 $i$ 組的 $n$ 名對象中事件發生的次數/成功的次數。


------------------------

### Exercise. Link functions.

推導出鏈接參數分別是

1) $\text{log}$
2) $\text{logit}$
3) $\text{complementary log-log}$

時，用參數 $\alpha, \beta_1, \cdots, \beta_p$ 表達的參數 $\pi_i=?, E(Y_i)=\mu_i=?$

**解**

1) $\text{log}$
$$
\begin{aligned}
\text{ln}(\pi_i) & = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i & = e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}} \\
            \mu_i & = n_i\pi_i = n_i e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}
\end{aligned}
$$


2) $\text{logit}$

$$
\begin{aligned}
\text{logit}(\pi_i) & = \text{ln}(\frac{\pi_i}{1-\pi_i})  \\
                    & = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i   & = \frac{e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}} \\
              \mu_i & = \frac{n_i e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}
\end{aligned}
$$


3) $\text{complementary log-log}$

$$
\begin{aligned}
\text{cloglog}(\pi_i) & = \text{ln}\{ - \text{ln}(1-\pi) \} \\
                      & = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i     & = 1 - e^{-e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}} \\
            \mu_i     & = n_i\pi_i = n_i(1-e^{-e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}})
\end{aligned}
$$

----------------------------------

## 邏輯迴歸模型迴歸係數的實際意義

邏輯迴歸 (logistic regression) 的模型可以寫成是

$$
\text{logist}(\pi_i) = \text{ln}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}
$$

假如觀察對象 $j$ 和 $i$ 兩人中，其餘的預測變量都相同，二者之間有且僅有最後一個預測變量相差一個單位：

$$
\begin{aligned}
\text{logit}(\pi_j) & = \text{ln}(\frac{\pi_j}{1-\pi_j}) = \alpha + \beta_1 x_{j1} + \beta_2 x_{j2} + \cdots + \beta_p x_{jp} \\
\text{logit}(\pi_i) & = \text{ln}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\text{Because they are} & \text{ in the same model share the same parameters, and } \\
x_{jp} & = x_{ip} + 1\\
\Rightarrow \text{logit}(\pi_j) - \text{logit}(\pi_i) & = \beta_p (x_{jp} + 1 - x_{jp}) = \beta_p \\
\Rightarrow \beta_p & =  \text{ln}(\frac{\pi_j}{1-\pi_j})  -  \text{ln}(\frac{\pi_i}{1-\pi_i})  \\
                    & = \text{ln}(\frac{\frac{\pi_j}{1-\pi_j}}{\frac{\pi_i}{1-\pi_i}}) \\
                    & = \text{ln}(\text{Odds Ratio})
\end{aligned}
$$

所以迴歸係數 $\beta_p$ 可以被理解爲是 $j$ 與 $i$ 相比較時的對數比值比 log Odds Ratio。我們只要對迴歸係數求反函數，即可求得比值比。

## 邏輯迴歸實際案例 {#BSEinfection}

一組數據如下：

其中，牲畜來自兩大羣 (group)；每羣有五個組的牲畜被飼養五種不同濃度的飼料 (dfactor)；每組牲畜我們記錄了牲畜的總數 (cattle) 以及感染了瘋牛病的牲畜數量 (infect)：

```{r  GLM-0303, echo=FALSE, cache=TRUE}
group <- c(1,1,1,1,1,2,2,2,2,2)
dfactor <- c(1,2,3,4,5,1,2,3,4,5)
cattle <- c(11,10,12,11,12,10,10,12,11,10)
infect <- c(8,7,5,3,2,10,9,8,6,4)

Cattle <- data.frame(group, dfactor, cattle, infect)
print(Cattle)
```

### 分析目的

通過對本數據的分析，回答如下的問題：

1. 考慮了牲畜來自兩羣以後，不同的飼料 (dfactor) 是否和感染瘋牛病有關？
2. 兩羣牲畜之間，飼料和瘋牛病感染之間的關係是否不同？

### 模型 1 飼料 + 羣

$$
\begin{aligned}
\text{Assume } Y_i & \sim \text{Bin} (n_i, \pi_i) \\
\text{logit}(\pi_i) & = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2}
\end{aligned}
$$

```{r  GLM-0304, message=FALSE, cache=TRUE}
Model1 <- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor, family = binomial(link = logit), data = Cattle)
summary(Model1)
epiDisplay::logistic.display(Model1)
```

於是，我們可以寫下這個邏輯迴歸的數學模型：

$$
\begin{aligned}
\text{logit}(\hat\pi_i) & = \text{ln}(\frac{\hat\pi_i}{1-\hat\pi_i})  = \hat\alpha + \hat\beta_1 x_{i1} + \hat\beta_2 x_{i2} \\
                        & = 2.1310 - 0.7874 \times \text{dfactor} + 1.3059 \times \text{group}
\end{aligned}
$$

**解讀這些參數估計的意義**

- 截距 $\hat\alpha = 2.1310$ 的含義是，當 $x_{1}, x_{2}$ 都等於零，i.e. 飼料濃度 0，在第一羣的那些牲畜感染瘋牛病的**對數比值 (log-odds)**；
- 斜率 $\hat\beta_1 = -0.7874$ 的含義是，當牲畜羣不變時，飼料濃度每增加一個單位，牲畜感染瘋牛病的**對數比值的估計變化量 (estimated increase in log odds of infection)**；
- 迴歸係數 $\hat\beta_2 = 1.3059$ 的含義是，當飼料濃度不變時，兩羣牲畜之間感染瘋牛病的**對數比值比 (log-Odds Ratio)**，所以第二羣牲畜比第一羣牲畜感染瘋牛病的比值比的估計量，以及 $95\%\text{CI}$ 的計算方法就是：<br>  $$\begin{aligned} \text{exp}(\hat\beta_2) & = \text{exp}(1.3059) = 3.69,\\ \text{ with 95% CI: } & \text{exp}(\hat\beta_2 \pm 1.96\times \text{Std.Error}_{\hat\beta_2}) \\  & = (1.48, 9.19) \end{aligned}$$

### 模型 2 增加交互作用項 飼料 $\times$ 羣

飼料濃度與瘋牛病感染之間的關係，是否因爲牲畜所在的 “羣” 不同而發生改變？

定義增加了飼料和羣交互作用項的邏輯迴歸模型：

$$
\text{logit}(\pi_i) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i1}\times x_{i2}
$$


```{r  GLM-0305, cache=TRUE}
Model2 <- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor + factor(group)*dfactor, family = binomial(link = logit), data = Cattle)
summary(Model2)
epiDisplay::logistic.display(Model2)
```

從輸出的報告來看，增加了交互作用項以後，在第一羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 是

$$
\text{exp}(-0.7051) = 0.49
$$

在第二羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 變成了

$$
\text{exp}(-0.7051 - 0.2058) = 0.40
$$

通過對 $\hat\beta_3 = 0$ 的假設檢驗，就可以推斷飼料濃度和感染瘋牛病之間的關係是否因爲不同牲畜 “羣” 而不同。所以上面的報告中也已經有了交互作用項的檢驗結果 $p = 0.584$，所以，此處可以下的結論是：沒有足夠的證據證明交互作用存在。

## GLM-Practical 03

數據來自一個毒理學實驗，該實驗中 8 組昆蟲在不同濃度的二硫化碳下暴露四個小時，實驗的目的是研究二硫化碳劑量和昆蟲死亡率之間的關系。

### 昆蟲的死亡率

```{r GLM-exe-3-1, echo=TRUE, cache=TRUE}
Insect <- read.table("backupfiles/INSECT.RAW", header =  FALSE, sep ="", col.names = c("dose", "n_deaths", "n_subjects"))
print(Insect)
```

1. 計算每組實驗濃度下死亡昆蟲的比例

```{r GLM-exe-3-2, echo=TRUE, cache=TRUE}
Insect <- Insect %>%
  mutate(p = n_deaths/n_subjects)
print(Insect)
```

2. 將濃度和死亡比例做散點圖

```{r GLM-exe-3-3, echo=TRUE, cache=TRUE, fig.asp=.7, fig.width=6, fig.cap='Scatter plot of CS2 dose and proportion killed.', fig.align='center', out.width='80%', message=FALSE, warning=FALSE}
ggplot(Insect, aes(x = dose, y = p)) +
  geom_point()+
  scale_x_continuous(breaks = seq(50, 75, by = 5)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2)) +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "CS2 dose (mg/L)", y = "Proportion killed")  +
  theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank())
```

這裏如果使用**線性回歸模型是不合適的**，這是因爲:

- 散點圖提示濃度和死亡比例之間不是線性關系;
- “比例”這一數據被局限在 (0,1) 範圍之內，線性回歸的結果變量不會滿足這個條件;
- 觀察數據本身的方差不齊，也就是每個觀察點(死亡比例)的變化程度無法保證是相同的。

3. 計算死亡比例的對數比值比 (log-odds)，再作相同的散點圖，你會得出什麼樣的結論？

```{r GLM-exe-3-4, echo=TRUE, cache=TRUE, fig.asp=.7, fig.width=6, fig.cap='Scatter plot of CS2 dose and log-odds of proportion killed.', fig.align='center', out.width='80%', message=FALSE, warning=FALSE}
Insect <- Insect %>%
  mutate(log_odds = log(p / (1-p)))

ggplot(Insect, aes(x = dose, y = log_odds)) +
  geom_point()+
  scale_x_continuous(breaks = seq(50, 75, by = 5)) +
  scale_y_continuous(breaks = seq(-2, 4, by = 1)) +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "CS2 dose (mg/L)", y = "Log odds of proportion killed")  +
  theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank())
```


死亡比例的對數比值比和二硫化碳濃度之間更加接近線性關系。

4. 寫下此模型的數學表達式，你的表達式必須指明數據的分布，線性預測方程，和鏈接方程三個部分。用 R 擬合你寫下的模型。

**解**

本數據中，隨機變量是每組昆蟲中死亡的個數。用 $Y_i$ 標記第 $i$ 組昆蟲中死亡昆蟲數量，$d_i$ 表示第 $i$ 組昆蟲被暴露的二硫化碳濃度。對於所有的廣義線性回歸模型來說，它都由三個部分組成:
1) 反應量分布 the response distribution; 2) 鏈接方程 link function; 3) 線性預測方程 linear predictor.

反應量分布:

$$
Y_i \sim \text{Bin}(n_i, \pi_i),i = 1, \cdots, 8
$$

$Y_i$ 的期望值是 $\mu_i$ 的話，鏈接方程是

$$
\eta_i = \log(\frac{\mu_i}{n_i - \mu_i}) = \log(\frac{\pi_i}{1- \pi_i}) = \text{logit}(\pi_i)
$$

線性預測方程是

$$
\eta_i = \beta_0 + \beta_1 d_i
$$

用 R 來擬合這個模型:

```{r  GLM-exe-3-5, echo=TRUE, cache=TRUE}
Model1 <- glm(cbind(n_deaths, n_subjects - n_deaths) ~ dose, family = binomial(link = logit), data = Insect)
summary(Model1)
```


1. 計算 CS~2~ 在 55mg/l 時該模型預測的昆蟲死亡概率是多少。

$$
\text{logit}(\hat\pi_i) = -14.09 + 0.2366\times55 \\
\Rightarrow \hat\pi_i = \frac{\exp(-14.09 + 0.2366\times55)}{1+\exp(-14.09 + 0.2366\times55)} = 0.254
$$

2. 計算昆蟲死亡比例達到50%的CS~2~濃度(LD50)。

當死亡比例達到一半時， $\hat\pi = 0.5 \Rightarrow \text{logit}(\hat\pi) = 0$

$$
0 = -14.09 + 0.2366 \times \text{LD50} \\
\Rightarrow \text{LD50} = 59.5 \text{mg/l}
$$

3. 有證據證明昆蟲的死亡率隨着 CS~2~ 濃度的增加而升高嗎？

有極強的證據證明昆蟲死亡率隨着 CS~2~ 濃度增加而升高 $(z = 11.65, P < 0.001, \text{Wald test})$。

4. 將參數轉換成比值比，並解釋其實際含義。

CS~2~ 濃每增加 1 個單位 (1 mg/l)，昆蟲死亡率的比值比是 $\exp(0.2366) = 1.27$，95% 信賴區間下限: $\exp(0.2366 - 1.96\times0.0203) = 1.22$，上限: $\exp(0.2366 + 1.96\times0.0203) = 1.32$。

下面是在 R 裏計算的 OR 及其對應的信賴區間:
```{r GLM-exe-3-6, echo=TRUE, cache=TRUE}
epiDisplay::logistic.display(Model1)
```

5. 提取模型中擬合值 fitted value

```{r GLM-exe-3-7, echo=TRUE, cache=TRUE}
# the fitted values relate to the probability of the deaths in each group
Model1$fitted.values
# to calculate the counts of numbers of deaths in each group
Model1$fitted.values * Insect$n_subjects
```

6. 把模型擬合的概率和觀測概率放在同一個散點圖中比較:

```{r GLM-exe-3-8, echo=FALSE, cache=TRUE, fig.asp=.7, fig.width=6, fig.cap='Observed (circles) and fitted (triangles) proportions are generally similar, with differences greatest in the third and fourth dose groups.', fig.align='center', out.width='80%', message=FALSE, warning=FALSE}
Insect$fitval <- Model1$fitted.values
# shapes  <- c("s1" = 16, "s2" = 17)

Insect_long <- Insect[,-5] %>%
  gather(Fitted, probability, -dose, -n_deaths, -n_subjects) %>%
      arrange(Fitted, dose, n_subjects, n_deaths)


ggplot(Insect_long, aes(x = dose, y = probability, shape = Fitted)) +
  geom_point(size = 4) +  scale_shape(solid = FALSE)+
  # geom_point(aes(y = p), shape =1 , size = 4)+
  # geom_point(aes(y = fitval), shape = 2, size = 4) +
  scale_x_continuous(breaks = seq(50, 75, by = 5)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2)) +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "CS2 dose (mg/L)", y = "Proportion killed")  +
  theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank()) +
  scale_shape_manual(name = "", values = c(1,2),
                     labels = c("Obeserved", "Fitted")) +
    theme(plot.subtitle = element_text(vjust = 1),
  plot.caption = element_text(vjust = 1),
  legend.position = "bottom", legend.direction = "horizontal")
```

7. 現在計算一個新的濃度值 dose2 = dose^2^。這個新的變量用於分析是否模型中使用濃度平方可以提升模型的擬合優度。1) 用 Wald 檢驗的結果說明濃度平方的回歸系數是否有意義。2) 新模型的擬合值是否有所改善？

```{r GLM-exe-3-9, echo=TRUE, cache=TRUE}
Insect <- Insect %>%
  mutate(dose2 = dose^2)
Model2 <- glm(cbind(n_deaths, n_subjects - n_deaths) ~ dose + dose2, family = binomial(link = logit), data = Insect)
summary(Model2)
```

加入了濃度平方以後，該項本身的 Wald 檢驗結果告訴我們，沒有證據證明濃度和昆蟲死亡比例的對數比值比之間呈拋物線關系。

```{r GLM-exe-3-10, echo=FALSE, cache=TRUE, fig.asp=.7, fig.width=6, fig.cap='Fitted probabilities for each dose from two models', fig.align='center', out.width='80%', message=FALSE, warning=FALSE}
Insect$fitval2 <- Model2$fitted.values
# shapes  <- c("s1" = 16, "s2" = 17, "s3" = 18)

Insect_long <- Insect[,-c(5,7)] %>%
  gather(Fitted, probability, -n_deaths, -n_subjects, -dose) %>%
      arrange(Fitted, dose, n_subjects, n_deaths)


ggplot(Insect_long, aes(x = dose, y = probability, shape = Fitted)) +
  geom_point(size = 4)+ scale_shape(solid = FALSE)+
  # geom_point(aes(y = fitval), shape = 2, size = 4) +
  # geom_point(aes(y = fitval2), shape = 3, size = 4) +
  scale_x_continuous(breaks = seq(50, 75, by = 5)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2)) +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "CS2 dose (mg/L)", y = "Proportion killed")  +
  theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank())  +
  scale_shape_manual(name = "",
                     values = c(1:3),
                     labels = c("Obeserved", "Fitted-quadratic", "Fitted-linear")) + theme(plot.subtitle = element_text(vjust = 1),
  plot.caption = element_text(vjust = 1),
  legend.position = "bottom", legend.direction = "horizontal")
```

加入濃度平方二次項的模型在第三和第四組給出了比一次模型更加接近觀測值的估計。但是這種提升是極爲有限的，且統計學上加入的二次項的回歸系數並無意義。

所以，本數據分析的結論是，有很強的證據證明昆蟲死亡的概率隨着CS~2~ 濃度的升高而升高 (P<0.001)。死亡的比值 (odds)，隨着濃度每升高1個單位 (mg/l) 而升高 27% (95% CI: 22%-32%)。

### 哮喘門診數據

在一項橫斷面研究中，訪問哮喘門診連續達到 6 個月以上的全部患者被一一詢問其目前的用藥情況和症狀。下面的表格總結的是這些患者中，目前使用口服類固醇藥物與否，及患者報告夜間由於哮喘症狀而從睡眠中醒來的次數。

```{r GLM-exe-3-11, echo=FALSE, cache=TRUE}
my_tbl <- tibble::tribble(
  ~Corticosteroids, ~Never, ~Less.than.once.a.week, ~More.than.once.a.week, ~Every.night,
            "User",     27,                     41,                     44,           38,
        "Non-user",     20,                     10,                      8,           22
  )

kable(my_tbl, digits = 3, row.names = FALSE, align = "c",
              format = "html", caption = "Frequency of night waking due to asthma") %>%
 kable_styling(
        bootstrap_options = c("striped", "hover", "condensed"),
        position = "center", full_width = FALSE)
```

下面的 STATA 輸出報告，是對上述數據擬合的邏輯回歸的結果。其中變量 `user` 和 `never` 被編碼爲 0/1，1 代表該患者正在使用口服類固醇藥物，或者從未因爲哮喘而在夜間醒來。變量 `sev` 是患者自己報告的哮喘症狀嚴重程度 (0-3 分，分數越高症狀越嚴重)。


```{r GLM-exe-3-12, echo=FALSE, fig.asp=.7, fig.width=7, fig.align='center', out.width='90%', cache=TRUE}
knitr::include_graphics("img/Selection_125.png")
```


1. 用表格的數據實施了一個總體的卡方檢驗還有一個卡方檢驗的傾向性檢驗。這兩個卡方檢驗的統計量分別是 12.87, 和 0.25。請解釋這兩個統計量的實際含義。

在零假設 -- 使用口服類固醇藥物和夜間因爲哮喘而醒來次數之間沒有關系 -- 條件下，表格總體的卡方檢驗服從 $\chi^2_3$ 分布。查表或者在 R 裏使用

```{r GLM-exe-3-13, echo=TRUE,cache=TRUE}
1-pchisq(12.87, 3)
```

可以知道 p = 0.005。這是極強的反對零假設的證據。

相反，卡方檢驗的傾向性檢驗結果是 p = 0.62，這個結果提示使用類固醇藥物所佔的比例沒有傾向性:

```{r GLM-exe-3-14, echo=TRUE,cache=TRUE}
1-pchisq(0.25, 1)
```

兩個卡方檢驗的顯著不同應是因爲用類固醇藥物的患者比例在 "從不", "低於每周一次"，"多餘每周一次" 中遞增，但是到了最後一組 "每天" 時又下降。傾向性檢驗比起總體的卡方檢驗在關系是單調遞增或者單調遞減時統計學效能更好，但是當關系變得復雜以後，傾向性卡方檢驗變得不再有優勢。傾向性檢驗其實等同於用一個變量 (用藥與否) 和另一個變量 (夜間因爲哮喘醒來次數) 做線性回歸。對於這個表格的數據來說，這是一個 U 型的關系，所以做線性回歸的結果也是會給出沒有意義的 p 值。

2. 利用 STATA 的邏輯回歸報告，能對哮喘的嚴重程度和患者報告夜間從未因爲哮喘醒來(never wake up)之間的關系作出怎樣的結論？

從 STATA 計算的結果來看，該數據提供了極強的證據證明哮喘的嚴重程度和報告從未因哮喘而醒來之間呈負相關。特別地，哮喘嚴重程度爲 2 的患者比 1 的患者報告從未醒來的比值比 (odds ratio) 是 0.077 (95% CI: 0.027, 0.224, p < 0.001); 哮喘嚴重程度爲 3 的患者 比 1 的患者報告醒來的比值比是 0.0128 (95% CI: 0.0022, 0.0738, p < 0.001)。所以，哮喘越嚴重，報告夜裏從未醒來的概率越低。


3. 利用 STATA 的邏輯回歸報告，能對是否使用口服類固醇藥物和報告從未因哮喘而醒來之間的關系作出怎樣的結論？

如果要計算未調整的比值比，我們可以把表格中第2-4列的數據合並，那麼在使用類固醇藥物的患者 (n = 150) 中 27 人報告從未醒來，在不使用類固醇藥物的患者中 (n = 60)，有 20 人報告從未醒來。這樣未調整的比值比就是 $\frac{27 \times 40}{20 \times 123} = 0.44$。STATA 計算的邏輯回歸模型的結果顯示，這一數字在調整了哮喘症狀之後，發生了本質的變化:
$e^{0.815} = 2.26$。雖然調整後的比值比並沒有統計學意義。但是它從小於 1 變成了大於 1，方向上發生了轉變。所以，調整了哮喘嚴重程度之後，數據似乎提示使用類固醇藥物和報告從不在夜間因哮喘醒來的概率呈正相關 (用藥者睡得更好)，但是這個相關性沒有統計學意義，其95%信賴區間很寬。

4. 從這些分析來看，哮喘嚴重程度和是否口服類固醇藥物之間有什麼樣的關系？

因爲用類固醇藥物和報告夜間不曾醒來在調整了哮喘嚴重程度之後從原先的負相關變成了正相關。又因爲哮喘嚴重程度本身和報告夜間不曾醒來之間是負相關，所以，是否口服類固醇藥物和哮喘嚴重程度之間呈正相關，也就是哮喘越嚴重，患者越傾向於使用類固醇藥物。





# 模型比較和擬合優度

我們用數據擬合廣義線性模型時其實有許多不同的目的和意義：

1. 估計某些因素的暴露和因變量之間的相關程度，同時調整其餘的混雜因素；
2. 確定能夠強有力的預測因變量變化的因子；
3. 用於預測未來的事件或者病人的預後等等。

但是一般情況下，我們拿到數據以後不可能立刻就能構建起來一個完美無缺的模型。我們常常會擬合兩三個甚至許多個模型，探索模型和數據的擬合程度，就成爲了比較哪個模型更優於其他模型的硬指標。本章的目的是介紹 GLM 嵌套式模型之間的兩兩比較方法，其中一個模型的預測變量是另一個模型的預測變量的子集。

對手裡的數據構建一個GLM的過程，其實就是在該數據的條件下(given the data)，對模型參數 $\mathbf{\beta}$ 定義其對數似然 (log-likelihood)，並尋找能給出極大值的那一系列極大似然估計 (maximum likelihood estimates, MLE) $\mathbf{\hat\beta}$ 的過程。每次構建一個模型，我們都會獲得該模型對應的極大對數似然，它其實是極爲依賴構建它的觀察數據的，意味着每次觀察數據發生變化，你即使用了相同的模型來擬合相同的GLM獲得的極大似然都會發生變化。所以其實我們並不會十分關心這個極大似然的絕對值大小。我們關心的其實是，當對相同數據，構建了包含不同變量的模型時，極大似然的**變化量**。因爲這個極大似然(或者常被略稱爲對數似然 log likelihood，甚至直接只叫做似然)的變化量本身確實會反應我們思考的模型，和觀察數據之間的擬合程度。一般來說，模型中變量較少的那個 (通常叫做更加一般化的模型 more general model)獲得的似然值和變量較多的那個模型獲得的似然值相比較都會比較小，我們關心的似然值在增加了新變量之後的複雜模型後獲得的**增量**，是否有價值，是否真的改善了模型的擬合度 (whether the difference in log likelihoods is large enough to indicate that the less general model provides a "real" improvement in fit)。

## 嵌套式模型的比較 nested models

假如我們用相同的數據擬合兩個 GLM，$\text{Model 1, Model 2}$。其中，當限制 $\text{Model 2}$ 中部分參數爲零之後會變成 $\text{Model 1}$時， 我們說 $\text{Model 1}$ 是 $\text{Model 2}$ 的嵌套模型。



- 例1：嵌套式模型 I
   <br> 模型 1 的線性預測方程爲 $$\eta_i = \alpha + \beta_1 x_{i1}$$
   <br> 模型 2 和模型 1 的因變量相同 (分佈相同)，使用相同的鏈接方程 (link function) 和尺度參數 (scale parameter, $\phi$)，但是它的線性預測方程爲 $$\eta_i = \alpha + \beta_1 x_{i1} + \beta_2 x_{i1} + \beta_3 x_{i3}$$
   <br> 此時我們說模型 1 是模型 2 的嵌套模型，因爲令 $\beta_2 = \beta_3 = 0$ 時，模型 2 就變成了 模型 1。
- 例2：嵌套式模型 II
   <br> 模型 1 的線性預測方程爲 (此處默認 $x_{i1}$ 是連續型預測變量) $$\eta_i = \alpha + \beta_1 x_{i1}$$
   <br> 模型 2 的線性預測方程如果是 $$\eta_i = \alpha + \beta_1 x_{i1} + \beta_2 x^2_{i1}$$
   <br> 此時我們依然認爲 模型 1 是模型 2 的嵌套模型， 因爲令 $\beta_2 = 0$ 時，模型 2 就變成了 模型 1。


關於嵌套式模型，更加一般性的定義是這樣的：**標記模型 2 的參數向量是 $\mathbf{(\psi, \lambda)}$，其中，當我們限制了參數向量的一部分例如 $\mathbf{\psi = 0}$，模型 2 就變成了 模型 1 的話，模型 1 就是嵌套於 模型 2 的**。所以比較嵌套模型之間的擬合度，我們可以比較較爲複雜的 模型 2 相較 模型 1 多出來的複雜的預測變量參數部分 $\mathbf{\psi}$ 是否是必要的。也就是說，比較嵌套模型哪個更優的情況下，零假設是 $\mathbf{\psi = 0}$。

這是典型的多變量的模型比較，需要用到子集似然比檢驗 \@ref(profile-log-likelihood)，log-likelihood ratio test：

$$
\begin{aligned}
-2pllr(\psi = 0) & = -2\{ \ell_p(\psi=0) - \ell_p(\hat\psi) \} \stackrel{\cdot}{\sim} \chi^2_{df}\\
\text{Where } \hat\psi & \text{ denotes the MLE of } \psi \text{ in Model 2} \\
\text{With } df & = \text{ the dimension of } \mathbf{\psi}
\end{aligned}
$$


$\ell_p(\psi=0)$，其實是 模型 1 的極大對數似然，記爲 $\ell_1$。$\ell_p(\hat\psi)$ 其實是 模型 2 的極大對數似然，記爲 $\ell_2$。所以這個似然比檢驗統計量就變成了：

$$
-2pllr(\psi = 0) = -2(\ell_1-\ell_2)
$$

這個統計量在零假設的條件下服從自由度爲兩個模型參數數量之差的卡方分佈。如果 $p$ 值小於提前定義好的顯著性水平，將會提示有足夠證據證明 模型 2 比 模型 1 更好地擬合數據。

## 嵌套式模型比較實例

回到之前用過的瘋牛病和牲畜羣的數據 \@ref(BSEinfection)。我們當時成功擬合了兩個 GLM 模型，模型 1 的預測變量只有 “飼料”，“羣”；模型 2 的預測變量在模型 1 的基礎上增加二者的交互作用項。並且我們當時發現交互作用項部分並無實際統計學意義 $p = 0.584$。現在用對數似然比檢驗來進行類似的假設檢驗。

先用 `logLik(Model)` 的方式提取兩個模型各自的對數似然，然後計算對數似然比，再去和自由度爲 1 (因爲兩個模型只差了 1 個預測變量) 的卡方分佈做比較：

```{r GLM-0401, cache=TRUE, message=FALSE}
Model1 <- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor, family = binomial(link = logit), data = Cattle)
Model2 <- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor + factor(group)*dfactor, family = binomial(link = logit), data = Cattle)
logLik(Model1)
logLik(Model2)
LLR <- -2*(logLik(Model1) - logLik(Model2))

1-pchisq(as.numeric(LLR), df=1) # p value for the LLR test
```

再和 `lmtest::lrtest` 的輸出結果作比較。

```{r GLM-0402, cache=TRUE,  message=FALSE}
lmtest::lrtest(Model1, Model2)
```

結果跟我們手計算的結果完全吻合。AWESOME !!!

值得注意的是，此時進行的似然比檢驗結果獲得的 p 值，和模型中 Wald 檢驗結果獲得的 p 值十分接近 (0.5801 v.s. 0.584)，這也充分顯示了這兩個檢驗方法其實是漸進相同的 (asymptotically equivalent)。

## 飽和模型，模型的偏差，擬合優度

在簡單線性迴歸中，殘差平方和提供了模型擬合數據好壞的指標 -- 決定係數 $R^2$ (Section \@ref(Rsquare))，並且在 偏 F 檢驗 (Section \@ref(partialF)) 中得到模型比較的應用。

廣義線性迴歸模型中事情雖然沒有這麼簡單，但是思想可以借鑑。先介紹飽和模型 (saturated model) 的概念，再介紹其用於模型偏差 (deviance) 比較的方法。前文中介紹過的嵌套模型之間的對數似然比檢驗，也是測量兩個模型之間偏差大小的方法。

### 飽和模型 saturated model

飽和模型 saturated model，是指一個模型中所有可能放入的參數都被放進去的時候，模型達到飽和，自由度爲零。其實就是模型中參數的數量和觀測值個數相等的情況。飽和模型的情況下，所有的擬合值和對應的觀測值相等。所以，對於給定的數據庫，飽和模型提供了所有模型中最 “完美” 的擬合值，因爲擬合值和觀測值完全一致，所以飽和模型的對數似然，比其他所有你建立的模型的對數似然都要大。但是多數情況下，飽和模型並不是合理的模型，不能用來預測也無法拿來解釋數據，因爲它本身就是數據。

### 模型偏差 deviance {#deviance}

令 $L_c$ 是目前擬合模型的對數似然，$L_s$ 是數據的飽和模型的對數似然，所以兩個模型的對數似然比是 $\frac{L_c}{L_s}$。那麼尺度化的模型偏差 (scaled deviance) $S$ 被定義爲：

$$
S=-2\text{ln}(\frac{L_c}{L_s}) = -2(\ell_c - \ell_s)
$$

值得注意的是，非尺度化偏差 (unscaled deviance) 被定義爲 $\phi S$，其中的 $\phi$ 是尺度參數，由於泊松分佈和二項分佈的尺度參數都等於 1 ($\phi = 1$)，所以尺度化偏差和非尺度化偏差才會在數值上相等。

這裏定義的模型偏差大小，可以反應一個模型擬合數據的程度，偏差越大，該模型對數據的擬合越差。"Deviance can be interpreted as Badness of fit".

**但是，模型偏差只適用於彙總後的二項分佈數據(aggregated)。當數據是個人的二分類數據時 (inidividual binary data)，模型的偏差值變得不再適用，無法用來比較模型對數據的擬合程度。** 這是因爲當你的觀測值 (個人數據) 有很多時，擬合飽和模型所需要的參數個數會趨向於無窮大，這違背了子集對數似然比檢驗的條件。

### 彙總型二項分佈數據 aggregated/grouped binary data

假如，觀察數據是互相獨立的，服從二項分佈的 $n$ 個觀測值: $Y_i \sim Bin(n_i, \pi_i), i=1,\dots,n$。用彙總型的數據表達方法來描述它，那麼獲得的數據就是一個個分類變量在各自組中的人數或者百分比的數據 (如下面的數據所示)。這樣的數據的飽和模型，其實允許了每個分類變量的組中百分比變化 (The saturated model for this data allows the probability of "success" to be different in each group, so that $\tilde{\pi} = \frac{y_i}{n_i}$)。也就是每組的模型擬合後百分比，等於觀察到的百分比。


```{r  GLM-040202, echo=FALSE, cache=TRUE}
Insect <- read.table("backupfiles/INSECT.RAW", header =  FALSE, sep ="", col.names = c("dose", "n_deaths", "n_subjects"))
print(Insect)
```


那麼彙總型二項分佈數據，其飽和模型的對數似然其實就是

$$
\ell_s = \sum_{i = 1}^n\{ \log\binom{n_i}{y_i} + y_i\log(\tilde{\pi_i}) + (n_i - y_i)\log(1 - \tilde{\pi_i}) \}
$$

假設此時我們給這個數據擬合一個非飽和模型，該模型告訴我們每個分類組中的預測百分比是 $\hat\pi_i, i = 1, \dots, n$，那麼這個非飽和模型的對數似然其實是

$$
\ell_c = \sum_{i = 1}^n\{ \binom{n_i}{y_i} + y_i\log(\hat\pi_i) + (n_i - y_i)\log(1-\hat\pi_i)\}
$$


那麼這個非飽和模型的模型偏差 (deviance) 就等於 

$$
\begin{aligned}
S & = -2(\ell_c - \ell_s) \\
  & = 2\sum_{i = 1}^n\{ y_i\log(\frac{\tilde{\pi_i}}{\hat\pi_i}) + (n_i - y_i)\log(\frac{1-\tilde{\pi_i}}{1-\hat\pi_i}) \}
\end{aligned}
$$

從上面這個表達式不難看出，模型偏差值的大小，將會隨着模型預測值的變化而變化，如果它更加接近飽和模型的預測值 (飽和模型的預測值其實就等於觀測值)，那麼模型的偏差就會比較小。如果你的彙總型數據擬合了你認爲合適的模型以後，你發現它的模型偏差值很大，那麼就意味着你的模型預測值其實和觀測值相去甚遠，模型和觀測值的擬合度應該不理想。對於彙總型數據來說，模型偏差值，其實等價於將你擬合的模型和飽和模型之間做子集對數似然比檢驗 (profile log-likelihood ratio test)。漸進來說 (asymptotically)，這個子集對數似然比檢驗的結果，會服從自由度爲 $n-p$ 的 $\chi^2$ 分佈，其中 $n, p$ 分別是飽和模型和你擬合的模型中被估計參數的個數。


## 個人數據擬合模型的優度檢驗 {#gof}

在上文中已經提到了，當你的數據不再是彙總型二項分佈數據，而是個人二項分佈數據 (individual binary data) 時，模型偏差 (deviance) 無法用來評價你建立的模型。這樣的數據其實比彙總型二項分佈數據更加常見，當模型中一旦需要加入一個連續型變量時，數據就只能被表達爲個人二項分佈數據。對於個人二項分佈數據模型擬合度比較，最常用的方法是 [@hosmer1980goodness] 提出的模型擬合優度檢驗法 (goodness of fit)。該方法的主要思想是，把個人二項分佈數據模型獲得的個人預測值 (model predicted probabilities) $\hat\pi_i$ 進行人爲的分組，把預測值數據強行變成彙總型二項分佈數據，那麼觀測值的樣本量即使增加到無窮大，也不會使得模型中組別增加到無窮大，從而可以規避

在 R 裏面，進行邏輯迴歸模型的擬合優度檢驗的自定義方程如下，參考[網站](http://data.princeton.edu/wws509/r/c3s8.html)：

```{r  GLM-0403, cache=TRUE}
hosmer <- function(y, fv, groups=10, table=TRUE, type=2) {
 # A simple implementation of the Hosmer-Lemeshow test
   q <- quantile(fv, seq(0,1,1/groups), type=type)
   fv.g <- cut(fv, breaks=q, include.lowest=TRUE)
   obs <- xtabs( ~ fv.g + y)
   fit <- cbind( e.0 = tapply(1-fv, fv.g, sum), e.1 = tapply(fv, fv.g, sum))
   if(table) print(cbind(obs,fit))
   chi2 <- sum((obs-fit)^2/fit)
   pval <- pchisq(chi2, groups-2, lower.tail=FALSE)
   data.frame(test="Hosmer-Lemeshow",groups=groups,chi.sq=chi2,pvalue=pval)
 }
```

```{r lbw, cache=TRUE}
# lbw <- read_dta("http://www.stata-press.com/data/r12/lbw.dta")
lbw <- read_dta(file = "backupfiles/lbw.dta")
lbw$race <- factor(lbw$race)
lbw$smoke <- factor(lbw$smoke)
lbw$ht <- factor(lbw$ht)
Modelgof <- glm(low ~ age + lwt + race + smoke + ptl + ht + ui, 
                data = lbw, family = binomial(link = logit))
hosmer(lbw$low, fitted(Modelgof))
hosmer(lbw$low, fitted(Modelgof), group=5)
```

## GLM Practical 04

### 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。

1. 重新讀入昆蟲數據，擬合前一個練習中擬合過的模型，使用 `glm()` 命令。

```{r GLM-prac04-01, cache=TRUE}
Insect <- read.table("backupfiles/INSECT.RAW", header =  FALSE, sep ="", col.names = c("dose", "n_deaths", "n_subjects"))
# print(Insect)
Insect <- Insect %>% 
  mutate(p = n_deaths/n_subjects)

Model1 <- glm(cbind(n_deaths, n_subjects - n_deaths) ~ dose, 
              family = binomial(link = logit), data = Insect)
summary(Model1); jtools::summ(Model1, digits = 6, confint = TRUE, exp = TRUE)
```

2. 根據上面模型輸出的結果，檢驗是否有證據證明該模型對數據的擬合不佳。

上面模型擬合的輸出結果中，可以找到最下面的模型偏差值的大小和相應的自由度： `Residual deviance:   4.6155  on 6  degrees of freedom`。如果我們要檢驗該模型中假設的前提條件之一--昆蟲死亡的對數比值 (on a log-odds scale) 和藥物濃度 (dose) 之間是線性關係（或者你也可以說，檢驗是否有證據證明該模型對數據擬合不佳），我們可以比較計算獲得的模型偏差值在自由度為 6 的卡方分布 ($\chi^2_6$) 中出現的概率。這裡自由度 6 是由 $n - p = 8 - 2$ 計算獲得，其中 $n$ 是數據中觀察值個數，$p$ 是模型中估計的參數的個數。檢驗方法很簡單：

```{r GLM-prac04-02, cache=TRUE}
1 - pchisq(4.6155, df = 6)
```

所以，檢驗的結果，P 值就是 0.594，沒有任何證據反對零假設（模型擬合數據合理）。

3. 試比較兩個模型對數據的擬合效果孰優孰劣：模型1，上面的模型；模型2，加入劑量的平方 (dose^2^)，作為新增的模型解釋變量。嵌套式模型之間的比較使用的是似然比檢驗法 (profile likelihood ratio test)，試着解釋這個比較方法和 Wald 檢驗之間的區別。

```{r GLM-prac04-03, cache=TRUE}
Model2 <- glm(cbind(n_deaths, n_subjects - n_deaths) ~ dose + I(dose^2), family = binomial(link = logit), data = Insect)
summary(Model2)

anova(Model1, Model2)
# P-value for model comparison
1 - pchisq(1.43, df = 1)
```

兩個模型比較的結果表明，無證據反對零假設（只用線性關係擬合數據是合理的），也就是說增加劑量的平方這一新的解釋變量並不能提升模型對數據的擬合程度。仔細觀察模型2的輸出結果中，可以發現 `I(dose^2)` 項的 Wald 檢驗結果是 `p = 0.24`，十分接近似然比檢驗的結果。因為它們兩者是漸近相同的 (asymptotically equivalent)。


### 低出生體重數據

1. 讀入該數據，試分析數據中和低出生體重可能相關的變量：

```{r GLM-prac04-04, cache=TRUE, warning=FALSE, message=FALSE}
lbw <- read_dta("backupfiles/lbw.dta")
head(lbw)
```

2. 擬合一個這樣的邏輯回歸模型：結果變量使用低出生體重與否 `low`，解釋變量使用母親最後一次月經時體重 `lwt` (磅)。

```{r GLM-prac04-05, cache=TRUE, warning=FALSE, message=FALSE}
M <- glm(low ~ lwt, data = lbw, family = binomial(link = logit))
summary(M)
logistic.display(M)
```

3. 利用 `lowess` 平滑曲線作圖，評價在 logit 單位上，`lwt` 和 `low` 之間是否可以認為是線性關係。


```{r  GLM-prac04-06,warning=FALSE, message=FALSE, cache=TRUE, echo=TRUE, fig.width=7, fig.height=5, fig.cap="The loess plot of the observed proportion with low birth weight against mother's weight at last menstural period. Span = 0.6", fig.align='center', out.width='100%'}
pi <- M$fitted.values

# with(lbw, scatter.smooth(lwt, pi, pch = 20, span = 0.4, lpars =
#                  list(col = "blue", lwd = 3, lty = 1), col=rgb(0,0,0,0.004),
#                  xlab = "Mother's weight at last menstural period (lbs)",
#                  ylab = "Logit(probability) of being low birth weight",
#                  frame = FALSE))

plot(lbw$lwt, lbw$low, main="Lowess smoother plot\n of the prob of having a low brith weight baby", 
     xlab = "Weight at at last menstural period (lbs)", 
     ylab = "Probability")
lines(lowess(lbw$lwt, lbw$low, f = 0.7), col=2, lwd = 2)
points(lbw$lwt, pi)
```


Lowess 平滑曲線提示模型的擬合值(`fitted.values`)有一些變動，由於樣本採樣方法等原因，這是無法避免的。但是總體來說，擬合值和平滑曲線基本在同一個步調上，從該圖來看，認為母親的最後一次月經時體重和是否生下低出生體重兒的概率的 logit 之間的關係是線性的應該不是太大的問題。

# 計數型因變量 Count outcomes 

計數型變量在臨牀醫學/流行病學研究中也十分常見，下面是一些例子：

1. 某個呼吸科診所的患者中，每個人在過去一個月中哮喘發作的次數；
2. 癲癇患者在過去一年中癲癇發作次數；
3. 接受腦部 CT 掃描的患者中，每個人被診斷出顱內腫瘤個數。

最早的泊松模型可以追溯到普魯士騎兵連中被馬蹄踢死士兵的人數模型。

## 泊松 GLM

一個計數型的隨機變量，只能取大於等於零的正整數，$0,1,\cdots$。泊松隨機變量可以理解爲產生於發生在一段時間內的事件次數。泊松模型可以用於計數型數據的迴歸模型的構建：

$$
\begin{aligned}
Y &\sim \text{Po}(\mu) \\
\text{P} (Y = y) & = \frac{\mu^y e^{-\mu}}{y!}
\end{aligned}
$$

所以，一個泊松迴歸，默認的前提是因變量 $Y$ 服從一個以預測變量 $x_1, \cdots, x_p$ 爲條件的泊松分佈。其標準鏈接方程是 $\theta=\text{log}(\mu)$。

$$
\begin{aligned}
Y_i & \sim \text{Po}(\mu_i) \\
\text{log}(\mu_i) & = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
\end{aligned}
$$

觀測對象 1，用模型中全部的預測變量 $\mathbf{x_1}=(x_{11},\cdots,x_{1p})$ 計算獲得的擬合值，和另一個觀測對象 0 的擬合值之比爲：

$$
\begin{aligned}
  & \frac{\text{exp}(\alpha + \beta_1 x_{11} + \cdots + \beta_p x_{1p})}{\text{exp}(\alpha + \beta_1 x_{01} + \cdots + \beta_p x_{0p})} \\
= & \exp(\beta_1(x_{11}-x_{01}) + \cdots + \beta_p(x_{1p} - x_{0p}))
\end{aligned}
$$

其中，

- 線性預測方程 linear predictor 中的截距 $\alpha$ 的含義是，**當所有的預測變量均等於零 $\mathbf{x_1} = 0$** 時，**因變量 $Y$ 的均值之對數**。
- $\beta_1$ 的含義是，**其餘預測變量保持不變時，預測變量 $x_1$ 每增加一個單位時，因變量變化量的對數**。
- 迴歸係數的指數 (自然底數) 大小，可以被理解爲是**率比 (rate ratio)** (詳見下一章率的 GLM)。


## 泊松迴歸實例

下列數據來自 [UCLA 的統計學網站](https://stats.idre.ucla.edu/r/dae/poisson-regression/)。數據內容是某高中全部學生，獲獎的次數。預測變量包括，1) 獲獎種類 “一般 General”，“學術類 Academic”，“技能類 Vocational”；和所有學生期末數學考試分數。



```{r  GLM-0404, cache=TRUE, cache=TRUE}
p <- read_csv("backupfiles/poisson_sim.csv")
p <- within(p, {
  prog <- factor(prog, levels=1:3, labels=c("General", "Academic",
                                                     "Vocational"))
  id <- factor(id)
})
summary(p)
```

下面的代碼擬合因變量爲獲獎次數，預測變量爲獲獎種類 (分類) 和數學成績 (連續) 的泊松分佈，泊松分佈默認的鏈接方程就是 $\text{log}$，所以你可以像第一行那樣把鏈接方程部分省略。結果也是一樣的。

```{r  GLM-0405, cache=TRUE}
m1 <- glm(num_awards ~ prog, family="poisson", data=p)
m2 <- glm(num_awards ~ prog, family=poisson(link = log), data=p)
summary(m1); summary(m2)
```

輸出結果的迴歸係數部分，

- 該學校學生獲得學術類獎項的平均次數和獲得一般獎項的平均次數的比值是 $\text{exp}(1.6094) = 4.999$，所以獲得的學術類獎平均次數要高於一般獎次數 $390\%$；
- 獲得技能類獎的平均次數和一般獎平均次數的比值是 $\text{exp}(0.1823) = 1.199$，也就是高出了 $19.9\%$；
- 該校學生獲得一般類獎的次數平均每人是 $\text{exp}(-1.6094) = 0.20$ 次；
- 該校學生獲得學術獎的次數平均每人是 $\text{exp}(-1.6094 + 1.6094) = 1$ 次；(一人一次夠流弊)
- 該校學生獲得技能類獎的次數平均每人是 $\text{exp}(-1.6094 + 0.182) = 0.24$ 次。


看來該校師生很重視學術。

當然也可以用下面定義的函數來幫助我們計算上面這些數值，及其信賴區間。

```{r GLM-0406, cache=TRUE}
glm.RR <- function(GLM.RESULT, digits = 2) {

    if (GLM.RESULT$family$family == "binomial") {
        LABEL <- "OR"
    } else if (GLM.RESULT$family$family == "poisson") {
        LABEL <- "RR"
    } else {
        stop("Not logistic or Poisson model")
    }

    COEF      <- stats::coef(GLM.RESULT)
    CONFINT   <- stats::confint(GLM.RESULT)
    TABLE     <- cbind(coef=COEF, CONFINT)
    TABLE.EXP <- round(exp(TABLE), digits)

    colnames(TABLE.EXP)[1] <- LABEL

    TABLE.EXP
}
```

```{r  GLM-0407, cache=TRUE,  message=FALSE}
glm.RR(m1)
```

## 過度離散 overdispersion

泊松分佈的前提條件之一是，方差和均值相等。這是一個**非常強的假設**，很多計數型數據其實是無法滿足這個條件的。許多時候 (包括上面的例子也是) 方差要大於或者小於均值：

```{r  GLM-0408, cache=TRUE}
epiDisplay::summ(p$num_awards[p$prog == "Academic"], graph = FALSE)
epiDisplay::summ(p$num_awards[p$prog == "General"], graph = FALSE)
epiDisplay::summ(p$num_awards[p$prog == "Vocational"], graph = FALSE)
```

試想一下，實際的數據中其實是經常出現這樣的違反泊松分佈前提的計數型數據的。例如某兩個觀測對象，如果他們二者的線性預測方程給出相等的結果 (他們各自的預測變量可以完全不同)，會被認爲服從相同均值，相同方差的泊松分佈，這顯然是不合理的。例如本章用到的學校學生獲獎的例子，有的學生成績好，那麼獲得學術類獎的平均次數 (及其方差) 自然和成績排在後面的學生不同，強制這樣的兩個學生服從相同均值，相同方差的泊松分佈顯然是不合情理的。手工好的學生，可能更傾向於獲得更多得技能類獎。實際情況下，還有許許多多其他的未知因素會影響學生獲獎的次數，例如家庭教育背景的不同，有些學生鋼琴獲獎多，因爲他每天都去練習彈鋼琴等等，這些都是沒有被收集到的數據。

真實情況應該是這樣的，當有其他的我們不知道的因素存在時，這些因素會導致某些人的均值高於其他人。如果對象 $i$ 的因變量 $Y_i$ 服從均值爲 $\mu_i$ 的泊松分佈，那麼對於所有的 $\mu_i$，其均值 (overall mean) 是 $\mu$，方差 (overall variance) 是 $\sigma^2$。這是一個典型的隨機效應模型 random effect model，我們會在後面的 hierarchical data analysis 再深入討論，但是這裏的重點是，每個觀測對象自己的均值 $\mu_i$，是我們在普通泊松迴歸中忽略掉的隨機共變量 (the effects of omitted covariates)。

所以樣本數據來自的人羣如果共同均值 (或者叫邊際效應均值，marginal mean) 爲 $\mu$：

$$
E(Y_i) = E(E(Y_i | \mu_i)) = E(\mu_i) = \mu
$$

和共同方差 (邊際效應方差) ，需要用到 [總體方差法則 (Law of total variance)](https://en.wikipedia.org/wiki/Law_of_total_variance) 概念：

$$
\begin{aligned}
\text{Var}(Y_i) & = E(\text{Var}(Y_i | \mu_i)) + \text{Var}(E(Y_i | \mu_i)) \\
                & = E(\mu_i) + \text{Var}(\mu_i) \\
                & = \mu + \sigma^2
\end{aligned}
$$

### 過度離散怎麼查？


如果，我們的泊松回歸模型中的共變量全部都是分類型變量，我們可以把觀測值 $Y$ 對每一個分類變量分別作簡單的數據總結，觀察其均值和方差是否可以認為大致相同。但是許多時候模型中不會只有分類型變量。

R 輸出的結果中的 模型偏差 deviance，可以用來初步判斷整體模型的擬合優度。如果模型偏差除以殘差獲得的殘差偏差 (residual deviance) 足夠小，說明擬合的模型跟數據本身比較接近，也就是模型和數據擬合程度較好，反之則提示模型本身具有較高的過度離散 overdispersion。另外，模型偏差由於在個人數據 (individual data) 情況下不適用 (因為模型偏差值就不再服從卡方分佈了)，下面的檢驗結果僅僅只能作為極為微弱的參考證據。此時應該推薦使用 Pearson 的模型擬合檢驗。如果 Pearson 統計量，除以殘差的自由度獲得的值遠大於 1，就提示存在過度離散。



```{r  GLM-0409, cache=TRUE}
with(m1, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))
```

Goodness of fit 檢驗結果 提示本模型**可能存在過度離散**，數據擬合度不理想。值得注意的是如果樣本很大時，模型偏差的檢驗統計量**將不再服從卡方分佈**，應用的時候一定要慎重。

### 負二項式分佈模型 negative binomial model

如果普通泊松迴歸模型擬合數據時，發現數據本身有過度離散的嫌疑，那麼建議使用負二項式分佈模型來重新擬合數據。負二項式分佈模型其實是泊松分佈的擴展版本，即考慮了個體的方差和均值的隨機效應 subject-specific random effect。如果設每個觀測對象的隨機效應部分爲 $a_i$，預測變量爲向量 $\mathbf{x_i} = (x_{i1}, \cdots, x_{ip})$，那麼因變量 $Y_i$ 服從均值爲 $\text{exp}(\beta^T\mathbf{x_i}+a_i)$ 泊松分佈。在負二項式分佈中，個體的隨機效應部分的自然底數的指數 $e^{a_i}$ 其實是服從均值爲 1， 方差爲 $\alpha$ 的[伽馬分佈 (gamma distribution)](https://cosx.org/2013/01/lda-math-gamma-function/)。$\alpha$ 越大，说明过度离散越明显。

接下來用相同的數據，使用負二項式分佈模型在 R 裏作模型的擬合，你就會看到差別：

R 裏擬合負二項式分佈模型的函數 `glm.nb` 在基本包 `MASS` 裏。

```{r  GLM-0410, cache=TRUE, message=FALSE , eval = TRUE}
m1 <- glm.nb(num_awards ~ prog, data = p)
m2 <- glm(num_awards ~ prog, family=poisson(link = log), data=p)
summary(m1)
summary(m2)
```

仔細比較普通泊松分佈迴歸和負二項式分佈迴歸的輸出結果，你會發現

1. 迴歸係數的計算是完全相同的 (由於我們只放了一個簡單的分類型變量作爲預測變量，一般來說泊松迴歸和負二項式分佈迴歸計算的迴歸係數會有些許不同)；
2. 另外一個變化是標準誤的估計量在負二項式分佈模型中明顯變大了，這就是我們放寬了前提條件，允許模型考慮個體的隨機效應的體現。如果泊松模型被數據本身的過度離散影響顯著，那麼泊松迴歸計算獲得的參數標準無是偏低的；
3. 負二項式分佈迴歸的結果最底下出現的 `Theta:  1.723` 部分，它的倒數是前面提到的個體的隨機效應部分 $a_i$ 服從的伽馬分佈的方差 $\alpha$。它是關鍵的離散程度參數 (dispersion parameter)。**在 STATA 裏，如果用 `nbreg` 擬合負二項式分佈迴歸的模型，輸出的結果最底下會有 $\alpha$ 值的報告，注意它和 R 輸出的 `Theta` 結果互爲倒數**。另外，STATA 的輸出結果還會對 $\alpha = 0$ 直接進行檢驗。在 R 裏面則需要給兩個模型分別進行擬合優度檢驗，多數情況下你會發現負二項式分佈迴歸的模型更加擬合數據：

```{r  GLM-0411, cache=TRUE, eval = TRUE}
with(m1, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))
with(m2, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))
```

另一種獲取沒有被低估的迴歸係數的標準誤的方法來自穩健統計學手段。在 R 裏，擬合完普通泊松迴歸以後，用 `sandwich` 包裏的 `vcovHC()` 命令進行穩健的參數誤差估計 (具體說是夾心方差矩陣估計 sandwich estimator of variance)：


```{r  GLM-0412, cache=TRUE, eval = TRUE}
m2 <- glm(num_awards ~ prog, family=poisson(link = log), data=p)
cov.m2 <- vcovHC(m2, type = "HC0")
std.err <- sqrt(diag(cov.m2))
robust.est <- cbind(Estimate= coef(m2), "Robust SE" = std.err,
"Pr(>|z|)" = 2 * pnorm(abs(coef(m2)/std.err), lower.tail=FALSE),
LL = coef(m1) - 1.96 * std.err,
UL = coef(m1) + 1.96 * std.err)
robust.est
```

## GLM Practical 05

在這次練習中，我們來探索幾個不同的計數型數據的模型，進一步探討如何處理過度離散的方法。數據來自Stata的網站，記錄的是美國亞利桑那州醫院的住院時長[數據](http://www.stata-press.com/data/hh3/medpar.dta)。使用如下代碼下載該數據:

```{r GLM-prac05-01, cache=TRUE}
# medpar <- read_dta("http://www.stata-press.com/data/hh3/medpar.dta")
medpar <- read_dta(file = "backupfiles/medpar.dta")
```

我們主要使用的數據是下面這幾列：

| Variable | Description                                    |
|----------|------------------------------------------------|
| `los`    | length of hospital stay, in days               |
| `age`    | Age group                                      |
| `type1`  | Binary variable indicating elective admission  |
| `type2`  | Binary variable indicating urgent admission    |
| `type3`  | Binary variable indicating emergency admission |


1. 分析住院時間長短和年齡及其他共變量之間關係之前，先瞭解一下 `los` 本身的特徵。 首先，計算 `los` 的平均值，及其 [Wald 法的 95% 信賴區間](https://rpubs.com/FJRubio/WCIN)。在怎樣的前提條件下，這個信賴區間可以被認爲有效 (valid)？你認爲這些前提條件在這裏得到滿足了嗎？

```{r GLM-prac05-02, cache=TRUE}
psych::describe(medpar$los)
t.test(medpar$los)$conf.int
```

這裏默認的前提條件是，住院時長 (days) 服從正態分佈。即使住院時長這一數據可能並不100% 服從正態分佈，但是如果樣本量足夠大，那麼該 95% 信賴區間依然可以被認爲近似可以涵蓋95%的可重複實驗的次數。這一結論依據的是中心極限定理。在這裏，住院時長的數據其實分佈的非常的偏，並非正態分佈。但是我們可以認爲由於樣本量接近1500，可以認爲計算獲得的95%信賴區間是漸進有效的。

2. 接下來我們使用 `glm` 命令來估計 `los` 的邊際均值 (marginal mean)，不加任何預測變量。根據你擬合的泊松回歸模型獲得的結果，請思考 `los` 的模型估計 95% 信賴區間是多少。和前一步簡單的估計相比較，他們是否相似或者有怎樣的不同，原因是什麼。你認爲哪種估計更加有意義？

```{r GLM-prac05-03, cache=TRUE}
mA <- glm(los ~ 1, family=poisson(link = log), data=medpar)
jtools::summ(mA, digits = 6, confint = TRUE)
```

根據這個模型的結果，住院時長的均值可以被估計爲 $\exp(2.287896) = 9.854$。但是其95%信賴區間的估計是：

下限爲，$\exp(2.287896 - 1.96\times0.008239) = 9.696$

上限爲，$\exp(2.287896 + 1.96\times0.008239) = 10.014$

我們發現，均值的點估計，和第一步簡單歸納時的結果一致，都是 9.854 天。但是模型估計的95%信賴區間 (9.696, 10.014) 相比 Wald 法的 95% 信賴區間 (9.406, 10.302) 更加精確 (範圍更窄)。當然可以理解爲，當數據本身分佈較偏 (skew) 時，使用泊松模型分析獲得的結果更加可靠且更加有效 (more efficient)。在這個數據中，模型估計的信賴區間和wald法信賴區間之間的差別更加可能是由於住院時長數據本身的過度離散問題導致的。在R裏我們獲得的結果只有殘差離差量 (residual deviance): `Residual deviance: 8901.1  on 1494  degrees of freedom`。如果你用的是 Stata，還可以獲得 Pearson 統計量，以及他們除以自由度以後獲得的數字都顯著地大於1。這說明其實病人住院時長這樣的數據很大程度上有相當大的差異，因爲每個病人各自住院的時間長度更加取決於他們本身患病的程度。**這樣的數據不會是通過泊松分佈可以簡單擬合的，因爲泊松分佈的均值和方差是嚴格相等的。**

```{r GLM-prac05-04, engine='stata', echo=FALSE}
use http://www.stata-press.com/data/hh3/medpar, clear
glm los, family(Poisson) 
```


也就是下面這兩行所提示的內容。

```
## Deviance         =  8901.134077                   (1/df) Deviance =   5.957921
## Pearson          =  11828.70662                   (1/df) Pearson  =   7.917474
```

3. 下面我們在泊松回歸模型中加入不同的入院類型的啞變量，看他們是否和患者住院時長有關。嘗試用醫學文獻的文章寫法描述這個模型的結果。

```{r GLM-prac05-05, cache=TRUE}
mB <- glm(los ~ type2 + type3, family=poisson(link = log), data=medpar)
jtools::summ(mB, digits = 6, confint = TRUE, exp = TRUE)
```

記得模型中省略掉了 `type1` 因爲它被當作參考組 (reference group)。

下面的文獻描述可以用於參考：

There is strong evidence (p < 0.0001) that the length of hospital admission is related to the type of admission. The mean length of stay for elective admission is 8.83 days (95% CI 8.66 to 9.01 days). Urgent admissions are associated with stays that are on average 26.8% (95% CI 21.7% to 32.1%) longer than those resulting from elective admissions. Emergency admissions result in stays that are on average 2.06 (95% CI 1.96 to 2.17) times as long as those from elective admissions. 


值得注意的是，這些結果所依據的泊松回歸模型的前提條件很可能因爲數據本身存在過度離散 (overdispersion) 的問題而無法得到滿足。

4. 在上述模型中如果加入年齡作爲解釋變量，試分析年齡是否可以認爲是住院時長的獨立解釋變量 (獨立於住院形態 type of admission)。


```{r GLM-prac05-06, cache=TRUE}
mC <- glm(los ~ as.factor(age) + type2 + type3, 
          family=poisson(link = log), data=medpar)
jtools::summ(mC, digits = 6, confint = TRUE, exp = TRUE)

lrtest(mC, mB)
```

加入和年齡組作爲預測變量的模型結果如上所示。和沒有加年齡的模型相比較的似然比檢驗 (likelihood ratio test) 結果顯示，如果泊松回歸模型前提得到滿足，那麼有證據證明 (p = 0.018)，在調整了住院形態之後，年齡依然是住院時長獨立的預測變量。

5. 重新對加入年齡的泊松回歸模型加入穩健統計標準誤 (robust standard error) 的估計，獲得新的穩健信賴區間估計。與非穩健信賴區間相比較，你能得出怎樣的結論？


```{r GLM-prac05-07, cache=TRUE}
jtools::summ(mC, digits = 6, confint = TRUE, exp = TRUE, 
             robust = "HC1")
```

可以看到加入了 `robust` 選項之後，並不會改變每個變量的回歸係數的點估計 (point estimates)。但是，可以發現每個變量的回歸係數對應的標準誤發生了較大的變化 -- 信賴區間的範圍都無一例外地變大了。由於使用 `robust = "HC1"` 選項，這裏的標準誤估計不再依據泊松模型的前提條件 -- 泊松分佈的特徵。在 Stata 中擬合相同的模型，我們可以獲得是否有過度離散的指標型數據結果，也就是殘差離差量 (residual deviance) 和 Pearson 統計量，以及他們對各自的自由度之比：

```{r GLM-prac05-08, engine='stata', echo=FALSE}
use http://www.stata-press.com/data/hh3/medpar, clear
glm los type2 type3 i.age, family(Poisson) robust eform
```

可以看到殘差離差量 (residual deviance) 和 Pearson 統計量與各自的自由度之比均顯著大於1。提示該數據有相當程度的過度離散，也就是泊松回歸模型的前提泊松分佈無法得到滿足。而使用了 `robust = "HC1"` (in R) 或者 `robust` (in Stata) 的選項之後，就不再需要這一前提假設。我們也看到穩健信賴區間相較於沒有使用該選項時要不那麼精確，也就是區間範圍都變寬了。

6. 當考慮了過度離散的模型被採納後 `robust` (in Stata)，我們無法再使用似然比檢驗法檢驗年齡是否是住院時長的獨立預測變量。但是我們可以使用 Stata 裏特有的模型擬合之後的 `test` 命令來實施聯合 Wald 檢驗 (joint Wald test) 年齡是否在穩健泊松模型下依然是住院時長的獨立預測變量。試解讀該檢驗結果和之前未考慮過度離散現象時使用的模型的年齡的獨立預測變量檢驗之間有何不同，原因是什麼呢？

```{r GLM-prac05-09, engine='stata', echo=FALSE}
use http://www.stata-press.com/data/hh3/medpar, clear
quietly: glm los type2 type3 i.age, family(Poisson) robust eform
test 2.age = 3.age = 4.age = 5.age = 6.age = 7.age = 8.age = 9.age = 0
```


這個聯合 Wald 檢驗的結果是 `p = 0.8493`。這和之前未考慮數據過度離散時使用的模型時進行的對年齡這一變量的似然比模型檢驗結果大相徑庭 (p = 0.018)。之所以結果相差如此之大，我們相信主要是因爲之前忽略數據過度離散問題的模型其實是錯誤的。而考慮了數據過度離散特徵之後，可以認爲使用了穩健泊松回歸模型之後的聯合 Wald 檢驗結果才是真的值得相信的。

7. 請使用負二項回歸模型 (negative binomial regression model) 來擬合上述模型，先擬合一個不加任何預測變量的負二項回歸模型。請解釋模型結果的下半部分出現的似然比檢驗的意義，和無預測變量的泊松回歸模型結果做一下對比。

在 Stata 裏：
```{r GLM-prac05-10, engine='stata', echo=FALSE}
use http://www.stata-press.com/data/hh3/medpar, clear
nbreg los
```


在 R 裏：
```{r GLM-prac05-11, cache=TRUE}
mD <- glm.nb(los ~ 1, data=medpar)
jtools::summ(mD, digits = 6, confint = TRUE, exp = TRUE)
summary(mD)
```

可以看到在 R 裏最下方出現的是 `Theta` 也就是評價過度離散程度的指標，他和 Stata 的輸出報告中的 `alpha` 互爲倒數。不同的是 Stata 的報告中還對 `alpha = 0` 做了檢驗。檢驗結果提示住院時長這個數據並不服從泊松分佈。也就是實際的住院時長的數據比泊松分佈時的結果的方差要大的多。 (there is more variability than would be expected from a Poisson variable) 其實，簡單對 `los` 分析一下就知道它的樣本均值和樣本方差分別是：（他們相差巨大，不符合泊松分佈的特徵）

```{r GLM-prac05-12, cache=TRUE}
mean(medpar$los) 
var(medpar$los)
```

8. 如果你有興趣，請擬合一個只有住院形態一個預測變量的負二項回歸模型。使用其輸出的結果來計算一下不同住院形態下的平均住院時長。比較模型預測的平均住院時長和觀測到的不同住院形態下的實際住院時長的平均值之間的差別。


在 Stata 裏：
```{r GLM-prac05-13, engine='stata', echo=FALSE}
use http://www.stata-press.com/data/hh3/medpar, clear
nbreg los type2 type3 
```


在 R 裏：
```{r GLM-prac05-14, cache=TRUE}
mE <- glm.nb(los ~ type2 + type3, data=medpar)
jtools::summ(mE, digits = 6, confint = TRUE)
summary(mE)
```

從輸出的分析報告結果來看，模型估計的不同住院形態 (elective, urgent, and emergency) 的平均住院時長分別是 $\exp(2.1782) = 8.83$ 天，$\exp(2.1782 + 0.2373) = 11.20$ 天，$\exp(2.1782 + 0.7253) = 18.24$天。要估算模型的預測方差，可以通過手工計算。已知如果期待值是 $\mu$，那麼其方差是 $\mu(1 + \alpha \mu)$。那麼依據這個公式，就可以估算不同住院形態 (elective, urgent, and emergency) 的住院時長的方差分別是 $8.83 \times (1 + 0.4478 \times 8.83) = 43.74$ days$^2$，$11.2 \times (1 + 0.4478 \times 11.2) = 67.3$ days$^2$，$18.24 \times (1 + 0.4478 \times 18.24) = 167.2$ days$^2$。

和觀測值相比較：

```{r GLM-prac05-15, cache=TRUE}

var(medpar$los[medpar$type1 == 1])
var(medpar$los[medpar$type2 == 1])
var(medpar$los[medpar$type3 == 1])
```

可見，對於前兩種住院形態來說，模型推測的方差和觀測方差還是比較接近的。但是對於第三種住院形態 (emergency)，觀測方差遠遠大於模型推測方差。當然，這可能由於因爲緊急住院的患者人數較低 (n = 96)。也就是說，樣本量太低的組使用該模型推測的方差準確度就比較低。另一種原因值得考慮的就是，負二項回歸模型中使用的 Gamma 隨機效應分佈可能並不適用與本數據 (對於不同住院形態的住院時長可能需要不同的 `alpha`，而不是強迫他們都是相同的)。另外一個被忽視的是，住院時長這一數據其實是只能取正值的數據。然而泊松分佈和負二項分佈本身其實是允許有 0 這樣的數字的。如此一來，或許我們應該把住院時長定義爲允許 0 存在的數字。也就是把住院時長的數據減去1。(number of days from the day of admission)



# 率的廣義線性迴歸 Poisson GLM for rates

## 醫學中的率

前章介紹的事件發生次數，使用的是泊松迴歸。本章介紹同樣利用泊松迴歸，對事件發生率類型數據的泊松迴歸模型。常見的率的數據例如：

- 肺癌發病率
- 工廠職工的死亡率
- 術後後遺症的發生率

下列數據來自英國醫生調查 (British doctors study)，研究的是男性醫生中吸菸與否和冠心病死亡之間的關係。最後一列是每組觀測對象被追蹤的人年 (person-year)。

```{r  GLM-0501, echo=FALSE, cache = TRUE}
agegrp <- c("35-44","45-54","55-64","65-74","75+","35-44","45-54","55-64","65-74","75+")
smokes <- c(rep("Smoker",5), rep("Non-smoker",5))
deaths <- c(32,104,206,186,102,2,12,28,28,31)
pyrs <- c(52407, 43248, 28612, 12663, 5317, 18790, 10673, 5710, 2585, 1462)
BritishD <- data.frame(agegrp, smokes, deaths, pyrs)
print(BritishD)
```

這是一個已經被整理過的數據，我們沒有辦法從這樣的數據還原到每個觀察對象的個人水平數據。冠心病的粗死亡率 (crude death rate) 可以被計算如下表 (忽略年齡分組)，此時默認的前提是死亡事件在追蹤的過程中發生的概率不發生改變。


```{r PoissonRates, echo=FALSE, cache=TRUE}
dt <- read.csv("backupfiles/PoissonRates.csv", header = T)
names(dt) <- c("Group", "Person-years of follow-up", "CHD deaths", "Death Rate per 1000 person-years", "Rate Ratios")
kable(dt, "html",  align = "c", caption = "Death rates due to CHD in smokers and non-smokers, collapsed over age group") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"))
```

## 泊松過程

設 $Y$ 是代表某段時間 $t$ 內**事件發生次數 (死亡)** 的隨機變量。如果可以假設：

- 每次事件的發生，是互相獨立的，即在沒有重疊的時間線上，每個事件的發生是隨機的。
- 在一個無限小的時間段 $\delta t$ 內，事件發生的概率是 $\lambda\times\delta t$，其中 $\delta t \rightarrow 0$。

那麼根據泊松分佈 (Section \@ref(poisson)) 的定義，在這個時間段內，隨機變量 $Y$ 事件發生次數服從泊松分佈：

$$
\begin{aligned}
Y & \sim \text{Po}(\mu) \\
\text{Where } \mu & = \lambda t, \text{ and } \lambda \text{ is the Rate}
\end{aligned}
$$

所以，從泊松過程可以看到，我們關心的參數是事件發生率 $\lambda$。

## 率的模型

既然關心的參數只是發生率，且我們已知泊松分佈是指數分佈的家族成員，可以用廣義線性模型的概念來建模。

1. 因變量分佈，distribution of dependent variable $$Y_i \sim \text{Po}(\mu_i), \text{ where } \mu_i = \lambda_i t_i$$
2. 線性預測方程，linear predictor $$\eta_i = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}$$
3. 標準鏈接方程，canonical link function $$\text{log}(\lambda_i) = \text{log}(\frac{\mu_i}{t_i})$$

所以，將率的模型整理一下，就變成了

$$
\begin{aligned}
\text{log}(\mu_i) - \text{log}(t_i) & = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip} \\
\text{log}(\mu_i) & = \text{log}(t_i) + \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
\end{aligned}
$$

你可以看到，時間項的對數部分 $\text{log}(t_i)$ 其實是被移到線性預測方程的右邊跟參數放在一起的，只是**它的迴歸係數被強制爲 $1$**。這個時間項被叫做 **補償項 (offset)**。這樣我們就成功地擬合了用於求事件發生率的一個泊松迴歸模型。在 R 裏，你可以用 `glm()` 命令的 `offset = ` 選項功能，也可以把 `offset(log(Person-year))` 作爲線性預測方程的一部分把時間項取對數以後放進模型裏面。

## 率的 GLM

所以我們一起來把率的 GLM 正式定義一下，它包含三個部分：

1. 可被認爲互相獨立的因變量觀測值的分佈服從泊松分佈  $$Y_i \sim \text{Po}(\mu_i)$$ <br> 其中 $E(Y_i) = \mu_i = \lambda_i t_i$，$t_i$ 是第 $i$ 個觀察對象 (或者觀察組) 的追蹤人年 (person-time)。
2. 線性預測方程 $$\eta_i = \text{log}(t_i) + \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}$$
3. 鏈接方程是均值的對數方程 $$\text{log}(\mu_i) = \eta_i$$

和分組型二項分佈數據相似，如果泊松 GLM 擬合的數據也是分組型數據，如本章開頭的英國醫生隊列數據。那麼模型偏差值 (deviance) 可以用來衡量模型擬合的好壞。在零假設條件下，模型偏差值服從自由度爲 $n-p$ 的卡方分佈 (這裏的 $n$ 是分組型數據中的“組的數量”，也就是飽和模型中參數的數量，$p$ 是擬合的線性預測方程中參數的數量)。

## 分析實例 Example: British doctors study

數據是本章開頭使用的英國醫生隊列

```{r  GLM-0502, echo=FALSE, cache=TRUE}
print(BritishD)
```

- 每組的死亡人數用 $y_i, i=1,\cdots,10$ 標記；
- 每組追蹤的人年用 $t_i$ 標記；
- $x_{i1} = 0$ 時對象是吸菸者，$x_{i1} = 1$ 時對象是非吸菸者；
- $x_{i2}, x_{i3}, x_{i4}, x_{i5}$ 作爲5個年齡組的啞變量。


分析目的是：

1. 調查吸菸與冠心病死亡率的關係 (不調整年齡)；
2. 調查吸菸與冠心病死亡率的年齡調整後關係；
3. 調查年齡是否對吸菸與冠心病死亡率的關係起到交互作用。

### 模型 1: 吸菸

第一個模型可以用下面的數學表達式：

$$
\text{log}(\mu_i)  = \text{log}(t_i) + \alpha + \beta_1 x_{i1}
$$

在 R 裏面用下面的代碼來擬合這個模型，仔細閱讀輸出的結果：

```{r  GLM-0503, cache=TRUE}
# the following 2 models are equivalent
Model1 <- glm(deaths ~ smokes + offset(log(pyrs)), family = poisson(link = "log"), data = BritishD)
Model1 <- glm(deaths ~ smokes, offset = log(pyrs), family = poisson(link = "log"), data = BritishD)
summary(Model1); jtools::summ(Model1, digits = 6, confint = TRUE, exp = TRUE)
```

輸出報告中的參數估計部分 `Estimate` 就是我們擬合模型中參數的估計 $\hat\alpha, \hat\beta_1$，他們各自的含義是：

- $\hat\alpha = -5.96$：非吸菸者的冠心病估計死亡率的對數 (the estimated log rate for non-smokers)；
- $\hat\beta_1 = 0.547$：非吸菸者和吸菸者兩組之間冠心病死亡率對數之差 (the estimated difference in log rate between non-smokers and smokers)。

注意看報告中間部分模型偏差部分的數字 `Residual deviance: 905.98  on 8  degrees of freedom`，如果對 模型 1 進行擬合優度檢驗：


```{r  GLM-0504, cache=TRUE}
with(Model1, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))
```

擬合優度檢驗結果提示，這個模型對數據的擬合非常差 (poor fit)。可能的原因是，模型 1 中忽略了“年齡”這一重要的因素，使得當僅僅使用 吸菸與否 的信息擬合的泊松迴歸模型的擬合值和觀察值之間的差異的波動非常大，大到很可能無法滿足泊松分佈的前提假設。

### 模型 2: 吸菸 + 年齡

第二個模型的線性預測方程可以寫作：

$$
\text{log}(\mu_i) = \text{ln}(t_i) + \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \beta_4 x_{i4} + \beta_5 x_{i5}
$$

在 R 裏面用下面的代碼來擬合這個模型，仔細閱讀輸出的結果：

```{r  GLM-0505, cache=TRUE}
Model2 <- glm(deaths ~ smokes + agegrp + offset(log(pyrs)), family = poisson(link = "log"), data = BritishD)
summary(Model2); jtools::summ(Model2, digits = 6, confint = TRUE, exp = TRUE)
```

此時可以計算吸菸者與非吸菸者相比時，年齡調整後冠心病死亡率的比爲：

$$
\begin{aligned}
e^{0.3545} & = 1.43 \text{ with } 95\% \text{ CI: } \\
(e^{0.3545 - 1.96\times0.1074}, & e^{0.3545 + 1.96\times0.1074}) = (1.16, 1.76)
\end{aligned}
$$

報告中還包含了對吸菸項迴歸係數的 Wald 檢驗結果 `smokesSmoker   0.3545     0.1074   3.302  0.00096 ***`，從這一結果來看，數據提供了強有力的證據證明了年齡調整以後，吸菸會引起冠心病死亡率的顯著升高。再利用模型擬合報告中模型偏差部分的數據 `Residual deviance: 905.98  on 8  degrees of freedom`，模型的擬合優度檢驗結果爲：

```{r  GLM-0506, cache=TRUE}
with(Model2, cbind(res.deviance = deviance, df = df.residual,
  p = pchisq(deviance, df.residual, lower.tail=FALSE)))
```

結果依然提示，即使把年齡組放入這個泊松迴歸，模型對數據的擬合程度依然非常的不好。所以，到這裏，在即使調整了年齡之後模型擬合度依然不理想的情況下 (這是需要加交互作用項的證據)，我們需要在模型中加入年齡和吸菸的交互作用項 (結果是加入交互作用項的模型就變成了飽和模型)。


### 模型 3: 吸菸 + 年齡 + 吸菸與年齡的交互作用項


```{r  GLM-0507, cache=TRUE}
Model3 <- glm(deaths ~ smokes*agegrp + offset(log(pyrs)), 
              family = poisson(link = "log"), data = BritishD)
summary(Model3); jtools::summ(Model3, digits = 6, confint = TRUE, exp = TRUE)
```

此時你會看到模型的偏差已經幾乎接近於零，因爲這已經是一個飽和模型。你能根據這個模型的結果描述吸菸與冠心病發病率之間的關係及其如何隨着年齡變化而變化的嗎？

根据上述模型的结果，相對於非吸菸人羣，吸菸人羣的年齡調整後的冠心病發病率比 (rate ratio)，隨着年齡的增加而呈現下降趨勢。在最低年齡組 "35-44歲" 中，吸菸與非吸菸相比冠心病發病率比的估計值是 $e^{1.747} = 5.74$。 在 "45-54歲" 年齡組中，吸菸與非吸菸相比冠心病發病率比的估計值是 $e^{1.747 - 0.987} = 2.14$。。。。



## GLM Practical 06

在這個練習題中，我們將學會擬合，並能夠解釋多個不同的泊松回歸模型的分析結果，研究對象來自兩家橡膠製造工廠的男性職員。其中一家工廠在製造過程中對員工施加了保護的獨立設備，然而另一家工廠的工人則較多的暴露在製造橡膠過程中產生的粉塵和污染物中。該研究是爲了分析兩家工廠職工的死亡率是否有不同，需要考慮的已知的混雜因素是職工年齡。

### 將數據導入 R 環境中，初步計算每個工廠不同年齡組工人的死亡人數，和追蹤人年數據。

```{r GLM-prac06-01, cache=TRUE}
Rubber <- read.table("backupfiles/RUBBER.RAW", header = FALSE, 
                     sep ="", col.names = c("Agegrp", "Factory", 
                                            "n_deaths", "Pyears"))
Rubber <- Rubber %>% 
  mutate(Factory = as.factor(Factory)) %>% 
  mutate(Agegrp = as.factor(Agegrp)) %>% 
  mutate(Agegrp = fct_recode(Agegrp, 
                             "50-59" = "1", 
                             "60-69" = "2", 
                             "70-79" = "3", 
                             "80-89" = "4"))

tab <- stat.table(index=list(Factory=Factory,Agegrp=Agegrp),
                   contents=list(sum(n_deaths), 
                                 sum(Pyears)), 
                  data=Rubber, margins=T)

print(tab, digits = 0)
```

上面的代碼計算了每個工廠不同年齡組的死亡人數 (總人數 160) ，以及追蹤的人年 (總人年 19345)。

在 Stata 裏面的代碼更簡單(嗎？)

```{r GLM-prac06-02, engine='stata', echo=FALSE}
infile agegrp factory deaths pyrs using "backupfiles/RUBBER.RAW", clear

label var agegrp "Age group (1:5-59; 2:60-69; 3: 70-79; 4: 80-89)"
label var factor "Factory 1 or 2"
label var deaths "Number of deaths"
label var pyrs "Number of person-years of exposure"

table factory agegrp, c(sum deaths) row col

table factory agegrp, c(sum pyrs) row col
```


### 計算死亡率的對數值，繪製其與年齡組的點圖。

```{r deathRAgeR, echo=TRUE, fig.asp=.7, fig.width=7, fig.cap='Rates increase with age and age specific rates are higher in factory 2.', fig.align='center', out.width='90%', cache=TRUE}

Rubber <- Rubber %>%
  mutate(logdeathR = log(n_deaths/Pyears))

ggplot(Rubber, aes(x = Agegrp, y = logdeathR, shape = Factory)) +
  geom_point(size=3)+
  scale_y_continuous(breaks = seq(-7.5, -2.5, by = 0.5)) +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "Age group", y = "Log death rate (deaths/year)")  +
  theme(axis.title = element_text(size = 17), 
        axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank())
```


下面是 Stata 繪製圖\@ref(fig:deathRAge)的代碼：

```
gen logdeathR = log(deaths/pyrs)
twoway (scatter logdeathR agegrp, name(deathRAge, replace) mlabel(factory)), xtitle(age group) xlabel (1(1)4.2)
```

```{r deathRAge, echo=FALSE, fig.asp=.7, fig.width=7, fig.cap='Rates increase with age and age specific rates are higher in factory 2.', fig.align='center', out.width='90%', cache=TRUE}
knitr::include_graphics("img/deathRAge.png")
```


不論你用哪個圖，都可以看出，死亡率隨年齡增長而增加，2號工廠的死亡率似乎在各個年齡組都較1號工廠高。


### 請用數學語言描述死亡率和年齡組之間關係的模型。

令 $Y_i$ 爲年齡組 $i, (i = 1,\dots,8)$ 死亡人數，對應的觀測時間則爲 $t_i$ 年。如果前提條件每名工人之間相互獨立可以認爲得到滿足，那麼 $Y_i$ 可以用一個死亡率爲 $\lambda_i$ 的泊松模型來描述：

$$
Y_i \sim \text{Po}(\mu_i) \text{ where } \mu_i = \lambda_i t_i
$$

對應的鏈接方程以及其線性預測變量之間的關係可以表述爲：

$$
\begin{aligned}
\eta_i & = \log(\mu_i) = \log(t_i) + \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + \beta_3x_{3i} \\
\text{where } x_{1i} & = \left\{ \begin{array}{ll}  0 \text{ if the } i \text{th group is not aged 60-69}\\  1 \text{ if the } i \text{th group is aged 60-69}\\ \end{array} \right. \\
\text{where } x_{2i} & = \left\{ \begin{array}{ll}  0 \text{ if the } i \text{th group is not aged 70-79}\\  1 \text{ if the } i \text{th group is aged 70-79}\\ \end{array} \right. \\
\text{where } x_{3i} & = \left\{ \begin{array}{ll}  0 \text{ if the } i \text{th group is not aged 80-89}\\  1 \text{ if the } i \text{th group is aged 80-89}\\ \end{array} \right. \\
\end{aligned}
$$

#### 用R和Stata計算上述數學模型描述的死亡率和年齡之間關係的極大似然估計 (MLE)。年齡對於死亡率的效果有多強？
  
```{r GLM-prac06-03, cache=TRUE}
# fit a model without "agegroup"
mA <- glm(n_deaths ~ offset(log(Pyears)), 
              family = poisson(link = "log"), data = Rubber)
jtools::summ(mA, confint = TRUE, digits = 6)

# fit a model with age group
mB <- glm(n_deaths ~ Agegrp + offset(log(Pyears)), 
              family = poisson(link = "log"), data = Rubber)
jtools::summ(mB, confint = TRUE, digits = 6)

lrtest(mA, mB)
```

你可以比較加入年齡和沒加入年齡時的兩個模型，如上面使用的似然比檢驗法 (likelihood ratio test)。

在 Stata 你可以這樣做上面相同的事：

```{r GLM-prac06-04, engine='stata', echo=FALSE}
infile agegrp factory deaths pyrs using "backupfiles/RUBBER.RAW", clear

gen lpyrs = log(pyrs)

glm deaths, family(poisson) offset(lpyrs) link(log)
est store A

glm deaths i.agegrp, family(poisson) offset(lpyrs) link(log)
est store B

lrtest A B
```


其實Stata裏面還可以用簡化的 `Poisson` 命令

```{r GLM-prac06-05, engine='stata', echo=FALSE}
infile agegrp factory deaths pyrs using "backupfiles/RUBBER.RAW", clear

gen lpyrs = log(pyrs)

poisson deaths i.agegrp, e(pyrs)
```

#### 計算下列兩組年齡組對比之下的模型估計死亡率比 (rate ratios)

1. 60-69歲 比 50-59歲 RR 及其 95%CI

$$
\exp(1.583) (\exp(1.005), \exp(2.161)) = 4.87 (2.73, 8.68)
$$

2. 80-89歲 比 70-79歲 RR 及其 95%CI 的計算

$$
\exp(\hat{\beta_3} - \hat{\beta_2}) = \exp(2.555 - 2.302) = 1.29
$$

爲了獲取 $\hat{\beta_3} - \hat{\beta_2}$ 的方差，已知 $\text{Var}(\hat{\beta_3} - \hat{\beta_2}) = \text{Var}(\hat{\beta_3}) + \text{Var}(\hat{\beta_2}) - 2\text{Cov}(\hat{\beta_3}, \hat{\beta_2})$。根據這個在概率論學到的方差性質，我們可以手動計算想要的方差和標準差，從而進一步獲取其 95% CI：

You can also use `vce` command in Stata to obtain the Covariance matrix of coefficients of a fitted poisson model


```{r GLM-prac06-06, cache=TRUE}
vcov(mB) 
```


$$
\begin{aligned}
\text{Var}(\hat{\beta_3} - \hat{\beta_2}) & = \text{Var}(\hat{\beta_3}) + \text{Var}(\hat{\beta_2}) - 2\text{Cov}(\hat{\beta_3}, \hat{\beta_2}) \\
& =  0.13025 + 0.08681 - 2 \times 0.07143 \\
& = 0.0743 \\
\Rightarrow \text{the 95%CI} & = \exp(2.555 - 2.303 \pm\sqrt{0.07143}) \\
                             & = (0.75, 2.20) 
\end{aligned}
$$

在R裏你可以這樣計算：

```{r GLM-prac06-07, cache=TRUE}
# change the reference group to "70-79"
Rubber <- Rubber %>% 
  mutate(Agegrp1 = fct_relevel(Agegrp, "70-79"))

mC <- glm(n_deaths ~ Agegrp1 + offset(log(Pyears)), 
              family = poisson(link = "log"), data = Rubber)
jtools::summ(mC, confint = TRUE, digits = 6, exp = TRUE)
```

但是在 Stata 裏面可以使用靈活無比的 `lincom` 命令：

```{r GLM-prac06-08, engine='stata', echo=FALSE}
infile agegrp factory deaths pyrs using "backupfiles/RUBBER.RAW", clear

gen lpyrs = log(pyrs)

quietly: poisson deaths i.agegrp, e(pyrs)
lincom 4.agegrp - 3.agegrp, eform
```

### 接下來的模型中在前面的基礎上加入工廠編號，你認爲是否有證據證明工廠之間的工人的死亡率在調整了年齡之後依然有差異？計算年齡調整過後的兩工廠之間死亡率之比和95%CI。

```{r GLM-prac06-09, cache=TRUE}
mD <- glm(n_deaths ~ Agegrp + Factory + offset(log(Pyears)), 
              family = poisson(link = "log"), data = Rubber)
jtools::summ(mD, confint = TRUE, digits = 6, exp = TRUE)

lrtest(mD, mB)
```

從 `mD` 模型的報告來看，2號工廠比較1號工廠的工人死亡率比是 1.21 (95%CI: 0.89, 1.66)。兩個模型的似然比檢驗結果也提示，並無確實證據證明兩工廠工人的死亡率在調整了年齡因素之後有顯著差異。

### 現在在前一步加了工廠變量的基礎上，重新擬合模型，加入工廠和年齡之間的交互作用項

```{r GLM-prac06-10, cache=TRUE}
mE <- glm(n_deaths ~ Agegrp + Factory + Factory*Agegrp 
                    + offset(log(Pyears)), 
              family = poisson(link = "log"), data = Rubber)
summary(mE); jtools::summ(mE, confint = TRUE, digits = 6, exp = TRUE)
```

#### 請問這是一個怎樣的模型？

這是一個有8組觀測數據，8個參數估計的模型，是一個飽和模型。 The model is saturated. 

#### 有沒有足夠的證據證明工廠和年齡變量之間的交互作用項是有意義的？

```{r GLM-prac06-11, cache=TRUE}
lrtest(mE, mD)
```

似然比檢驗結果顯示，沒有證據證明二者之間交互作用項是有意義的。

#### 用數學語言描述上述包含了交互作用項的模型，並利用這個模型手頭計算下列各組的死亡率：

1. 1號工廠的 70-79 歲
2. 2號工廠的 50-50 歲
3. 2號工廠的 60-69 歲


$$
\begin{aligned}
\eta_i  = \log(\mu_i) & = \log(t_i) + \beta_0 + \beta_1x_{1i} + \beta_2x_{2i} + \beta_3x_{3i} + \beta_4z_{i}  \\
            & \;\;\; + \beta_5(x_{1i}z_{i}) + \beta_6(x_{2i}z_{i}) + \beta_7(x_{3i}z_{i})\\
\text{where } x_{1i} & = \left\{ \begin{array}{ll}  0 \text{ if the } i \text{th group is not aged 60-69}\\  1 \text{ if the } i \text{th group is aged 60-69}\\ \end{array} \right. \\
\text{where } x_{2i} & = \left\{ \begin{array}{ll}  0 \text{ if the } i \text{th group is not aged 70-79}\\  1 \text{ if the } i \text{th group is aged 70-79}\\ \end{array} \right. \\
\text{where } x_{3i} & = \left\{ \begin{array}{ll}  0 \text{ if the } i \text{th group is not aged 80-89}\\  1 \text{ if the } i \text{th group is aged 80-89}\\ \end{array} \right. \\
\text{and } z_{i} & = \left\{ \begin{array}{ll}  0 \text{ if the } i \text{th group is from factory 1}\\  1 \text{ if the } i \text{th group is from factory 2}\\ \end{array} \right. 
\end{aligned}
$$

1. 1號工廠的 70-79 歲組中該模型估計的死亡率是

$$
\exp(\hat{\beta}_0 + \hat{\beta}_2) = \exp(-6.359 + 2.2778) = 16.9 /1000 \text{ person-years}
$$


2. 2號工廠的 50-59 歲組中該模型估計的死亡率是

$$
\exp(\hat{\beta}_0 + \hat{\beta}_4) = \exp(-6.359 + 0.089) = 1.89 / 1000 \text{ person-years}
$$


3. 2號工廠的 60-69 歲組中該模型估計的死亡率是

$$
\exp(\hat{\beta}_0 + \hat{\beta}_1 + \hat{\beta}_4 + \hat{\beta}_5) = \exp(-6.359 + 1.475 + 0.089 + 0.190) = 10.0 / 1000 \text{ person-years}
$$


#### 對比你計算的模型估計死亡率和實際觀測到的死亡率

```{r GLM-prac06-12, cache=TRUE}
tab <- stat.table(index=list(Factory=Factory,Agegrp=Agegrp),
                   contents=list(sum(n_deaths/Pyears)), 
                  data=Rubber, margins=FALSE)

print(tab, digits = 7)
```

我們發現該模型估計的各組的死亡率和觀測值完全一致。

### 現在把年齡當作連續型變量來考慮。擬合下列模型

#### 只有年齡作爲連續型變量

```{r GLM-prac06-13, cache=TRUE}
mF <- glm(n_deaths ~ as.numeric(Agegrp) + offset(log(Pyears)), 
              family = poisson(link = "log"), data = Rubber)
jtools::summ(mF, confint = TRUE, digits = 6, exp = TRUE)
```

`mF` 的結果提供很強的證據證明年齡作爲連續型變量和死亡率的變化有關。年齡每增加10歲，死亡率增長的數字要乘以 2.24。

#### 年齡和工廠兩個預測變量

```{r GLM-prac06-14, cache=TRUE}
mG <- glm(n_deaths ~ as.numeric(Agegrp) + Factory + offset(log(Pyears)), 
              family = poisson(link = "log"), data = Rubber)
jtools::summ(mG, confint = TRUE, digits = 6, exp = TRUE)

lrtest(mG, mF)
```

並無有效證據證明工廠之間有死亡率的顯著區別。

#### 年齡和工廠，及兩個變量的交互作用項


```{r GLM-prac06-15, cache=TRUE}
mH <- glm(n_deaths ~ as.numeric(Agegrp) + Factory  + as.numeric(Agegrp)*Factory + 
          offset(log(Pyears)), family = poisson(link = "log"), data = Rubber)
jtools::summ(mH, confint = TRUE, digits = 6, exp = TRUE)

lrtest(mG, mH)
```

並無有效證據證明工廠之間的相互作用項有意義。


### 計算只有年齡(連續型)和工廠兩個變量模型時的模型偏差 (deviance)，該模型和第一部分中飽和模型之間相比相差幾個參數(parameters)？你有怎樣的推論？


```{r GLM-prac06-16, cache=TRUE}
lrtest(mF, mE)
```

看上面似然比檢驗結果顯示，有一些不太強的證據 (p = 0.0262) 證明相對飽和模型來說，把年齡當連續變量的模型可能擬合度較差。所以把年齡當作分類型變量 (categorical) 會是比較好的選擇。


### 對這個數據進行了這一系列的分析之後，你從流行病學的角度來說，有怎樣的結論？

總的來說，死亡率隨着年齡增長而增加。60-69 歲組的死亡率是50-59 歲組的 4.8 (95% CI 2.7, 8.6) 倍。之後年齡每增長十歲死亡率也在增長，只是增長幅度逐漸減少。至於工廠之間的死亡率比較，2號工廠似乎有 21% 較高 (95%CI: -11%, 66%) 的死亡率。但是工廠之間的死亡率差異並無顯著性 (p = 0.22)。交互作用項的分析也表明，並沒有證據表明工廠之間的死亡率差異會由於年齡的變化而有所不同。


# 混雜的調整，交互作用，和模型的可壓縮性

臨牀醫學，流行病學研究的許多問題，需要我們通過數據來評估某些結果變量 (outcome) 和某些預測變量 (predictors/exposures) 之間的關係 (甚至是因果關係)。這些問題的最佳解決方法應該說是隨機臨牀試驗 (ramdomized clinical trial, RCT)。但是有更多的時候 (由於違反醫學倫理，或者現狀所困，甚至是知識有限) 我們無法設計 RCT 來解決這些問題，就只能藉助於觀察性研究 (observational study)。觀察性研究最大的侷限性在於無法像 RCT 那樣從實驗設計階段把混雜因素排除或者降到最低，所以觀察數據在分析的時候，混雜 (confounding) 是必須要加以考慮的一大要因。在簡單線性迴歸章節 (Section \@ref(confounding))，詳細討論過混雜因素的定義及條件：

> 對於一個預測變量是否夠格被叫做混雜因子，它必須滿足下面的條件：
>
> -   與關心的預測變量相關 (i.e. $\delta_1 \neq 0$)；
> -   與因變量相關 (當關心的預測變量不變時，$\beta_2\neq0$ )；
> -   不在預測變量和因變量的因果關係 (如果有的話) 中作媒介。Not be on the causal pathway between the predictor of interest and the dependent variable.


下面的統計數據來自一個比較手術和超聲碎石術對於腎結石治療結果的評價。已知大多數醫生都公認，腎結石的直徑小於 2 公分時治療成功的概率較高。

```{r Lithotripsy, echo=FALSE, eval = TRUE, cache=TRUE}
dt <- read.csv("backupfiles/Lithotripsy.csv", header = T)
dt[4,3] <- " "
dt[4,5] <- " "
names(dt) <- c("Group", "Surgery", "Lithotripsy", "Surgery", "Lithotripsy")
kable(dt, "html",  align = "c", caption = "Lithotripsy") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"))%>%
  add_header_above(c(" " = 1, "< 2cm Diameter" = 2, ">= 2cm Diameter" = 2))
```

<!-- <table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;"> -->
<!-- <caption>表 49.1: Lithotripsy data</caption> -->
<!--  <thead> -->
<!--   <tr> -->
<!-- <th style="border-bottom:hidden" colspan="1"></th> -->
<!-- <th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;> < 2 cm Diameter</div></th> -->
<!-- <th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;>  >= 2 cm Diameter</div></th> -->
<!-- </tr> -->
<!-- <tr> -->
<!--    <th style="text-align:center;"> Group </th> -->
<!--    <th style="text-align:center;"> Surgery </th> -->
<!--    <th style="text-align:center;"> Lithotripsy </th> -->
<!--    <th style="text-align:center;"> Surgery </th> -->
<!--    <th style="text-align:center;"> Lithotripsy </th> -->
<!--   </tr> -->
<!--  </thead> -->
<!-- <tbody> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> Success </td> -->
<!--    <td style="text-align:center;"> 81 </td> -->
<!--    <td style="text-align:center;"> 234 </td> -->
<!--    <td style="text-align:center;"> 192 </td> -->
<!--    <td style="text-align:center;"> 55 </td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> Failure </td> -->
<!--    <td style="text-align:center;"> 6 </td> -->
<!--    <td style="text-align:center;"> 36 </td> -->
<!--    <td style="text-align:center;"> 71 </td> -->
<!--    <td style="text-align:center;"> 25 </td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> Total </td> -->
<!--    <td style="text-align:center;"> 87 </td> -->
<!--    <td style="text-align:center;"> 270 </td> -->
<!--    <td style="text-align:center;"> 263 </td> -->
<!--    <td style="text-align:center;"> 80 </td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> Odds Ratios </td> -->
<!--    <td style="text-align:center;"> 2.08 </td> -->
<!--    <td style="text-align:center;">  </td> -->
<!--    <td style="text-align:center;"> 1.23 </td> -->
<!--    <td style="text-align:center;">  </td> -->
<!--   </tr> -->
<!-- </tbody> -->
<!-- </table> -->

可以看到，在上面的分組表格中，左右兩邊的四格表分別統計了腎結石尺寸小於 2 cm 和大於 2 cm 時，手術摘除腎結石的成功/失敗次數，以及超聲碎石術的成功/失敗次數。這個表格告訴我們，無論腎結石的尺寸是大於還是小於 2 cm，手術的成功的比值比都大於超聲碎石術。但是如果我們沒有把數據按照腎結石尺寸區分時，數據就被壓縮 (collapsed) 成了下面表格總結的樣子：



```{r Lithotripsy-collapsed, echo=FALSE, eval = TRUE}
dt <- read.csv("backupfiles/Lithotripsy-col.csv", header = T, colClasses = "character")

dt[4,3] <- " "

kable(dt, "html",  align = "c", caption = "Lithotripsy data collapsed") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"))

```

<!-- <table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;"> -->
<!-- <caption>表 49.2: Lithotripsy data collapsed</caption> -->
<!--  <thead> -->
<!--   <tr> -->
<!--    <th style="text-align:center;"> Outcome </th> -->
<!--    <th style="text-align:center;"> Surgery </th> -->
<!--    <th style="text-align:center;"> Lithotripsy </th> -->
<!--   </tr> -->
<!--  </thead> -->
<!-- <tbody> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> Success </td> -->
<!--    <td style="text-align:center;"> 273 (78%) </td> -->
<!--    <td style="text-align:center;"> 289 (83%) </td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> Failure </td> -->
<!--    <td style="text-align:center;"> 77 </td> -->
<!--    <td style="text-align:center;"> 61 </td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> Total </td> -->
<!--    <td style="text-align:center;"> 350 </td> -->
<!--    <td style="text-align:center;"> 350 </td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> Odds ratio </td> -->
<!--    <td style="text-align:center;"> 0.75 </td> -->
<!--    <td style="text-align:center;">  </td> -->
<!--   </tr> -->
<!-- </tbody> -->
<!-- </table> -->

當腎結石尺寸被忽略時，數據卻顯示超聲碎石術的成功比值比要高於手術，和之前的結果是矛盾的，你會信哪個？

不要慌，**數據不會撒謊，撒謊(有意掩蓋事實)的永遠是人類**。我們來把手術次數，超聲碎石術次數，以及腎結石尺寸之間的關係再列個表格：


<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>表 49.3: Association between treatment and the size of the stone. </caption>
 <thead>
  <tr>
   <th style="text-align:center;"> Size of the Stone </th>
   <th style="text-align:center;"> Surgery </th>
   <th style="text-align:center;"> Lithotripsy </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> $< 2$  cm </td>
   <td style="text-align:center;"> 87 (33%) </td>
   <td style="text-align:center;"> 270 (77%) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> $\geqslant 2$ cm </td>
   <td style="text-align:center;"> 263 </td>
   <td style="text-align:center;"> 80 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Total </td>
   <td style="text-align:center;"> 350 </td>
   <td style="text-align:center;"> 350 </td>
  </tr>
</tbody>
</table>

可見醫生也都不是傻子，明明腎結石尺寸很大還要用超聲碎石術的人很少，有 77% 的腎結石尺寸小的患者選擇了超聲碎石術。然後我們再列一個表格來看看**腎結石的尺寸大小和超聲碎石術**成功與否有沒有關係：

<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>表 49.4: Among the **lithotripsy patients** higher percentage of success was observed when stones were small. </caption>
 <thead>
  <tr>
   <th style="text-align:center;"> Outcome </th>
   <th style="text-align:center;"> $< 2$  cm </th>
   <th style="text-align:center;"> $\geqslant 2$ cm </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> Success </td>
   <td style="text-align:center;"> 234 (87%) </td>
   <td style="text-align:center;"> 55 (69%) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Failure </td>
   <td style="text-align:center;"> 36 </td>
   <td style="text-align:center;"> 25 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Total </td>
   <td style="text-align:center;"> 370 </td>
   <td style="text-align:center;"> 80 </td>
  </tr>
</tbody>
</table>

可見結石尺寸較大時，超聲碎石術的成功率 (69%)，明顯低於尺寸小的時候的成功率 (87%)。在選擇做外科手術的患者中，大多數人的結石尺寸大於 2 cm，成功率仍然達到了 73%。


<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>表 49.5: Among the **surgery patients** higher percentage of success in both stones compared with lithotripsy </caption>
 <thead>
  <tr>
   <th style="text-align:center;"> Outcome </th>
   <th style="text-align:center;"> $< 2$  cm </th>
   <th style="text-align:center;"> $\geqslant 2$ cm </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> Success </td>
   <td style="text-align:center;"> 81 (93%) </td>
   <td style="text-align:center;"> 192 (73%) </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Failure </td>
   <td style="text-align:center;"> 6 </td>
   <td style="text-align:center;"> 71 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Total </td>
   <td style="text-align:center;"> 87 </td>
   <td style="text-align:center;"> 263 </td>
  </tr>
</tbody>
</table>

看到這裏，你是否也發現了，腎結石尺寸大小，同時和手術類型的選擇有關 (尺寸小的傾向於選擇超聲碎石術)，尺寸大小，同樣也和手術結果的成功與否，高度相關 (結石小的人成功率高)。所以，分析手術類型和結石手術的成功率的關係的時候，患者體內結石尺寸的大小，對這個關係是產生了混雜效應的。他們三者之間的關係，可以用下面的圖 \@ref(fig:confounding-kidney) 來理解：


```{r confounding-kidney, echo=FALSE, fig.asp=.7, fig.width=7, fig.cap='Confounding in kidney stones example', fig.align='center', out.width='90%', cache=TRUE}
knitr::include_graphics("img/Selection_113.png")
```

當數據被壓縮 (忽略了腎結石尺寸時)，比較兩種手術類型的成功率的時候，接受外科手術患者的尺寸大多數都較大的事實被“**人爲的掩蓋住了**”，但是當數據按照結石大小分層以後，你會看見外科手術不論是對付大的結石，還是小的結石，成功率都高於超聲碎石術。這個例子是混雜效應直接逆轉真實相關關係的極佳的實例。同時也提示我們，**總體的比值比 (overall odds ratio) 不能通過簡單地把分層表格直接壓縮 (collapsed table) 獲得的數字來計算**。

## 混雜因素的調整

在前面的腎結石手術的例子中，我們利用已有的背景知識 (小尺寸結石的成功率高)，和初步的統計分析 (變量之間兩兩列表分析其內在關係) 發現了混雜因素 (結石尺寸)，並且其結果也讓我們認定了要暴露因素和結果變量之間的關係，混雜因素必須被調整 (adjusted)。

如腎結石數據這樣簡單的情境下 (被認爲是混雜因素的變量和預測變量/暴露變量都只是一個二分類變量)，我們可以把變量兩兩捉對列表分析其相互關係，確定了混雜效應以後把暴露變量和結果變量按照混雜因素的有無列表之後，就可以求得混雜因素被**調整後的分層的比值比**。這些分層比值比，在暴露變量與結果變量的關係保持混雜因素的層之間保持不變的前提下，可以被“平均化”(簡單地說)以後求得總體/合併的比值比 (overall/pooled odds ratio)。這就是 Mantel-Haenszel 法或者 Woolf 法的合併比值比的思想出發點。我們來回顧一下 Woolf 法的全部計算過程：

現在假設我們關心的是某種疾病的患病與否 (是/否)，和某個暴露變量 (是/否) 之間的關係，但是同時想要調整另一個具有 $k$ 個分層的混雜因素變量。

```{r woolf, echo=FALSE, eval = FALSE}
dt <- read.csv("backupfiles/woolf.csv", header = T)
names(dt) <- c(" ", " ", "1", "2", " ")
kable(dt, "html",  align = "c", caption = "") %>%
  kable_styling(bootstrap_options = c("striped", "bordered")) %>%
  add_header_above(c(" " = 2, "Group" = 2, " " = 1))
```

<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>表 49.6: Woolf Method for estimating the stratified and pooled odds ratio </caption>
 <thead>
  <tr>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">Group</div></th>
</tr>
<tr>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;"> $X=0$ </th>
   <th style="text-align:center;"> $X=1$ </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> $D=0$ </td>
   <td style="text-align:center;"> $X=0$ </td>
   <td style="text-align:center;"> $n_{00}$ </td>
   <td style="text-align:center;"> $n_{10}$ </td>
  </tr>
  <tr>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> $X=1$ </td>
   <td style="text-align:center;"> $n_{01}$ </td>
   <td style="text-align:center;"> $n_{10}$ </td>
  </tr>
</tbody>
</table>

### Woolf 法估算合併比值比

對想要調整的一個 $k$ 組的混雜因素，把數據按照它的分組分層整理以後，可以得到上面的 $k$ 個四格表 (每個分層四格表都是暴露變量和結果變量結合的四個觀察值 $a_i, b_i, c_i, d_i, (i=1,\cdots, k)$)。每個分層四格表的觀測比值比爲 $\hat\Psi_i = \frac{a_id_i}{c_ib_i}$，且可以證明方差爲

$$
\text{Var}(\text{log}\hat\Psi_i) \approx \frac{1}{a_i} + \frac{1}{b_i} + \frac{1}{c_i} + \frac{1}{d_i} = \frac{1}{w_i}
$$

合併比值比的對數 $\text{log}\hat\Psi_w$ 的 Woolf 的計算方法就是

$$
\text{log}\hat\Psi_w = \frac{\sum w_i\text{log}\hat\Psi_i}{\sum w_i}
$$

所以，每個分層的對數比值比乘以自己的**方差的倒數** (權重 weights) 之後求和，再除以所有權重之和，獲得的是合併後的對數比值比，然後再逆運算回來就是 Woolf 法計算合併比值比的原理是。

這個合併比值比的對數的方差是

$$
\text{Var}(\text{log}\hat\Psi_w) = \frac{1}{\sum w_i}
$$

有了加權後的合併比值比，和方差，就可以求加權後的合併比值比的信賴區間了。值得注意的是，分層之後每個分層四格表中的四個數字 (四個樣本量) 都不能太小。腎結石手術數據滿足這些條件，那麼不妨跟我一起手算一下結石尺寸調整後的手術與超聲碎石術成功與否的比值比：

$$
\begin{aligned}
\hat\Psi_1 = 2.08 ;&\; \hat\Psi_2 = 1.23 \\
\text{Var}(\text{log}\hat\Psi_1) = \frac{1}{81} & + \frac{1}{234} + \frac{1}{6} + \frac{1}{36} = 0.2111 \\
\text{Var}(\text{log}\hat\Psi_2) = \frac{1}{192} & + \frac{1}{55} + \frac{1}{71} + \frac{1}{25} = 0.0775 \\
w_1 = \frac{1}{\text{Var}(\text{log}\hat\Psi_1)} = 4.74 ; \;& w_2 = \frac{1}{\text{Var}(\text{log}\hat\Psi_2)} = 12.91 \\
\text{log}\hat\Psi_w = & \frac{4.74\times\text{log(2.08)} + 12.91\times\text{log(1.23)}}{4.74 + 12.91} \\
                     = & 0.3481 \\
\Rightarrow \hat\Psi_w =& e^{0.3481} = 1.42\\
\text{Var}(\hat\Psi_w) =& \frac{1}{4.74+12.91} = 0.0567 \\
\Rightarrow 95\% \text{ CI} = & e^{0.3481 \pm 1.96\times\sqrt{0.0567}} \\
                            = & (0.89, 2.26)
\end{aligned}
$$

Woolf 的計算調整後的合併比值比的方法是**在線性迴歸和廣義線性迴歸被發現之前誕生的**，但是其想法之精妙，確實令人感嘆。可惜其最大的缺陷是無法用這樣的方法進行連續型變量的調整，也很難同時進行多個變量的調整，所以現在這一算法已經逐漸被淘汰。現在我們有了廣義線性迴歸模型這一更強大的工具，只要把變量加入廣義線性模型進行調整就可以計算曾經難以計算和擴展的調整後的合併比值比。從下面的代碼計算獲得的調整後比值比 $1.43 (0.91, 2.34)$ 也可以看出，Woolf 方法的計算結果也是足夠令人滿意的。

```{r GLM-0508, cache=TRUE}
size <- c("< 2cm", "< 2cm", ">= 2cm", ">= 2cm")
treatment <- c("Surgery","Lithotripsy","Surgery","Lithotripsy")
n <- c(87, 270, 263, 80)
Success <- c(81, 234, 192, 55)
Stone <- data.frame(size, treatment, n, Success)
ModelStone <- glm(cbind(Success, n - Success) ~ treatment + size, 
                  family = binomial(link = logit), data = Stone)
summary(ModelStone)
epiDisplay::logistic.display(ModelStone)
```

所以，此次分析的結論是，在 5% 的顯著性水平下，數據無法提供有效證據證明，當調整了結石尺寸之後，外科手術和超聲碎石術治療腎結石有差別。
We can conclude that there is no evidence at the 5% level for an effect of surgery, adjusted for stone size.


## 交互作用

我們決定調整一個混雜因素的時候，其實同時包含了 “在不同混雜因素的程度下，暴露變量和結果變量之間的關係不變/This implicitly assumes that the effect of the exposure is the same irrespective of the levels of the confounder.” 的假設。但是，一個混雜因素，它可能同時還扮演了改變暴露變量和結果變量之間關係的角色 (effect modifier/交互作用效應)。另外還有的情況下，某變量可能改變了暴露變量和結果變量之間的關係，卻不一定是一個混雜因素。此時我們說這個起到改變關係的變量和暴露變量之間發生了交互作用。

如果暴露變量在某個分組變量的不同層 (strata) 之間是不同質的 (hetergeneous, not constant)，我們建議**要分析且報告不同層各自的**比值比。惟一的例外是 RCT 臨牀試驗的時候，我們更加關心調整後合併比值比。因爲一項治療藥物對不同的 “個體” 有不同的療效是必然的，但是，RCT 的目的是要評價的其實是這個藥物或者新療法在整個人羣中的療效是怎樣的。

我們給腎結石數據加上治療方案和結石尺寸大小的交互作用項，結果如下：

```{r  GLM-0509, cache=TRUE}
ModelStone2 <- glm(cbind(Success, n - Success) ~ treatment*size, 
                   family = binomial(link = logit), data = Stone)
summary(ModelStone2)
epiDisplay::logistic.display(ModelStone2)
```

交互作用項的迴歸係數是否爲零的檢驗結果是 $p = 0.329$，提示數據無法提供足夠的證據證明結石尺寸對治療方案和手術成功與否之間的關係造成有意義的交互作用 (There is no evidence of an interaction between stone size and surgery)。所以此次的數據分析我們可以報告結石尺寸調整後的手術成功比值比就可以了。其中，交互作用項的迴歸係數 $-0.5245 = \text{log}(0.59)$，的含義是當結石尺寸 $\geqslant  2 \text{cm}$ 時，外科手術和超聲碎石術成功**比值比的對數的差**。我們可以看到一開始我們計算的分層比值比的比值 $\frac{1.23}{2.08} = 0.59$。還注意到這已經是一個飽和模型 (模型偏差爲零)，模型的擬合值和我們的觀測值是完全相同的。

另外一點不得不提的是，交互作用項的迴歸係數的點估計 $0.59$ 其實低於零假設時的 $1$ 挺多的，它的 $95\%$ 信賴區間也相當的寬 $(0.21,1.70)$，所以其實這裏我們沒有獲得足夠的證據證明替代假設 (有交互作用)，很難說不是因爲樣本量不足導致的統計效能較低，所以我們沒有辦法從這個數據完全排除結石尺寸對治療方案的選擇和手術成功的關係之間的交互作用。(We really cannot be sure that there is no interaction in truth - the data are consistent with quite large interactions between size and surgery effect.) 因此，**有些統計學家可能會傾向於報告分層的比值比，因爲我們沒有辦法從這個樣本數據排除有較強交互作用存在的可能性**。

## 可壓縮性  collapsibility

模型可壓縮性的概念可以這樣來理解：

當我們把一個 **我們認爲很重要的混雜因子** 加到模型中去時，自然而然我們會期待其對結果變量的 **效果估計 (effect estimate)** (迴歸係數)在調整前後發生變化。如果是反過來，當我們把一個 **我們認爲不重要的非混雜因子** 加到模型中去時，我們也會自然而然地期待其對結果變量的 **效果估計 (effect estimate)** 在調整前後不會發生改變才是。不幸的是，我們這種理想中的想當然，僅僅在某些情境下成立，其中之一是簡單線性迴歸 (Section \@ref(lm))。

### 線性迴歸的可壓縮性

**證明**

令 $Y$ 標記結果變量，$X$ 標記暴露變量，$Z$ 則標記我們想要調整的某個混雜因子：

$$
Y = \alpha + \beta_X X + \beta_Z Z + \varepsilon, \text{ where } \varepsilon \sim N(0, \sigma^2)
$$

然後把等式兩邊同時取以暴露變量 $X$ 爲條件的期待值：

$$
E(Y | X) = \alpha + \beta_X X + \beta_Z E(Z|X)
$$

如果 $Z$ 和 $X$ 是相互獨立的 (即，不是 $X, Y$ 之間關係的混淆因子)，那麼 $E(Z|X) = E(Z) = \mu_Z$，因爲 $X$ 不能提供任何 $Z$ 的有效信息。所以，等式就變爲：

$$
E(Y|X) = \alpha + \beta_Z \mu_Z + \beta_X X
$$

所以，當我們用簡單線性迴歸來擬合 $X,Y$ 之間的關係時，如果 $Z,X$ 是相互獨立的，模型中增加了 $Z$，不會影響 $X$ 的迴歸係數。線性迴歸的這個性質被定義爲模型的可壓縮性 (linear regression models are collapsible)。

### 邏輯鏈接方程時的不可壓縮性 {#collapsibility}

使用對數鏈接方程 ($\text{log link}$) 的迴歸模型，同樣具有和線性迴歸類似的可壓縮性。但是，邏輯鏈接方程 ($\text{logit link}$) 的迴歸模型則不具有可壓縮性。下面舉例的分層表格和壓縮表格，證明了邏輯鏈接方程不具有可壓縮性：


<style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-0lax{text-align:left;vertical-align:top}
</style>
<table class="tg">
<caption>表 49.7: **Non-collapsibility** of logit link in GLM **(stratified data)**</caption>
<thead>
  <tr>
    <th class="tg-0lax"></th>
    <th class="tg-baqh" colspan="2"> Strata 1 </th>
    <th class="tg-baqh" colspan="2"> Strata 2 </th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0lax"> Outcome </td>
    <td class="tg-0lax"> Exposure $+$ </td>
    <td class="tg-0lax"> Exposure $-$ </td>
    <td class="tg-0lax"> Exposure $+$ </td>
    <td class="tg-0lax"> Exposure $-$ </td>
  </tr>
  <tr>
    <td class="tg-0lax"> Success </td>
    <td class="tg-0lax"> 90 </td>
    <td class="tg-0lax"> 50 </td>
    <td class="tg-0lax"> 50 </td>
    <td class="tg-0lax"> 10 </td>
  </tr>
  <tr>
    <td class="tg-0lax"> Failure </td>
    <td class="tg-0lax"> 10 </td>
    <td class="tg-0lax"> 50 </td>
    <td class="tg-0lax"> 50 </td>
    <td class="tg-0lax"> 90 </td>
  </tr>
  <tr>
    <td class="tg-0lax"> Total </td>
    <td class="tg-0lax"> 100 </td>
    <td class="tg-0lax"> 100 </td>
    <td class="tg-0lax"> 100 </td>
    <td class="tg-0lax"> 100 </td>
  </tr>
  <tr>
    <td class="tg-0lax"> Odds Ratios </td>
    <td class="tg-0lax"> 9 </td>
    <td class="tg-0lax">  </td>
    <td class="tg-0lax"> 9 </td>
    <td class="tg-0lax">  </td>
  </tr>
</tbody>
</table>

從表格的數據計算可知，要被調整的分組變量的兩層數據中，暴露變量和結果變量的關係相同，比值比都是 $9$，沒有交互作用，也沒有混雜效應 (每一層中暴露與非暴露均佔相同的 $50\%$)。但是，你如果把這個觀測數據合併：


<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>表 49.8: **Non-collapsibility** of logit link in GLM **(collapsed data)**</caption>
 <thead>
  <tr>
   <th style="text-align:center;"> Outcome </th>
   <th style="text-align:center;"> Exposure $+$ </th>
   <th style="text-align:center;"> Exposure $-$ </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> Success </td>
   <td style="text-align:center;"> 140 </td>
   <td style="text-align:center;"> 60 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Failure </td>
   <td style="text-align:center;"> 60 </td>
   <td style="text-align:center;"> 140 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Total </td>
   <td style="text-align:center;"> 200 </td>
   <td style="text-align:center;"> 200 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Odds ratio </td>
   <td style="text-align:center;"> 5.4 </td>
   <td style="text-align:center;">  </td>
  </tr>
</tbody>
</table>

既然已知我們拿來分層的變量對暴露和結果的關係既沒有交互作用，也沒有混雜效應，那麼壓縮數據以後的合併比值比應該和分層比值比一樣才說的通，可惜我們獲得了截然不同的合併比值比 (非調整的)。所以在應用邏輯鏈接方程建立廣義線性迴歸模型的時候，一定不能忘記其不可壓縮性的特徵。所以，**即使加入一個非混淆因子，暴露變量的邏輯迴歸的效應估計 (係數) 也會發生改變**。調整了 $Z$ 以後的比值比被叫做條件 (或直接使用分層) 比值比。如同表格中實例所示，條件比值比會比邊緣比值比 (非調整) 看起來要大一些。

邏輯迴歸的不可壓縮性給我們的啓示是，加入某個變量進入邏輯迴歸模型前後，其他預測變量的迴歸係數發生的變化可能僅僅是由於模型的不可壓縮性導致的變化，而非由於新加入的變量對原先變量與結果之間的關係起到了交互作用或者混雜效應。所以，**擬合迴歸模型的時候，如果你要考慮對某個因素進行調整，必須做的一件事是，先分析它和其他模型中已有的預測變量之間的關係，從而有助於分析並判斷把要調整的變量放進模型前後的迴歸係數變化是否是真的來自於交互作用或者混雜效應。**

## 交互作用對尺度的依賴性 {#interaction-depend-scale}

GLM 模型中的交互作用檢驗，對選用的尺度 (比值比 OR，還是危險度比 RR) 依賴性極高。用模型可壓縮性的數據例子也可以說明交互作用對尺度的依賴性。上文書說到，兩個分層中的比值比都是 9，該分層變量既沒有交互作用，也不是混淆因子 (當使用比值比的時候)。如果我們改用危險度比 (risk ratio, RR)，在分類變量的第一層 (Strata 1) 中，暴露的危險度比是 $\frac{90/100}{50/100} = 1.8$；分類變量的第二層 (Strata 2) 中，暴露的危險度比是 $\frac{50/100}{10/100} = 5$。所以使用危險度比作爲評價指標的時候，被調整的分類變量就突然搖身一變變成了有交互作用的因子。這裏，我們用數據，證明了交互作用的存在與否，對尺度的選用依賴性極高。**這就導致我們在描述一個變量是否對我們關心的暴露和結果之間的關係有交互作用時，必須明確指出所使用的是比值比，還是危險度比進行的交互作用評價。**

## GLM Practical 07

在本次練習中，我們用一個計算機模擬的有5000名高血壓患者的RCT實驗數據。該數據只有三個隨機產生的二分類變量：

- `treat` 表示患者是接收了新療法 (1 = new)，或者繼續維持現有的療法 (0 = current)；

- `basecontrol` 表示患者在剛進入實驗時 (baseline) 血壓原本控制的狀態 (0 = bad; 1 = good)；

- `fupcontrol` 表示患者在實驗過程的隨訪結果中 (followup) 血壓原本控制的狀態 (0 = bad; 1 = good)；


### 使用你熟悉的統計學軟件擬合一個由 `fupcontrol` 作爲結果變量，`treat` 作爲唯一預測變量的廣義線性回歸模型。 根據報告的結果，寫一段適用於醫學/流行病學文獻雜誌的報告。

```{r GLM-prac07-01, cache=TRUE}
highbp <- read_dta("backupfiles/highbp.dta")

m0 <- glm(fupcontrol ~ treat, data = highbp, 
          family = binomial(link = logit))
summary(m0); jtools::summ(m0, exp = TRUE, confint = TRUE, digits = 7)
```

There was strong evidence (p < 0.001) that treatment is associated with the probability of having BP controlled at followup, with patients randomised to the treatment having odds of BP controlled of 2.28 (95%CI 2.04 to 2.56) higher than those randomised to the current treatment. 

### 分析 `treat` 和 `basecontrol` 之間的關係，結果是否如你的預期那樣？


```{r GLM-prac07-02, cache=TRUE}
m1 <- glm(basecontrol ~ treat, data = highbp, 
          family = binomial(link = logit))
summary(m1); jtools::summ(m1, exp = TRUE, confint = TRUE, digits = 7)
```

這個分析結果提示我們無證據表明該數據中 `basecontrol` 與治療方案有關。模型比值比十分接近 1。這與完全符合預期，因爲如何選擇治療方案在這個實驗中是完全隨機分配的，它不應與基線時的血壓控制情況有任何關聯。隨機過程把基線血壓控制的情況在兩個治療組之間平衡了。

### 已知模型中如果增加調整基線變量可能對 `fupcontrol` 有一定的預測效果。 在你的模型中增加基線血壓控制情況的變量。與 `m0` 的結果 (治療效果 treatment effect；參數標準誤 standard error；和 p 值)。重新修改之前用於發表在醫學雜誌上關於這個分析結果的報告描述。

```{r GLM-prac07-03, cache=TRUE}
m2 <- glm(fupcontrol ~ treat + basecontrol, data = highbp, 
          family = binomial(link = logit))
summary(m2); jtools::summ(m2, exp = TRUE, confint = TRUE, digits = 7)
```


After adjusting for baseline BP control, the estimated log OR for the new vs current treatment is 1.00 (95%CI 0.87 to 1.13). This is quite a bit larger than the corresponding estimate from part 1, which was 0.83 (0.71, 0.94). The standard error has, perhaps contrary to expectation, increased from 0.059 to 0.067. The p-values are highly significant from both analyses, but the z-statistics is larger in the baseline adjusted analysis, which indicates this result is more statistically significant. 

The increase in the log OR estimate is due to the fact that the baseline adjusted analysis is estimating a different parameter. This is because, although there is no confounding, odds ratios are not collapsible - **a conditional odds ratio has a different interpretation from a marginal one**. The baseline adjusted analyses estimates the odds ratio for two patients who have the same value of baseline BP control, and this differs from the unconditional OR. 

### 你更推薦使用哪個模型作爲最終主要結果的彙報？

都可以。取決於你想拿這結果用於怎樣的解釋。因爲他們回答的是不同的問題。條件比值比 (conditional OR) 的一個缺點是，它的解釋需要考慮這個比值比究竟調整了哪些變量（有哪些條件）。這就帶來一個缺點，如果相同的治療方法選取了不同的條件，也就是調整了不同的變量的話，他們就會完全不同。因爲條件比值比回答的問題更加關心的是病人個體水平的層面 (individual level characteristics) 的問題，也就是說他/她在基線時是否是血壓控制的良好的，或者增加其他的變量 (性別或者年齡等)。相反的，無條件，或者粗比值比回答的問題是更加廣泛的人羣水平的治療效果而不拘泥與究竟調整了哪些變量。後者對於需要採納針對整體人羣政策的決策者來說更加有參考價值。前者對於有（或沒有）某些具體特徵的病人（或非病人）來說則更加有意義。

### 實驗研究者更想知道新的治療方案是否由於基線時患者的血壓控制情況而有不同。爲了回答這個問題，請擬合對應的廣義線性回歸模型。根據結果回答這個問題。

```{r GLM-prac07-04, cache=TRUE}
m3 <- glm(fupcontrol ~ treat + basecontrol + treat*basecontrol, 
          data = highbp, family = binomial(link = logit))
summary(m3); jtools::summ(m3, exp = TRUE, confint = TRUE, digits = 7)
lrtest(m3, m2)
```

從模型本身的交互作用項結果(p = 0.54)和兩個模型的似然比檢驗結果 (p = 0.54) 來看，均無證據表示基線時的血壓控制情況和療效之間存在有意義的交互作用。

### 換一個模型，先不考慮 `basecontrol`，使用危險度比 (risk ratio) 來評價不同治療方案之間的療效。

```{r GLM-prac07-05, cache=TRUE}
m4 <- glm(fupcontrol ~ treat, 
          data = highbp, family = binomial(link = log))
summary(m4); jtools::summ(m4, exp = TRUE, confint = TRUE, digits = 7)
```

鏈接方程換爲對數而非邏輯方程的廣義線性回歸模型時，新治療方案和現行治療方案的血壓控制 RR 是 1.64 (95%CI: 1.52, 1.76)

### 在前一模型`m4`中加入 `basecontrol`，與未加入該變量時模型的輸出結果相比，有什麼不同？

```{r GLM-prac07-06, cache=TRUE}
m5 <- glm(fupcontrol ~ treat + basecontrol, 
          data = highbp, family = binomial(link = log))
summary(m5); jtools::summ(m5, exp = TRUE, confint = TRUE, digits = 7)
```

由於對數鏈接方程和邏輯鏈接方程不同，是具有可壓縮性的 (collapisble)。所以如果增加的預測變量和結果變量是無關的，那麼我們應該認爲評價治療效果的危險度比在加入無關變量前後不會有太大的變化。但實際結果我們看見危險度比略微減少了一些。這主要是因爲這裏的模型本身是有問題的。

### 給上述模型增加交互作用項。對於危險度比作爲指標時的交互作用分析結果，和使用比值比時相比，你有怎樣的思考和結論？

```{r GLM-prac07-07, cache=TRUE}
m6 <- glm(fupcontrol ~ treat + basecontrol + treat*basecontrol, 
          data = highbp, family = binomial(link = log))
summary(m6); jtools::summ(m6, exp = TRUE, confint = TRUE, digits = 7)
lrtest(m6, m5)
```


我們發現當我們把評價指標換成危險度比之後，治療方案和基線血壓控制情況之間的交互作用變得高度有統計學意義 (p < 0.0001)。這和之前使用邏輯鏈接函數的模型大相徑庭。這個結果提示我們交互作用存在與否是取決於你使用的評價指標的 (scale dependent)。這裏我們發現本數據中 log risk ratio 的尺度上交互作用存在且有意義， log odds ratio 的尺度上則並不存在有意義的交互作用。所以，採用危險度比作爲評價指標時，我們發現之前我們作出的結論應該需要被修正。

### 如果說不考慮一個RCT的統計分析不能在收集完數據之後修改這一事實，你認爲危險度比模型和比值比模型更應該使用哪一個來總結本數據的結果呢？

Since there is no interaction on the log odds scale, using a logisitic regression is probably preferable, as it **gives a simpler model which correctly models the data**. Whether the unadjusted or baseline adjusted results are presented is a question which is still hotly debated. The latter has increased power to detect a treatment effect, but as we have seen it estimates a different parameter to the marginal unadjusted OR. 

### 證明危險度比模型是可以壓縮的。Prove that the log-link models are collapsible.

令 $Y$ 爲結果變量，$X$ 爲主要暴露變量 (main exposure)，$Z$ 爲與 $X$ 相互獨立的變量，也就是 $Z$ 本身並不是一個 $X$ 的混雜因子。那麼爲了計算 $E(Y|X)$，我們可以使用期望的數學算法來證明：

$$
\begin{aligned}
\text{Assume that } E(Y | X, Z) & = \exp(\beta_0 + \beta_X X + \beta_Z Z) \\
\text{then }        E(Y|X)      & = E(E(Y | X,Z) | X)  \text{ by the law of total expectation}\\
                                & = E(e^{\beta_0}e^{\beta_XX}e^{\beta_ZZ} | X) \\
                                & = e^{\beta_0}e^{\beta_XX}E(e^{\beta_ZZ} |X) \\
\because X \perp \!\!\! \perp Z & \therefore E(e^{\beta_ZZ} |X) = E(e^{\beta_ZZ}) \text{ is a constant}\\
                                & = e^{\beta_0}e^{\beta_XX} \times k \\
      \Rightarrow \log(E(Y|X))  & = \beta_0 + \beta_XX + \log(k)
\end{aligned}
$$

由此，我們證明了在危險度比的對數鏈接方程的廣義線性回歸模型中，增加非混雜因子變量並不會改變主要暴露變量的回歸係數的參數估計。log risk ratio without adjusting for $Z$ is $\beta_X$, the same value as in the adjusted value. Therefore, a GLM with a log-link do possess the collapsibility property. 

如果你覺得上面的證明你看不懂，我下面自己寫的這個證明可能相對容易一些：

假定 $Z$ 也是二分類變量。

$$
\begin{aligned}
E(Y | X) & =  \text{Pr}(Y = 1 | X) \\
         & = \text{Pr}(Y = 1 | X, Z = 1) \text{Pr}(Z = 1| X) + \text{Pr}(Y = 1 | X, Z = 0)\text{Pr}(Z = 0 | X) \\
         & = \sum_Z \text{Pr}(Y = 1 | X,Z) \text{Pr}(Z | X) \\
         & = \exp(\beta_0 + \beta_XX + \beta_Z) \text{Pr}(Z = 1 | X) + \exp(\beta_0 + \beta_XX ) \text{Pr}(Z = 0 | X) \\
         & = \exp(\beta_0 + \beta_XX) \color{red}{\{\exp(\beta_Z)\text{Pr}(Z = 1 | X) +\text{Pr}(Z = 0 | X)  \}} \\
         & \text{the part in red color is a constant denote as }k \\
         & = \exp(\beta_0 + \beta_XX +  \log(k)) \\
\Rightarrow & \beta_X \text{ was not affected with or without adjusting for }Z
\end{aligned}
$$

# 流行病學中的邏輯迴歸

## 流行病學研究最常用的實驗設計

在流行病學研究中，我們最關心的無非是 暴露變量 (治療方案的選用，或者一些對象的某些特徵如吸菸或飲酒等生活習慣) 與結果變量 (罹患某種我們關心的疾病與否，或者死亡與否) 之間的關係。爲了方便解釋本章暫且只考慮 **單一的結果變量 (univariate)** 的情況，不過不要忘了真實世界中的數據和實驗，我們常要 **同時處理多個不同的結果變量 (multivariate)**。

流行病學最常用的兩種研究設計是：

- 隊列研究/前瞻性研究 cohort or prospective studies；
- 病例對照/回顧性研究 case-control or retrospective studies。

無論是這兩種研究中的哪一種，都要從定義研究的人羣開始 (start by defining some population we wish to study)。例如某個年齡段的男性或者女性；某個特定時間段內，在某特定地區範圍內生活的所有人等。這被定義爲 **潛在研究人羣 (underlying population of interest)**。

如果是**隊列研究**，我們需要對這個潛在研究人羣取樣，選取具 **有代表性的，且有足夠樣本量** 的一羣個體 (隊列) 參與研究。那些我們要研究的 **暴露變量 $(\mathbf{X})$** 被提前定義好，然後在開始研究的時候收集整理成數據庫。之後這個隊列的參與者不斷被隨訪，這個時間段可以是先定義好的 (一年，五年，十年...)，也可以因人而異，最終直至每個個體的結果變量被觀測到 $(D=1 \text{ or } D=0)$。更一般地，如果我們要研究的暴露因素是二分類的，甚至是多分類的，我們可能會使用一些取樣的技巧，從而保證取樣構成的隊列能夠真實地反應該暴露因子在人羣中的分佈情況，保證隊列的代表性。

如果是**病例對照研究**，從它的別名 -- 回顧性研究 -- 也可以看出，它的研究起點和隊列研究相反，是從收集到的病例開始的 $(D=1)$。有了病例以後，我們從人羣中沒有該結果變量 $(D=0)$ 的人羣中，取適合樣本量的人作爲對照組。然後再分別對病例和對照組用採訪或者問卷，或者調取過去的病例記錄/數據庫記錄等等尋找他們是否接觸過我們要研究的暴露變量。

到這裏，如果你還沒暈，恭喜你應該能理解爲什麼說**病例對照研究研究的是 “結果的原因/causes of effect”**；**隊列研究研究的是 “原因導致的結果/effect of causes”**。二者的終極目標卻是一致的 -- 尋找暴露和結果二者之間的關係/To investigate the association between exposures and the outcomes -- 只是手段不同而已。

觀察性研究 (不論是隊列還是病例對照研究)，除了我們一定會測量並收集的暴露變量數據，在分析過程中還不可避免地需要把混雜效應考慮進來，也就是我們還必須測量並收集那些潛在的混雜因子的數據 $(W)$。圖 \@ref(fig:cohort-case-control) 用簡單示意圖總結了 $W (\text{ confounders }), X (\text{ exposures }), D (\text{ outcomes })$ 之間，在不同實驗設計下的關係。


```{r cohort-case-control, echo=FALSE, fig.asp=.7, fig.width=7, fig.cap='Path diagrams showing relationships between variables in the underlying population and selection to a cohort study and a case-control study.', fig.align='center', out.width='90%', cache=TRUE}
knitr::include_graphics("img/Selection_114.png")
```

## 以簡單二分類暴露變量爲例 {#GLM8-3}

### 先決條件

我們以一個最簡單的二分類暴露變量 $(X)$ (例如是否接觸了某種化學試劑)，和一個二分類結果變量 $(D)$ (是否患有食道癌) 爲例展開：

- 觀察對象樣本量爲 $n, i = 1,\cdots,n$；
- $X_i$ 爲一個二分類暴露變量 (是否接觸了某種化學試劑，$1=$是，$0=$否)；
- $D_i$ 爲一個二分類結果變量 (是否有食道癌，$1=$是，$0=$否)。

所以，該研究的潛在研究人羣可以被分成四組：$(X=1,D=1),(X=1,D=0),(X=0,D=1),(X=0,D=0)$。如果用 $\pi_{11}, \pi_{10}, \pi_{01}, \pi_{00}$ 標記每組人在該潛在研究人羣中所佔的比例，那麼有：

$$
\begin{aligned}
\pi_{xd} & = \text{Pr}(X=x, D=d) \\
\pi_{11} &+ \pi_{10} + \pi_{01} + \pi_{00}  = 1
\end{aligned}
(\#eq:GLM8-123)
$$


<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>表 50.1: Probabilities associated with binary explanatory and binary response variables **in the underlying population structure** </caption>
 <thead>
  <tr>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;"> $D$ </div></th>
</tr>
<tr>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;"> $0$ </th>
   <th style="text-align:center;"> $1$ </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> $X$ </td>
   <td style="text-align:center;"> $0$ </td>
   <td style="text-align:center;"> $\pi_{00}$ </td>
   <td style="text-align:center;"> $\pi_{01}$ </td>
  </tr>
  <tr>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> $1$ </td>
   <td style="text-align:center;"> $\pi_{10}$ </td>
   <td style="text-align:center;"> $\pi_{11}$ </td>
  </tr>
</tbody>
</table>



這裏我們應用概率標記法來輔助理解隊列研究：我們從潛在研究人羣中抽樣，觀察其暴露情況，再追蹤其結果變量。所以實際上，**隊列研究的樣本，來自與對暴露與否 $(X=0, X=1)$ 兩組人的抽樣**，所以我們實際求的是，

$$
\begin{equation}
\text{Pr}(D=d|X=x) = \frac{\pi_{xd}}{\pi_{x0} + \pi_{x1}}
\end{equation}
$$



<style type="text/css">
.tg  {border-collapse:collapse;border-color:#ccc;border-spacing:0;}
.tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:0px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:0px;color:#333;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-0lax{text-align:left;vertical-align:top}
.tg .tg-nrix{text-align:center;vertical-align:middle}
</style>
<table class="tg">
<caption>表 50.2: Probabilities associated with binary explanatory and binary response variables **in a cohort study**</caption>
<thead>
  <tr>
    <th class="tg-0lax"></th>
    <th class="tg-baqh" colspan="2"> $D$ </th>
    <th class="tg-nrix" rowspan="2"> $\text{Pr}(D=d|X=x)$</th>
  </tr>
  <tr>
    <td class="tg-0lax"> $X$ </td>
    <td class="tg-0lax"> $0$ </td>
    <td class="tg-0lax"> $1$ </td>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-0lax"> $0$ </td>
    <td class="tg-0lax"> $\pi_{00}$ </td>
    <td class="tg-0lax"> $\pi_{01}$ </td>
    <td class="tg-0lax"> $\frac{\pi_{01}}{\pi_{01} + \pi_{00}}$ </td>
  </tr>
  <tr>
    <td class="tg-0lax"> $1$ </td>
    <td class="tg-0lax"> $\pi_{10}$ </td>
    <td class="tg-0lax"> $\pi_{11}$ </td>
    <td class="tg-0lax"> $\frac{\pi_{11}}{\pi_{10} + \pi_{11}}$ </td>
  </tr>
</tbody>
</table>

<!-- <table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;"> -->
<!-- <caption>表 50.2: Probabilities associated with binary explanatory and binary response variables **in a cohort study**</caption> -->
<!--  <thead> -->
<!--   <tr> -->
<!-- <th style="border-bottom:hidden" colspan="1"></th> -->
<!-- <th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"> $D$ </th> -->
<!-- <th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="1"> $\text{Pr}(D=d|X=x)$</th> -->
<!-- </tr> -->
<!-- <tr> -->
<!--    <th style="text-align:center;"> $X$ </th> -->
<!--    <th style="text-align:center;"> $0$ </th> -->
<!--    <th style="text-align:center;"> $1$ </th> -->
<!--    <th style="text-align:center;">  </th> -->
<!--   </tr> -->
<!--  </thead> -->
<!-- <tbody> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> $0$ </td> -->
<!--    <td style="text-align:center;"> $\pi_{00}$ </td> -->
<!--    <td style="text-align:center;"> $\pi_{01}$ </td> -->
<!--    <td style="text-align:center;"> $\frac{\pi_{01}}{\pi_{01} + \pi_{00}}$ </td> -->
<!--   </tr> -->
<!--   <tr> -->
<!--    <td style="text-align:center;"> $1$ </td> -->
<!--    <td style="text-align:center;"> $\pi_{10}$ </td> -->
<!--    <td style="text-align:center;"> $\pi_{11}$ </td> -->
<!--    <td style="text-align:center;"> $\frac{\pi_{11}}{\pi_{10} + \pi_{11}}$ </td> -->
<!--   </tr> -->
<!-- </tbody> -->
<!-- </table> -->

相反地，病例對照研究中我們從已有的病例 $(D=1)$ 出發，這樣做的理由有很多，通常可能由於病例可能十分稀少，如果建立隊列研究可能需要龐大的樣本量 (即便如此也不一定能夠收集到足夠分析的數據，可能還要花費相當長的隨訪時間，吃力不討好)。所以，在病例對照研究的設計中，我們其實是獨立地從兩個人羣 (病例組，$D=1$，對照組，$D=0$) 中抽取樣本。所以，**病例對照研究獲得的數據，只能用於計算暴露在病例組和對照組中的條件概率**：

$$
\text{Pr}(X=x|D=d) = \frac{\pi_{xd}}{\pi_{0d}+\pi_{1d}}
$$


<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>表 50.3: Separate samples from subpopulations $D=0,1$ with relavant conditional probabilities **in a case-control study** </caption>
 <thead>
  <tr>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;"> $D$ </div></th>
</tr>
<tr>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;"> $0$ </th>
   <th style="text-align:center;"> $1$ </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> $X$ </td>
   <td style="text-align:center;"> $0$ </td>
   <td style="text-align:center;"> $\pi_{00}$ </td>
   <td style="text-align:center;"> $\pi_{01}$ </td>
  </tr>
  <tr>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> $1$ </td>
   <td style="text-align:center;"> $\pi_{10}$ </td>
   <td style="text-align:center;"> $\pi_{11}$ </td>
  </tr>
  <tr>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> $\text{Pr}(X=x|D=d)$ </td>
   <td style="text-align:center;"> $\frac{\pi_{10}}{\pi_{10}+\pi_{00}}$ </td>
   <td style="text-align:center;"> $\frac{\pi_{11}}{\pi_{11}+\pi_{01}}$ </td>
  </tr>
</tbody>
</table>

### 比值比 Odds ratios

某研究的數據中，暴露變量是二分類的 $X$，和 結果變量是二分類的 $D$。我們其實最關心的問題是：結果變量的兩個分類 $D=0, D=1$，在暴露變量 $X=0, X=1$ 兩組中到底個佔多少比例。用吸菸與肺癌的例子來解釋就是，我們最關心的是，在吸菸人羣中，發生肺癌的人的比例，是否顯著地高於非吸菸人羣中發生肺癌的人的比例，僅此而已。這句話用概率論的標記法來寫的話，則是兩個條件概率：$\text{Pr}(D=1|X=1), \text{Pr}(D=1|X=0)$。此處，可以定義暴露變量 $X=1$ 的條件下，結果變量 $D=1$ 的概率的比值 (Odds)：

$$
\text{Odds}_1 = \frac{\text{Pr}(D=1|X=1)}{1-\text{Pr}(D=1|X=1)} = \frac{\pi_{11}/(\pi_{10} + \pi_{11})}{1-\pi_{11}/(\pi_{10} + \pi_{11})}
$$

類似地，暴露變量 $X=0$ 的條件下，結果變量 $D=1$ 的概率的比值 (Odds)：

$$
\text{Odds}_2 = \frac{\text{Pr}(D=1|X=0)}{1-\text{Pr}(D=1|X=0)} = \frac{\pi_{01}/(\pi_{01} + \pi_{00})}{1-\pi_{01}/(\pi_{01} + \pi_{00})}
$$

故，從隊列研究中，可以很自然的計算暴露變量和結果變量的比值比：

$$
\begin{aligned}
\text{Odds Ratio}_{\text{cohort}} = \frac{\text{Odds}_1}{\text{Odds}_2} & = \frac{\frac{\text{Pr}(D=1|X=1)}{1-\text{Pr}(D=1|X=1)}}{\frac{\text{Pr}(D=1|X=0)}{1-\text{Pr}(D=1|X=0)}}\\
 & = \frac{\frac{\pi_{11}/(\pi_{10} + \pi_{11})}{1-\pi_{11}/(\pi_{10} + \pi_{11})}}{\frac{\pi_{01}/(\pi_{01} + \pi_{00})}{1-\pi_{01}/(\pi_{01} + \pi_{00})}} \\
 & = \frac{\frac{\pi_{11}/(\pi_{10}+\pi_{11})}{\pi_{10}/(\pi_{10}+\pi_{11})}}{\frac{\pi_{01}/(\pi_{01}+\pi_{00})}{\pi_{00}/(\pi_{01}+\pi_{00})}} \\
 & = \frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}
\end{aligned}
$$

從病例對照研究中，推算的暴露變量和結果變量的比值比是另外一個過程：

$$
\begin{aligned}
\text{Odds Ratio}_{\text{case-control}} = \frac{\text{Odds}^\prime_1}{\text{Odds}^\prime_2} & = \frac{\frac{\text{Pr}(X=1|D=1)}{1-\text{Pr}(X=1|D=1)}}{\frac{\text{Pr}(X=0|D=0)}{1-\text{Pr}(X=0|D=0)}} \\
& = \frac{\frac{\pi_{11}/(\pi_{11} + \pi_{01})}{1-\pi_{11}/(\pi_{11} + \pi_{01})}}{\frac{\pi_{10}/(\pi_{10} + \pi_{00})}{1-\pi_{10}/(\pi_{10} + \pi_{00})}} \\
& = \frac{\frac{\pi_{11}/(\pi_{11}+\pi_{01})}{\pi_{01}/(\pi_{11}+\pi_{01})}}{\frac{\pi_{10}/(\pi_{10}+\pi_{00})}{\pi_{00}/(\pi_{10}+\pi_{00})}} \\
& =  \frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}
\end{aligned}
$$

經過上面的推演，我們發現用病例對照研究的數據，**雖然不能像隊列研究一樣直接推算正確的暴露條件下的比值 (conditional odds given exposure)**，**卻能用較少的樣本量中獲得真實的比值比 (OR) **。

### 邏輯迴歸應用於病例對照研究的合理性 {#GLM8-3-4}

在一個**隊列研究**中，當我們有不止一個暴露變量時，顯然就需要更加複雜的模型來輔助分析 (迴歸型分析法) 暴露變量和結果變量之間的關係。估計比值比最佳的模型是邏輯迴歸。如果 $D$ 表示一個隨機型結果變量，其中每個觀察對象的結果變量服從暴露變量的條件二項分佈 (繼續用單一的**二分類暴露變量** $x_i$)：

$$
D_i|X_i = x_i \sim \text{Binomial}(1, \pi_i)
$$

所以，可以用邏輯迴歸來擬合：

$$
\text{logit}(\pi_i) = \text{log}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta x_i
$$

把這個邏輯迴歸方程重新整理：

$$
\begin{aligned}
\text{Pr}(D=1|X=1) & = \frac{e^{\alpha + \beta}}{1 + e^{\alpha + \beta}} \\
\text{Pr}(D=1|X=0) & = \frac{e^\alpha}{1 + e^\alpha} \\
\text{Where, }\alpha & =  \text{log}{\frac{\pi_{01}}{\pi_{00}}} \\
\beta & = \text{log}{\frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}}
\end{aligned}
$$

在一個**病例對照研究**中，結果變量 $D_i$ 被鎖死，暴露變量成了服從結果變量的條件二項分佈的隨機變量：

$$
X_i | D_i = d_i \sim \text{Binomial}(1,\pi_i^*)
$$

繼續任性地用邏輯迴歸擬合的話：

$$
\text{logit}(\pi_i^*) = \text{log}(\frac{\pi_i^*}{1-\pi_i^*}) = \alpha^* + \beta d_i
$$

同樣整理成概率方程：

$$
\begin{aligned}
\text{Pr}(X=1|D=1) & = \frac{e^{\alpha^* + \beta}}{1 + e^{\alpha^* + \beta}} \\
\text{Pr}(X=1|D=0) & = \frac{e^{\alpha^*}}{1 + e^{\alpha^*}} \\
\text{Where, }\alpha & =  \text{log}{\frac{\pi_{10}}{\pi_{00}}} \\
\beta & = \text{log}{\frac{\pi_{11}\pi_{00}}{\pi_{10}\pi_{01}}}
\end{aligned}
$$

所以，用邏輯迴歸擬合病例對照研究的數據，同樣可以得到和隊列研究一樣正確的比值比估計。但是這個截距 $\alpha$，**在隊列研究中指的是，非暴露組中患病的比值的對數 (log odds of disease in the unexposed)**；**在病例對照研究中指的是，對照組中暴露的比值的對數 (log odds of exposure in the controls)**。是兩個完全不同含義的估計量。

綜上所述，從一個**隊列研究獲得的似然方程**是：

$$
\begin{aligned}
L_{\text{cohort}} & = \prod_{i=1}^n(\frac{e^{\alpha + \beta x_i}}{1+e^{\alpha + \beta x_i}})^{d_i}(\frac{1}{e^{\alpha + \beta x_i}})^{1-d_i} \\
\text{Where } d_i & = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the outcome}\\  1 \text{ if subjects were observed with the outcome}\\ \end{array} \right. \\
              x_i & = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the exposure}\\  1 \text{ if subjects were observed with the exposure}\\ \end{array} \right.
\end{aligned}
$$

從一個**病例對照研究獲得的似然方程**是：


$$
\begin{aligned}
L_{\text{case-control}} & = \prod_{i=1}^n(\frac{e^{\alpha + \beta d_i}}{1+e^{\alpha + \beta d_i}})^{x_i}(\frac{1}{e^{\alpha + \beta d_i}})^{1-x_i} \\
\text{Where } d_i & = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the outcome}\\  1 \text{ if subjects were observed with the outcome}\\ \end{array} \right. \\
              x_i & = \left\{ \begin{array}{ll}  0 \text{ if subjects were not observed with the exposure}\\  1 \text{ if subjects were observed with the exposure}\\ \end{array} \right.
\end{aligned}
$$

## 拓展到多個暴露變量的邏輯迴歸模型

現在來考慮 $p$ 個暴露變量的情況：$X_1, \cdots, X_p$，這些暴露變量可以是分類型變量，也可以是連續型變量，例如，

- $D_i = 0 \text{ or } 1$，第 $i$ 名研究對象觀察到有 $(=1)$，或沒有 $(=0)$ 結果變量 (如發生胰腺癌)；
- $X_{i1} = 0 \text{ or } 1$，第 $i$ 名研究對象有 $(=1)$，或沒有 $(=0)$ 暴露變量 (如吸菸)；
- $X_{i2} = 0 \text{ or } 1$，第 $i$ 名研究對象是男性 $(=1)$，或女性 $(=0)$；
- $X_{i3}$，第 $i$ 名研究對象的年齡 (years)。

### Mantel Haenszel 法

如果數據有且只有兩個暴露變量，$X_1, X_2$，其中 $X_1$ 是一個二分類變量，$X_2$ 是一個可以分成 $C$ 組的分類變量。那麼如果樣本量足夠大，可以把數據整理成 $C$ 個四格表用於分析每一個 $X_2$ 的分層中 $X_1$ 和結果變量 $D$ 之間的關係。多層數據的合併比值比可以用 [Mantel Haenszel 法](https://en.wikipedia.org/wiki/Cochran%E2%80%93Mantel%E2%80%93Haenszel_statistics)。此法在兩個分類暴露變量的情況下還能適用，當某個(或兩個)分類變量的層數越來越多時，你會發現最終落到小格子裏的樣本量急劇下降，侷限性就體現了出來。另外，此法亦不能應用於連續型變量的調整，用處簡直就是捉襟見肘。迫切地我們需要有更加一般的 (藉助於迴歸的威力的) 方法來對多個暴露變量進行調整。

### 隊列研究和病例對照研究的似然

一個**隊列研究**，用邏輯迴歸擬合其結果變量 (因變量) $D$ 和暴露變量 $X_1, \cdots, X_p$ 之間的關係時，可以寫作：

$$
\begin{aligned}
D_i=1 | (X_{i1} & = x_{i1}, \cdots, X_{ip} = x_{ip}) \sim \text{Binomial}(1, \pi_i) \\
\text{logit} (\pi_i) & = \text{log}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}
\end{aligned}
$$

將這個迴歸方程重新整理成爲概率方程：

$$
\text{Pr}(D_i = 1 | X_{i1}  = x_{i1}, \cdots, X_{ip} = x_{ip}) = \frac{e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}
$$

- 截距 $\alpha$ 的含義是，當所有的暴露變量都取 $0$ 時，研究對象觀察到結果變量爲 $1$ 的對數比值 $(\text{log odds})$；
- 迴歸係數 $\beta_k$ 的含義是，當其餘的暴露變量保持不變時，$x_k$ 每增加一個單位，結果變量爲 $1$ 的對數比值比 $(\text{log odds-ratio})$ (即，調整了其餘所有變量之後，$x_k$ 和結果變量之間的對數比值比)。

所以，隊列研究的數據，其似然方程是：

$$
\begin{aligned}
L_{\text{cohort}} & = \prod_{i=1}^n\text{Pr}(D_i = d_i |  X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip}) \\
                  & = \prod_{i=1}^n\text{Pr}(\frac{e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{d_i}(\frac{1}{1+e^{\alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{1-d_i}
\end{aligned}
$$

當數據變成了**病例對照研究**，其似然方程會變成怎樣呢？

$$
L_{\text{case-control}} = \prod_{i=1}^n\text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |D_i = d_i)
$$

這裏，我們很難看出這到底是怎樣的一個條件概率，如果預測變量中同時包括了連續型變量和分類變量，情況就更加複雜，剪不斷理還亂。

### 病例對照研究中的邏輯迴歸

用 $\text{Pr}(S_i=1 \text{ or } 0)$ 表示在潛在研究人羣 (underlying study population) 中，被抽樣 (或者沒有被抽樣) 進入該隊列研究的概率。那麼，理想情況下，可認爲實施病例對照研究時，病例是稀少的，即我們收集到的病例，幾乎等價於我們關心的潛在研究人羣中全部的病例，且可以被證明：

$$
\begin{aligned}
 & \text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |D_i = 1) \\
=& \text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |D_i = 1, S_i=1) \\
=& \frac{e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}  \\
 & \;\;\;\; \times \frac{\text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |S_i=1)}{\text{Pr}(D_i = 1 | S_i = 1)} \\
\text{Where } \alpha^* & =  \alpha + \text{log}(\frac{\text{Pr}(D_i = 0)}{\text{Pr}(D_i = 1)}) + \text{log}(\frac{\text{Pr}(D_i = 1|S_i=1)}{\text{Pr}(D_i = 0|S_i=1)})
\end{aligned}
(\#eq:GLM8-2526)
$$

概率方程 \@ref(eq:GLM8-2526) 中，可以看出第一部分 $\frac{e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}$ 是一個邏輯迴歸模型。跟隊列研究的邏輯迴歸模型相比較，差別只是截距不同 $\alpha \neq \alpha^*$。其餘的部分如 $\text{Pr}(X_{i1} = x_{i1}, \cdots, X_{ip} = x_{ip} |S_i=1)$ 的含義是潛在人羣中被取樣放入該隊列研究，且預測變量各自不同的隨機概率分佈，其實和我們尋找的參數 $\beta_1,\cdots,\beta_p$，是沒有什麼關係的。最後一部分分母的 $\text{Pr}(D_i = 1 | S_i = 1)$ 的意思是，結果變量爲 $1$ 的人被選入本項病例對照研究的概率，理想的實驗設計下這被認爲是接近於 $1$ 的，即使不是，它也是一個固定不變的常數。所以，病例對照研究的似然方程中，我們關心的只有第一部分，邏輯迴歸模型：

$$
L_{\text{case-control}} \propto \prod_{i=1}^n(\frac{e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{d_i}(\frac{1}{1+e^{\alpha^* + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}}})^{1-d_i}
$$

這裏必須明確的一點是，病例對照研究擬合的邏輯迴歸，其截距是 $\alpha^*$，並非 $\alpha$。這個 $\alpha^*$ 其實是包含了 $\text{Pr}(D_i=1),\text{Pr}(D_i=0)$ 的，可惜這些概率也無法用病例對照研究設計獲得。所以，**病例對照研究數據擬合了邏輯迴歸模型以後的截距，其實沒有太多實際的含義**。

## 流行病學研究中變量的調整策略


```{r epi-adjustment, echo=FALSE, fig.asp=.7, fig.width=7, fig.cap='relationships between three variables in an underlying population of interest', fig.align='center', out.width='90%', cache=TRUE}
knitr::include_graphics("img/Selection_115.png")
```

圖 \@ref(fig:epi-adjustment) 展示的是在潛在研究人羣中 $W (\text{potential confounder}),X (\text{exposure}),D (\text{outcome})$ 三者之間可能存在的四種關係。

- 圖 \@ref(fig:epi-adjustment) - (a) $W$ 和 $X, D$ 都沒有關係，那麼我們研究 $X,D$ 之間的關係時，完全可以忽略掉 $W$，不用調整。<br> 但是，如果在邏輯迴歸模型中調整了一個和暴露變量結果變量之間無關的變量，獲得的比值比估計幾乎不會有太大改變，但是代價是會獲得較大的對數比值比的**標準誤 (standard error)，降低了對比值比估計的精確程度**。
- 圖 \@ref(fig:epi-adjustment) - (b) $W$ 和 $X, D$ 同時都相關，且不在 $X\rightarrow D$ 的因果關係通路上，此種情況下，必須對 $W$ 進行調整，否則獲得的比值比估計是帶有嚴重偏倚的。
- 圖 \@ref(fig:epi-adjustment) - (c) $W$ 僅僅和 $X$ 有關係，和結果變量 $D$ 沒有相關性。此時研究 $X,D$ 之間的關係時，忽略掉 $W$，不需要對之進行任何調整。和 (a) 一樣，如果此時調整了 $W$，估計的比值比不會發生質變，但是會損失估計的精確度。
- 圖 \@ref(fig:epi-adjustment) - (d) $W$ 僅僅和結果變量 $D$ 有關係，和暴露變量 $X$ 無關時，如果模型對 $W$ 進行調整，我們會獲得完全不同的比值比估計，因爲這種情況下其實調整 $W$ 前後的比值比估計的是具有不同含義的，二者都具有實際意義。調整前的估計量，是總體估計，有助於作總體的決策；調整後的估計量，是帶有某些特徵的部分人羣估計，有助於評價個人水平的 $X,D$ 之間的關係。

## GLM Practical 08

### Part 1

在第一部分的數據分析中，我們會使用邏輯回歸模型來分析來自病例對照研究設計的數據，並獲取比值比 (odds ratios)。

該病例對照研究數據來自一項關於食道癌的研究。病例是200名被診斷爲患有食道癌的法國男性。對照組則來自176名健康男性。你可以從作者的[個人網站](http://faculty.washington.edu/norm/datasets.html)下載原始數據。

# 分析策略

## 明確分析目的

作爲統計學家，着手分析數據之前，千萬記得，必須要制定一個儘可能詳盡的分析計劃。即使你的分析，可能並不一定受到第三方的監管或者調控，因爲同行評審的專家們，喜歡看到你分析的目的明確，假設檢驗的過程是經過仔細推敲的。同時，也可以避免陷入 “[玩弄數據 (data dredging)](https://en.wikipedia.org/wiki/Data_dredging)” 指控的危險。

數據分析的目的，可以分成三大類：

1. 估計一個或者幾個暴露變量，對結果變量的影響。以此目的的數據分析過程，需要我們有[醫學偵探](https://en.wikipedia.org/wiki/John_Snow)一樣的眼光和見解，從數據中判斷那些需要被調整和控制的混雜因子，從而提高你的分析效率。最常見的例子是分析隨機對照臨牀實驗 (RCT) 中，療效的差異；或者流行病學研究中，分析某種生活習慣，和疾病的發生或者死亡之間的關係。
2. 在現有的數據庫中，尋找並且建立 “最佳” 模型。以此目的的數據分析，需要我們對模型中的結果變量有極爲深入的瞭解，把與之相關的**所有要因**，儘可能多的納入你的分析模型。常見的例子如，在某個特定人羣的數據庫中尋找並確定能夠決定自殺這一結果變量的決定性因素，之所以有這樣的目的，背後可能有決策者希望尋找這些決定性因素後採取一些對策從而達到改善現狀的最終目的。所以找到和結果變量相關的因素，是此類研究的重中之重。
3. 建立預測模型。例如，某項研究的目的是爲了能夠建立一個能夠預測孕期胎兒患有唐氏綜合症的預測模型，用能夠測量的一些指標(如血液指標，或者母親的一些健康指標)，通過模型的算法，去計算胎兒患病的概率是多大。這樣的模型，對與診斷醫學有重大意義。所以，此類研究的目的，不是爲了尋找確定和胎兒患病相關的全部要因，而是**怎樣才能提高模型預測的準確度**，提高診斷的效率，減少錯誤診斷，拯救生命。

當然，上述目的中的 2 和 3 有時候易讓人混淆，因爲我們可能建立最佳模型，除了想要找到和 “自殺” 這一結果相關的所有要因，還可能希望通過該模型做出預測，尋找可能自殺的高危人羣，進行干預。這並不矛盾。

## 分析目的 1.1 -- 估計 RCT 中治療效果 (treatment effect)

先揀最軟的柿子捏，RCT 的療效比較作爲數據分析的目的時，情況要比其他的目的相對簡單些。RCT 的隨機過程，確保了臨牀試驗不會受到混雜因素的影響。但是我們還會出於爲了**提高統計分析效能**，**改善估計的精確度**的目的，對參與臨牀試驗的受試者最初測量的一些特徵進行調整。當然，不是所有的數據專家，也不是所有的 RCT 實施者都同意進行這一調整的。如果確定要調整，放入模型中的變量，可能常常是一開始隨機分配時用到的那些用於將受試者分層歸類或者最小化 (minimisation) 的那些變量。

基線值調整 (baseline adjustment)，在結果變量爲**連續型，同時模型是線性迴歸模型**時，能夠顯著提高統計效能 (statistical efficiency)，降低估計值的標準誤。理論上，一個基線測量時的連續型變量，如果它和實驗後測量的連續型結果變量之間的 **皮爾森相關係數 Pearson correlation coefficient** 是 $r$，那麼如果你用 ANCOVA 模型調整了這個基線值的話，療效差異估計值的標準誤會是沒有調整時的 $\sqrt{1-r^2}$ 倍 (也就是永遠比不調整時要小，大大提高精確度，縮小療效差異估計值的 95% 信賴區間)。

但是，但是，但是！如果一個 RCT 測量的結果變量是一個二分類變量 (死亡/存活)，線性迴歸模型不適用，只能使用邏輯迴歸時，模型中加入和結果變量相關 (和暴露變量無關) 的基線值的做法对分析效能的提高顯得十分有限，相反還会受到邏輯迴歸的不可壓縮性較大的影響 (Section \@ref(collapsibility))。

再把之前講邏輯迴歸不可壓縮性時用过的例子拿过来这里解释这个现象：


<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>表 51.1: **Non-collapsibility** of logit link in GLM **(stratified data)**</caption>
 <thead>
  <tr>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;> Strata 1 </div></th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;> Strata 2 </div></th>
</tr>
<tr>
   <th style="text-align:center;"> Outcome </th>
   <th style="text-align:center;"> Drug </th>
   <th style="text-align:center;"> Placebo </th>
   <th style="text-align:center;"> Drug </th>
   <th style="text-align:center;"> Placebo </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> Success </td>
   <td style="text-align:center;"> 90 </td>
   <td style="text-align:center;"> 50 </td>
   <td style="text-align:center;"> 50 </td>
   <td style="text-align:center;"> 10 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Failure </td>
   <td style="text-align:center;"> 10 </td>
   <td style="text-align:center;"> 50 </td>
   <td style="text-align:center;"> 50 </td>
   <td style="text-align:center;"> 90 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Total </td>
   <td style="text-align:center;"> 100 </td>
   <td style="text-align:center;"> 100 </td>
   <td style="text-align:center;"> 100 </td>
   <td style="text-align:center;"> 100 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Odds Ratios </td>
   <td style="text-align:center;"> 9 </td>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> 9 </td>
   <td style="text-align:center;">  </td>
  </tr>
</tbody>
</table>

上面的數據表示，分層變量 (Strata 1-2) 本身和使用藥物和安慰劑無交互作用，也和藥物使用與臨牀試驗結果之間的關係無關。但是，即使這個分類變量無關，壓縮後的數據計算獲得的比值比和分層時的比值比差異巨大：

<table class="table table-striped table-bordered" style="margin-left: auto; margin-right: auto;">
<caption>表 51.2: **Non-collapsibility** of logit link in GLM **(collapsed data)**</caption>
 <thead>
  <tr>
   <th style="text-align:center;"> Outcome </th>
   <th style="text-align:center;"> Drug </th>
   <th style="text-align:center;"> Placebo </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> Success </td>
   <td style="text-align:center;"> 140 </td>
   <td style="text-align:center;"> 60 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Failure </td>
   <td style="text-align:center;"> 60 </td>
   <td style="text-align:center;"> 140 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Total </td>
   <td style="text-align:center;"> 200 </td>
   <td style="text-align:center;"> 200 </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Odds ratio </td>
   <td style="text-align:center;"> 5.4 </td>
   <td style="text-align:center;">  </td>
  </tr>
</tbody>
</table>

實際在 R 裏擬合邏輯迴歸模型的結果如下：


```{r GLM-0510, echo=FALSE, cache=TRUE}
Strata <- c(rep("1",200), rep("2", 200))
Treatment <- c(rep("Drug", 100), rep("Placebo", 100), rep("Drug", 100), rep("Placebo", 100))
Result <- c(rep(1,90), rep(0,10), rep(1,50), rep(0,50),
            rep(1,50), rep(0,50), rep(1,10), rep(0,90))
RCT <- data.frame(Strata, Treatment, Result)

#with(RCT, table(Result, Treatment, Strata))

Model1 <- glm(Result ~ Treatment, family=binomial(link = logit),
              data = RCT)
summary(Model1)

Model2 <- glm(Result ~ Treatment + Strata, family=binomial(link = logit),
              data = RCT)
summary(Model2)
```

從結果的迴歸係數估計和計算的標準誤來看，調整了其他的變量會引起：

1. 使對數比值比的估計量升高 (這是由於模型的不可壓縮性) $1.69 \rightarrow 2.19$；
2. 對數比值比的標準誤估計升高 (非但不能增加估計精確度，反而起到了反作用) $0.22\rightarrow0.27$；
3. 對數比值比的統計檢驗量升高 (由於對數比值比的升高比標準誤升高的更多一些) $7.77\rightarrow7.99$。

事實上，上面的現象在使用邏輯迴歸的時候基本上都會呈現。在經典論文 [@Robinson1991] 中給出了詳細的論證。所以其實使用邏輯迴歸擬合數據的 RCT 臨牀試驗，我們可以推論，**當模型中加入第三個僅和結果變量有關的基線共變量** (baseline covariates)，如果模型估計的對數比值比在調整前後變化不大 (即，不可壓縮性造成的影響很小)，那這樣的調整對於改善分析的統計效能上幾乎也沒有貢獻。(跟使用線性迴歸的 RCT 完全不同！)

由於邏輯迴歸受使用 $\text{logit}$ 鏈接方程時不可壓縮性的侷限，同時還由於使用 $\text{log}$ 鏈接方程時獲得的危險度比 (risk ratios) 比比值比 (odds ratios) 更加容易讓人理解，結果變量爲二分類的 RCT 臨牀試驗常常會選用 $\text{log}$ 鏈接方程的廣義線性迴歸模型 (見 Section \@ref(logit-or-log) 第 5 條討論)。選用 $\text{log}$ 鏈接方程的 GLM 最大的問題在於，當模型中**加入過多的預測變量**時，會導致模型**無法收斂 (converge)--無法找到極大似然估計**。

至於使用泊松迴歸模型的時候，預測變量如果放入不合理，那麼很容易違反泊松分佈的前提 (方差和均值相同)。對於違反了泊松分佈前提，模型變得過度離散 (over-dispersed) 的 GLM，加入適當的基線共變量 (baseline covariates) 則有助於減少模型的過度離散，減小參數估計的標準誤 (使之變得更精確些)。和線性迴歸相同的是，泊松迴歸模型不受不可壓縮性 (non-collapsibility) 的影響。

### RCT 數據分析的一些不成熟的小建議

1. RCT 臨牀試驗通常都有嚴格的數據管理和監控，且統計分析計劃 (statistical analysis plan, SAP) 在任何一個 RCT 都已經是必須條件。除此之外，還要在試驗進行前就制訂所有詳細的計劃，並寫成實驗實施計劃文件，以供參與的所有人及倫理審查委員會等各種第三方機構的監督。所以，RCT 的統計分析計劃必須儘量考慮到所有的可能情況，因爲一旦開始了試驗，分析計劃是很難改動的。
2. SAP 必須詳細記錄哪些共變量需要被調整，常見的是實驗設計階段用於實施隨機化過程的那些特徵變量。對於連續型結果變量，(還有過度離散的計數型變量)，基線共變量的調整許多時候會有助於改善參數估計的精確度，提高統計效能。對於使用邏輯迴歸模型的試驗，調整基線共變量則沒有太多的好處，且調整後的比值比的含義會發生較大的改變，需慎重。
3. 有些統計學家支持調整基線共變量，認爲這樣做有助於減少萬一隨機化不徹底造成的治療組和對照組之間隨機產生的殘差偏倚 (residual bias)，但是你無法提前欲知那些變量可能會產生隨機的殘差偏倚，這樣便無法在事先需要準備的SAP計劃文件中明確到底哪些基線變量需要被調整。
4. 另有許多研究者喜歡在 RCT 中尋找交互作用的存在，但是他們常常忽略掉的一點是，一個 RCT 本身的檢驗效能是 80%-90%，其用於檢驗交互作用的效能會更低。建議在 RCT 中儘量少 (甚至不建議) 進行任何交互作用的統計檢驗。

## 分析目的 1.2 -- 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)

前文討論的關於調整僅僅和結果變量相關 (與暴露變量無關) 的基線共變量的內容，同樣適用與一般的流行病學研究。流行病學研究中另一個 (應該是更加) 重要的點是，混雜因子的排查和調整。

實例：

- $Y$ 標記結果變量，如嬰兒的出生體重；
- $X_1$ 標記最主要的 (想要分析其與結果變量之間的關係的) 預測變量，如母親孕期高血壓 (是/否)；
- $X_2, X_3, \cdots, X_Q$ 標記其他非主要預測變量，但是可能是 $X_1, Y$ 之間關係中重要的潛在混雜因子，如嬰兒的性別/母親孕前體重/嬰兒胎齡等等。

在這個簡單流行病學研究實例中，我們關心的問題包括：

1. 主要暴露變量--孕期高血壓，和結果變量--嬰兒出生體重二者的未调整前 (粗) 關係 (crude/before adjustment association) 是什麼樣的？
2. 主要暴露變量和結果變量之間的關係是否被其他因素影響 (例如胎齡)？如果有，那麼調整後的關係會發生怎樣的變化？
3. 有沒有其他的變量會改變 (modify) 主要暴露變量和結果變量之間的關係？也就是，有沒有那個變量和主要暴露變量有交互作用？
4. 有沒有其他的變量和主要暴露變量無關，卻可能和結果變量有關係呢？如果存在這樣的變量，模型中調整它在一些情況下可能會改善擬合的結果提高模型的統計效能 (statistical power)。
5. 收集的變量中，有沒有哪個變量可能是在主要暴露變量和結果變量之間因果關係 (如果存在因果關係的話) 的通路上 (on the causal pathway) 的呢？如果有，這樣的變量應該被認爲是媒介因子 (mediator)。

### 不成熟的小策略

這是很常見的簡單流行病學數據分析。可以按照 (但不一定非要按照) 下面建議的步驟實施統計分析：

1. 第一步，分析主要暴露變量和結果變量之間的未調整前 (粗) 關係： <br> $$g\{ E(Y|X_1) \} = \alpha + \beta_1 X_1$$
2. 第二步，逐個分析**其餘的變量和主要暴露變量之間的關係**，以及這些**潛在的混雜因子和結果變量之間的關係**。注意，這一步可能耗時較長，但是它並不是決定模型中是否要加入某個或某些非主要暴露變量的步驟，通過**這一步過程有助於我們分析和理解，進一步分析中調整前後的參數估計變化**。
3. 第三步，建立主要暴露變量和這些潛在混雜因子同時放入模型中的 GLM，逐步放入，**一次放入一個 (one at a time) 潛在混雜因子**，和上一步分析的三者之間的關係相結合，分析調整該潛在混雜因子前後，主要暴露變量的迴歸係數的參數估計變化的原因。<br> $$g\{ E(Y|X_1, X_k) \} = \alpha^* + \beta_1^*X_1 + \beta_kX_k,\; k= 1,\cdots,Q$$

我們來分析這個可以從 [Stata 網站上下載的數據](http://www.stata-press.com/data/r12/lbw.dta)：

- 第一步，先看看暴露變量和結果變量之間的關係

```{r  GLM-0511, cache=TRUE, warning=FALSE, message=FALSE}
lbw <- read_dta("http://www.stata-press.com/data/r12/lbw.dta")
lbw$race <- factor(lbw$race)
lbw$smoke <- factor(lbw$smoke)
lbw$ht <- factor(lbw$ht)
a <- Epi::stat.table(list("Birthweight <2500g" = low, "History of hypertension"=ht), list(count(),percent(low)), data = lbw, margins = TRUE)
# We first tabulate the data
print(a, digits = c(percent = 2))
```

- 第二步，分析母親高血壓病史和嬰兒低出生體重之間的調整前 (粗) 關係。

```{r  GLM-0512, cache=TRUE}
Model0 <- glm(low~ht, data = lbw, family = binomial(link = "logit"))
summary(Model0); epiDisplay::logistic.display(Model0)
```

所以，數據提供了一些證據證明母親的高血壓病史和嬰兒低出生體重之間可能存在正關係，這個調整前的關係是，粗比值比 (crude odds ratio) 爲 3.37 (1.02, 11.09)。

- 接下來，分析潛在的混雜因子是否和主要暴露變量相關：

```{r  GLM-0513, cache=TRUE}
# lwt is the last weight of mothers before pregnancy
Model1 <- lm(lwt ~ ht, data = lbw)
summary(Model1); epiDisplay::regress.display(Model1)
```

可見，有高血壓病史的母親，孕前體重較高。再看其與結果變量是否有關係：

```{r  GLM-0514, cache=TRUE}
Model2 <- glm(low ~ lwt, data = lbw, family = binomial(link = "logit"))
summary(Model2); epiDisplay::logistic.display(Model2)
```

由此知，母親孕前體重較高的人，有較低的可能剩下低出生體重的嬰兒。這兩個單獨的關係，各自看都具有 5% 的統計學意義，但是這 (或者其他變量分析的結果沒有統計學意義時) 並不是決定模型中是否加入母親孕前體重這一潛在的混雜因子的理由。接下來，我們通過模型中加入母親孕前體重這一變量前後模型的參數估計變化來分析：

```{r  GLM-0515, cache=TRUE}
Model3 <- glm(low ~ ht + lwt, data = lbw, family = binomial(link = "logit"))
summary(Model3);epiDisplay::logistic.display(Model3)
```

加入了孕前體重的模型給出的母親是否有高血壓病史對嬰兒的低出生體重關係的比值比估計爲 $6.39$，這很明顯比調整孕前體重前的粗比值比 $(3.37)$ 大了很多。這個比值比估計的變化有兩個原因：

1. (常被忽略的) 邏輯迴歸模型的不可壓縮性導致的；
2. 母親孕前體重對高血壓病史和嬰兒的低出生體重之間的關係造成了混雜效應。

上面的分析結果，告訴我們，數據提供了足夠的證據證明母親孕前體重和是否有高血壓病史，在調整了彼此之後，仍然獨立地和嬰兒低出生體重的發生有相關性。這裏，我們可以下結論認爲，模型中加入母親孕前體重作爲混雜因子，是合情合理的。

完成了目前爲止的初步分析和混雜因子的判斷以後，下一階段的分析側重於尋找有沒有任何第三方的預測變量，會對主要暴露變量 $X_1$ (孕期高血壓) 與結果變量 $Y$ (嬰兒出生體重過低) 之間的關係產生交互作用。如果數據中的預測變量有多個，那可能導致需要分析潛在的交互作用有許多對，通常建議在遇到多個預測變量之間的複雜關係需要討論的時候，建議不要一股腦全部作交互作用的分析，而是限定一個或者幾個最有可能有交互作用的變量就可以了。否則模型過於複雜，反而不利於理解。一般生物醫學的統計分析中考慮的重要交互作用分析，需要有重要的生物學意義，常見的例子是年齡，性別等。


本節使用的例子中，令人感興趣的是，母親的孕前體重，會不會對妊娠高血壓的有無與嬰兒出生體重過低之間的關係造成交互作用：

```{r  GLM-0516, cache=TRUE, message=FALSE, warning=FALSE}
Model4 <- glm(low ~ ht*lwt, family = binomial(link = "logit"), data = lbw)
summary(Model4); epiDisplay::logistic.display(Model4)
```

由於交互作用項結果爲 `ht1:lwt      0.003732   0.016173   0.231  0.81749`，無足夠的證據證明孕前體重會對妊娠高血壓和嬰兒出生體重過低之間的關係造成交互作用。

如果確認沒有交互作用，建立本例最終模型前的幾個建議：

1. 最終分析 $X_1, Y$ 之間關係的模型，需要加入我們逐一甄別之後確認過的混淆因子，此時稱爲**模型 1**；
2. 對於確認不是 $X_1, Y$ 之間關係的混淆因子的那些剩餘變量，逐一加入**模型 1**，比較前後是否模型中各個混淆因子的參數估計是否發生了變化 (有沒有混淆因子的混淆因子？)；
3. 最終模型中的變量，需要包含前兩步確認過的全部混淆因子；
4. 在報告中把調整前後的參數估計整理成表格。

如果在分析過程中發現了有重要意義的交互作用，那麼除了包含全部的混淆因子之外，你的最終模型中還需加入重要的交互作用項。此時需要報告的參數估計是有交互作用項部分的分層比值比/其他指標。

### 補充

除了使用二項分佈的邏輯迴歸之外，當結果變量是連續型或者計數型，也就是分析模型使用線性迴歸 (ANCOVA)，或者 (可能過度離散的) 泊松迴歸時，爲了提高模型的統計效能，減小參數估計的標準誤，模型可以選擇進一步調整一個或幾個**只和結果變量有關的基線變量**。此時，在你寫論文或者報告時，**必須把這些變量和確認是混雜因子的變量加以區分**，因爲加它們進入模型的目的不同。


## 分析目的 2 和 3 -- 建立預測模型 (predictive models)

建立預測模型的過程，其實就是選擇哪個或者那些變量進入模型的過程。方法有很多，可惜的是，沒有哪種是公認完美的。這裏只介紹兩種最常見，也最常被批評的方法 -- 前/後 逐步選擇法 (forward stepwise selection/backward elimination)。強調一下，逐步法本身並不是神奇法術，不同的算法選擇的變量自然會有不同，如果你用了逐步選擇法，選出來的模型變量僅僅只能作爲參考，而不能作爲最終結論。

```{r GLM50, cache=TRUE}
vitc <- haven::read_dta("backupfiles/vitC.dta")
vitc$ctakers <- factor(vitc$ctakers)
vitc$sex <- factor(vitc$sex)

stats::step(lm(seruvitc~1,data=vitc[complete.cases(vitc),]),direction="forward",scope=~age+height+weight+sex+cigs+ctakers)

stats::step(lm(seruvitc~.,data=vitc[complete.cases(vitc),]),direction="backward")
```



# 檢查你的模型 Model Checking - GLM

每次定義一個 GLM 模型的時候 (Section \@ref(defineaGLM))，均分三步走，所以一個模型會出錯的部分，就在這三步驟中的任何一步：

1. 因變量分佈定義錯誤 (或者分佈的假設不成立) mis-specified distribution: 因變量之間**是否相互獨立**，且**服從某個已知的分佈**，這兩個條件中的任意一個不能滿足，第一步都無法成立。例如，最常見的是我們用泊松迴歸模型來擬合計數型數據時，因爲缺乏一些關鍵變量，導致模型遇到過度離散的問題 (over-dispersed for a Poisson distribution due to an omitted covariate)；
2. 線性預測方程定義錯誤 mis-specified linear predictor: 線性預測方程中放入的變量，有的可能需要被轉換 (連續型轉換成分類型，或者是需要數學轉換)。或者是應該加入的交互作用項被我們粗心忽略了；
3. 鏈接方程錯誤 mis-specified link function: 對前一步定義好的線性預測方程，第三步的鏈接方程指定很可能出現錯誤。或者是，我們可以考慮選用別的鏈接方程 ($\text{log instead of logit}$)，改變了鏈接方程之後，很可能原先認爲有交互作用的變量之間交互作用就消失了 (Section \@ref(interaction-depend-scale))。

本章介紹一些廣義線性迴歸模型診斷的方法，這些手段雖然偶爾有一些檢驗方法，但更多的診斷方法需要繪圖通過視覺判斷。介紹邏輯迴歸時解釋過模型比較時使用的模型偏差 (deviance) 概念 (Section \@ref(deviance)) Pearson 的擬合優度檢驗，以及使用 Hosmer-Lemeshow 檢驗法檢驗個人二分類變量數據的邏輯迴歸擬合優度 (Section \@ref(gof)) 法。值得注意的是，這些方法是一種整體檢驗 (global test)，其零假設是 “**模型可以擬合數據**”，如果擬合優度檢驗的結果是拒絕這個零假設，那麼可以認爲模型建立的不佳，即**接受 “模型不能擬合數據” 的替代假設**。如果擬合優度檢驗的結果是無法拒絕零假設，那麼我們僅僅只能認爲**無證據證明 “模型不可以擬合數據”**，而**不能證明設計的模型可以良好的擬合數據**。所以，擬合優度的檢驗結果可以警告我們模型擬合有沒有錯誤，卻不能證明這個模型到底是不是一個良好的模型 (個人感覺應把擬合優度檢驗 goodness of fit 的名稱改爲 **擬合劣度檢驗 badness of fit**)。

## 線性預測方程的定義

線性預測方程定義錯誤的最常見的就是“忽略了不該忽略的交互作用”，及**連續型變量可能被以不恰當的方式加入預測方程中**。當然，你可以通過把一個變量放入模型前後，該變量本身的迴歸係數是否有意義 (Wald test) 或者你關心的**預測變量的迴歸係數的變化程度** (magnitude of the corresponding parameter estimate) 來判斷是否保留這個變量在你的模型裏。這麼做的時候，你要當心自己陷入多重比較 (multiple testing) 的陷阱 (某次或者某幾次出現的統計學有意義的結果，可以僅僅是由於偶然，而不是因爲它真的有意義)。

### 殘差

觀測值跟擬合值之間的差距，就是我們常說的殘差。

以二項分佈數據爲例，

$$Y_i\sim\text{Bin}(n_i, \pi_i), \\
\text{where n is the number of subjects in one group} \\
\text{logit}(\pi_i) = \eta_i$$

其第 $i$ 個觀測值的原始殘差 (raw residual)，是

$$
\begin{aligned}
r_i & = y_i - \hat\mu_i \\
    & = y_i - n_i\hat\pi_i
\end{aligned}
$$

觀測值 $Y_i$ 的變化程度 (variability) 本身並不是一成不變的 (會根據模型中加入的共變量而改變)，其變化程度可能是觀測值 $Y_i$ 的方差導致的。二項分佈數據的方差已知是 $\text{Var}(Y_i) = n_i\pi_i(1-\pi_i)$。舉個栗子，如果 $n_i = 10, \hat\pi_i = 0.01, Y_i = 10$，那麼 $r_i \approx 10$，這是一個很差的擬合效果。如果，$n_i = 100000, \hat\pi_i = 0.5, Y_i = 5010$，那麼 $r_i = 10$，此時的殘差也是 $10$ 又證明了這是一個擬合效果良好的模型。相同的殘差，由於方差不同，判斷則不一樣，所以我們需要有一個類似簡單線性迴歸中標準化殘差 (Section \@ref(standardres)) 的過程 -- **Pearson 殘差**:

$$
p_i = \frac{r_i}{\sqrt{\hat{\text{Var}}}(Y_i)}
$$

所以，二項分佈數據的 Pearson 殘差公式爲

$$
p_i = \frac{r_i}{\sqrt{n_i\hat\pi_i(1-\hat\pi_i)}}
$$

Pearson 殘差的平方和，就是 Pearson 卡方統計量，在只有分類變量的邏輯迴歸模型中可以用於擬合度診斷 (Section \@ref(calibration))，自由度爲 $1$：

$$
\sum_i^Np^2_i = \text{Pearson's } \chi^2 \text{ statistic}
$$

和標準化 Pearson 殘差相似地，另一個選項是使用**偏差殘差 (deviance residual)**。只要使偏差殘差 $d_i$ 和原始殘差 $r_i$ 保持相同的符號，偏差殘差也可以被標準化用於模型診斷。

用二項分佈數據的例子，

$$
\begin{aligned}
d_i & = \text{sign}(r_i)\sqrt{2\{ y_i\text{ln}(\frac{y_i}{\hat\mu_i}) + (n_i - y_i)\text{ln}(\frac{n_i-y_i}{n_i - \hat\mu_i})\}} \\
\sum_{i=1}^n d^2 = D & = 2\sum_{i=1}^N\{ y_i\text{ln}(\frac{y_i}{\hat\mu_i}) + (n_i - y_i)\text{ln}(\frac{n_i - y_i}{n_i - \hat\mu_i}) \}
\end{aligned}
$$


### GLM 在 R 裏獲取殘差

```{r  GLM-0517, cache=TRUE, eval=FALSE}
boot::glm.diag(modelname)$rp       ## 可以獲取 standardized Pearson residuals
resid(modelname, type = "pearson") ## 可以獲取 Pearson residuals
rstandard(modelname)               ## 可以獲取 standardized deviance residuals
resid(modelname)                   ## 可以獲取 deviance residuals
```

### 如何利用獲得的殘差

1. 將殘差和觀測值的排序作散點圖--查看是否有觀測值擁有過大的標準化殘差；
2. 作殘差和線性預測方程值的散點圖--如果模型合理的話，這兩者之間視覺上可以判斷是沒有關係的 (no systematic relationship)；
3. 作殘差和模型中任意一個連續型變量 (如果有的話) -- 可以判定該連續型變量的放入方式是否合理；
4. 作殘差和數據中尚未加入模型的新變量之間的散點圖 (甚至是已有變量的二次/三次方值)--如果二者之間有明顯的相關性，需要考慮是否加入這個新變量到模型中去。

做這些散點圖時，推薦都加上 `lowess` 的非線性平滑曲線，用於輔助判斷是否變量之間存在特殊關係。

## 共變量模式殘差 covariate pattern residuals



## 鏈接方程

## NHANES 飲酒量數據實例 {#NHANESdrinker}

數據的變量和每個變量的解釋如下表，總樣本量是 2548 人，飲酒量大於 5 杯每日者被定義爲重度飲酒者。

Variable  |  Description      |
:--------|:---------------- |
`gender`  |  1=male, 2=female
`ageyrs`  | Age in years at survey
`bmi`     | Body mass index $(\text{kg/m}^2)$
`sbp`     | Systolic blood pressure $(\text{mmHg})$
`ALQ130`  | Reported average number of drinks per day

```{r 09-GLM-1, cache=TRUE}
NHANES <- read_dta("backupfiles/nhanesglm.dta")
NHANES <- NHANES %>%
  mutate(Gender = ifelse(gender == 1, "Male", "Female")) %>%
    mutate(Gender = factor(Gender, levels = c("Male", "Female")))
with(NHANES, table(gender))
NHANES <- mutate(NHANES, Heavydrinker = ALQ130 > 5)
Model_NH <- glm(Heavydrinker ~ gender + ageyrs, data = NHANES, family = binomial(link = "logit"))
logistic.display(Model_NH);summary(Model_NH)
```

當用邏輯迴歸模型擬合數據，線性迴歸方程加入年齡和性別時，數據給出了極強的證據證明性別和年齡和是否爲重度飲酒者都有很大的關係。但是，擬合完這樣一個邏輯迴歸模型之後，我們最大的擔心是，模型中的年齡變量和 $\text{logit}(\text{P}(Y=1))$ 之間的關係，用簡單線性是不是恰當？要檢驗這樣的擔憂，最好的方法是追加一個非線性轉換後的年齡值，去看看模型的擬合程度是否得到改善：


```{r 09-GLM-2, cache=TRUE}
NHANES <- mutate(NHANES, age2 = ageyrs^2)
Model_NH2 <- glm(Heavydrinker ~ gender + ageyrs + age2, data = NHANES, family = binomial(link = "logit"))
logistic.display(Model_NH2) ; summary(Model_NH2)
```

擬合了年齡的平方 (`age2`) 進入邏輯迴歸模型中之後，`age2` 的迴歸係數的 Wald 檢驗結果是 $p = 0.073$，這證明用簡單的線性關係把年齡放在模型裏**並不算不妥當 (not unreasonable)**。

另外，可以提取 `Model_NH` 的標準化 Pearson 殘差和年齡作如下的散點圖：

```{r stPearsonAge, echo=FALSE, fig.asp=.7, fig.width=8, fig.cap='Standardized Pearson residuals agianst age, in logistic model with gender and linear age as covariates', fig.align='center', out.width='80%', cache=TRUE, message=FALSE, warning=FALSE}
#NHANES$stresPearson <- resid(Model_NH, type = "pearson")
NHANES$stresPearson <- boot::glm.diag(Model_NH)$rp       ## 可以獲取 standardized Pearson residuals
ggplot(NHANES, aes(x=ageyrs, y=stresPearson)) +
  geom_point() +
  theme_bw() +
  geom_smooth(span = 0.8) +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "Age in Years", y = "Standardized Pearson residual")  +
  theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank())
```

圖 \@ref(fig:stPearsonAge) 中靠近橫軸的藍色實線是 LOWESS 平滑曲線，它十分接近平直的橫線，也證明了 Pearson 標準化殘差值和年齡本身並無關聯。這同時也佐證了，將年齡以連續型共變量的形式放入本次邏輯迴歸模型中**並非不合理 (not unreasonable)**。

下一步，我們再來考慮，模型中加入 `bmi` 是否合理 (能改善模型的擬合度)：

```{r 09-GLM-3, cache=TRUE}
Model_NH3 <- glm(Heavydrinker ~ gender + ageyrs + bmi, data = NHANES, family = binomial(link = "logit"))
logistic.display(Model_NH3) ; summary(Model_NH3)
```

BMI的迴歸係數是否爲零的 Wald 檢驗 $p=0.477$，提示數據無法提供證據去反對零假設：“調整了年齡和性別之後，BMI 和是否是重度飲酒者的概率的對數比值 $\text{log-odds}$ 之間無線性關係”，也就是二者之間可能有非線性關係。如果把 Pearson 標準化殘差和 BMI 作殘差散點圖，如下所示：

```{r stPearsonBMI, echo=FALSE, fig.asp=.7, fig.width=8, fig.cap='Standardized Pearson residuals agianst BMI, in logistic model with gender and linear age as covariates', fig.align='center', out.width='80%', cache=TRUE, message=FALSE, warning=FALSE}
#NHANES$stresPearson_bmi <- resid(Model_NH3, type = "pearson")
NHANES$stresPearson_bmi <- boot::glm.diag(Model_NH3)$rp       ## 可以獲取 standardized Pearson residuals for individuals

ggplot(NHANES, aes(x=bmi, y=stresPearson_bmi)) +
  geom_point() +
  theme_bw() +
  geom_smooth(span = 0.8) +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "Body Mass Index", y = "Standardized Pearson residual")  +
  theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank())
```

此殘差圖 \@ref(fig:stPearsonBMI) 的 LOWESS 平滑曲線卻提示我們，BMI 和殘差之間不完全是毫無關係的 (應該是非線性的，拋物線關係？)。如果我們把 BMI 取平方放入模型中再看其結果：


```{r 09-GLM-4, cache=TRUE}
NHANES <- mutate(NHANES, bmi2 = bmi^2)
Model_NH4 <- glm(Heavydrinker ~ gender + ageyrs + bmi + bmi2, data = NHANES, family = binomial(link = "logit"))
summary(Model_NH4)
logistic.display(Model_NH4)
lmtest::lrtest(Model_NH, Model_NH4)
```

通過似然比檢驗比較加了 `bmi, bmi2` 兩個共變量的模型和只有 `gender, ageyrs` 兩個共變量的模型 $(p=0.022)$，提示我們 BMI 和是否是重度飲酒者 (概率的對數比值 $\text{log-odds}$) 之間的關係並非簡單的線性關係。不過這樣的關係似乎並不是特別的明顯，圖 \@ref(fig:stPearsonBMI) 的平滑曲線的彎曲程度也沒有特別明顯。所以，在這樣的情況下，有的統計學家可能還是會選擇不放 BMI 進入模型裏。

## Practical 10

繼續沿用 NHANES 數據，此次練習我們把重點放在收集到的收縮期血壓數據上。定義收縮期血壓大於 140 $\text{mmHg}$ 者爲高血壓患者。


```{r NHANEhyt, cache=TRUE}
# 1. load the data and define a binary variable indicating whether
#    each observation has hypertension (1) or not (0)
NHANES <- read_dta("backupfiles/nhanesglm.dta")
NHANES <- NHANES %>%
  mutate(Gender = ifelse(gender == 1, "Male", "Female")) %>%
    mutate(Gender = factor(Gender, levels = c("Male", "Female")))
NHANES <- mutate(NHANES, hypertension = sbp >= 140)
tab1(NHANES$hypertension, graph = FALSE)
```



```{r loesslogit, cache=TRUE, echo=TRUE, fig.width=7, fig.height=5, fig.cap="The loess plot of the observed proportin with hypertension against age. Span = 0.6", fig.align='center', out.width='100%'}
# 2. Bearing in mind that we know blood pressure increases with age
#    we begin by including age into a logistic regression for the
#    the binary hypertension variable. We can use a lowess smoother
#    plot to examine how the probability of hypertension varies with
#    age.
pi <- with(NHANES, predict(loess(hypertension ~ ageyrs)))

with(NHANES, scatter.smooth(ageyrs, logit(pi), pch = 20, span = 0.6, lpars =
                 list(col = "blue", lwd = 3, lty = 1), col=rgb(0,0,0,0.004),
                 xlab = "Age in years",
                 ylab = "Logit(probability) of Hypertension",
                 frame = FALSE))
```

Lowess 平滑曲線圖提示，高血壓患病的可能性的 $\text{logit}$，和年齡之間的關係似乎不是簡單直線關係。我們可能需要把**年齡本身**和**年齡的平方**放入邏輯迴歸模型中去看看。

```{r NHANEhyt1, cache=TRUE}
# 3. Include age into the logistic regression in the way suggested by the lowess plot.
#    do your results support your findings from the previous graph?
NHANES <- mutate(NHANES, agesq = ageyrs^2)
Model_NH5 <- glm(hypertension ~ ageyrs + agesq, data = NHANES, family = binomial(link = "logit"))
logistic.display(Model_NH5) ; summary(Model_NH5)
```

正如同 Lowess 平滑曲線建議的那樣，數據提供了極強的證據證明年齡和患有高血壓概率的對數比值 $(\text{log-odds})$ 之間呈現的是拋物線關係。

```{r NHANEhyt2, cache=TRUE, echo=TRUE, fig.width=7, fig.height=5, fig.cap="Standardized Pearson residuals (by covariate pattern) vs. age. Logistic mdoel with linear and quadratic age as covariates.", fig.align='center', out.width='100%', warning=FALSE, message=FALSE}
# 4. Generate Pearson residuals and investigate whether the way in
#    which you have included age in the logistic regression in the
#    previous part is correct.

# obtain the standardized Pearson residuals by covariate pattern
Diag <- LogisticDx::dx(Model_NH5)
ggplot(Diag, aes(x = ageyrs, y = sPr)) +  geom_point() +
  geom_smooth(span = 0.9, se = FALSE) +  theme_bw()  +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "Age in years", y = "standardised Pearson residual")  +
  theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank())
```


標準化 Pearson 殘差 (共變量模式) 和年齡之間的散點圖 \@ref(fig:NHANEhyt2) 提示此時的殘差和年齡之間再無明顯的關係。也就是說，年齡作爲連續變量和高血壓患病概率的對數比值之間的關係，用拋物線 (二次方程) 擬合**並非不合理 (not unreasonable)**。

```{r NHANEhyt3, cache=TRUE, echo=TRUE, fig.width=7, fig.height=5, fig.cap="Standardized Pearson residuals vs. BMI. Logistic mdoel with **just** linear and quadratic age as covariates.", fig.align='center', out.width='100%', warning=FALSE, message=FALSE}
# 5. Next, use individual level residuals to examine whether BMI ought to be
#    included in the model, and depending on what you find, continue with you
#    previous model or add BMI. In the latter case, generate new residuals and
#    assess if you have included BMI using the most appropriate functional form.
NHANES$stresPearson <- boot::glm.diag(Model_NH5)$rp
ggplot(NHANES, aes(x = bmi, y = stresPearson)) +
  geom_point() +
  theme_bw() +
  geom_smooth(span = 0.8, se = FALSE) +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "Body Mass Index", y = "Standardized Pearson residual")  +
  theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank())
```

圖 \@ref(fig:NHANEhyt3)，提示，標準化 Pearson 殘差和連續型 BMI 值之間應該存在相關性，也就是該圖提示需要加入連續型變量 BMI 進入邏輯迴歸模型中去！

```{r NHANEhyt4, cache=TRUE}
Model_NH6 <- glm(hypertension ~ ageyrs + agesq + bmi, data = NHANES, family = binomial(link = "logit"))
logistic.display(Model_NH6) ; summary(Model_NH6)
```

加入連續型變量 BMI 進入模型後，`bmi` 項的 Wald 檢驗結果果然證實了 之前殘差圖提示的 BMI 和高血壓患病概率之間存在相關性。再對 `Model_NH6` 的殘差和 `bmi` 作殘差散點圖：


```{r NHANEhyt5, cache=TRUE, echo=FALSE, fig.width=7, fig.height=5, fig.cap="Standardized Pearson residuals vs. BMI. Logistic mdoel with **linear and quadratic age and BMI** as covariates.", fig.align='center', out.width='100%', warning=FALSE, message=FALSE}
NHANES$stresPearson_bmi <- boot::glm.diag(Model_NH6)$rp
ggplot(NHANES, aes(x = bmi, y = stresPearson_bmi)) +
  geom_point() +
  theme_bw() +
  geom_smooth(span = 0.8, se = FALSE) +
  theme(axis.text = element_text(size = 15),
  axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15)) +
  labs(x = "Body Mass Index", y = "Standardized Pearson residual")  +
  theme(axis.title = element_text(size = 17), axis.text = element_text(size = 8),
        axis.line = element_line(colour = "black"),
    panel.border = element_blank(),
    panel.background = element_blank())
```

現在的殘差散點圖提示殘差和 `bmi` 之間不再有關係，所以之前把 `bmi` 加入邏輯迴歸模型是個**並非不合理 (not unreasonable)**的選擇。

```{r NHANEhyt6, cache=TRUE}
# 6. So far we have ingored gender. Explore whether gender should be included
#    in the model. including whether or not the other covariates included
#    already interact with gender with their effects on hypertension.
Model_NH7 <- glm(hypertension ~ ageyrs + agesq + bmi + Gender,
                 data = NHANES, family = binomial(link = "logit"))
logistic.display(Model_NH7) ; summary(Model_NH7)
lmtest::lrtest(Model_NH6, Model_NH7)
# some evidence of an effect of gender.
# the Wald test and the likelihood ratio test are both borderline
# statistically significant.
Model_NH8 <- glm(hypertension ~ ageyrs + agesq + bmi*Gender,
                 data = NHANES, family = binomial(link = "logit"))
logistic.display(Model_NH8)
lmtest::lrtest(Model_NH7, Model_NH8)
# no strong evidence of an interaction between BMI and gender
# from both wald test and likelihood ratio test.
Model_NH9 <- glm(hypertension ~ ageyrs*Gender + agesq + bmi,
                 data = NHANES, family = binomial(link = "logit"))
logistic.display(Model_NH9)
lmtest::lrtest(Model_NH7, Model_NH9)
# strong evidence of an interaction between gender and age
lmtest::lrtest(Model_NH6, Model_NH9)
# joint test of gender and its interaction with age is also significant
```

增加性別項進入邏輯迴歸模型以後，數據提供了臨界有意義證據 $(p = 0.070)$ 證明了調整了年齡和 BMI 以後，高血壓的患病概率依然和性別有關係。增加了 BMI 和性別的交互作用項之後發現，無證據證明性別和 BMI 之間存在有意義的交互作用 $(p=0.139)$。但是，增加了年齡和性別的交互作用項以後，發現了有很強的證據證明性別和年齡之間存在交互作用 $(p=0.004)$。增加性別以及性別和年齡的交互作用項，顯著提升了模型對數據的擬合度 $(p = 0.0028)$。此處，我們可以下結論認爲，雖然加入年齡本身，對模型擬合程度提升有有限的幫助，但是當模型考慮了年齡和性別的交互作用之後，擬合數據的程度得到極爲顯著的改善。

當然，想要繼續下去也是可以的，例如 `Model_NH9` 的前提下，再加入年齡平方與性別的交互作用項，會發現其 Wald 檢驗結果提示年齡平方，和性別的交互作用是沒有意義的 $(p=0.58)$。

```{r  NHANEhyt7, cache=TRUE}
# 7. Based on your final model, calculate fitted probabilities for an individual
#    aged 60 years, at BMI values from 20 to 40 in increments of 5, separately
#    for men and women, and plot the resulting values.

a <- data.frame(bmi = seq(20, 40, 5), ageyrs = rep(60, 5), agesq = rep(3600, 5), Gender = factor(rep("Male", 5)))
b <- data.frame(bmi = seq(20, 40, 5), ageyrs = rep(60, 5), agesq = rep(3600, 5), Gender = factor(rep("Female", 5)))

Predict_men <- predict(Model_NH9, a, se.fit = TRUE)$fit
Predict_men_se <- predict(Model_NH9, a, se.fit = TRUE)$se.fit
Point_pred_men <- exp(Predict_men)/(1+exp(Predict_men))
PredictCI_men_L <- exp(Predict_men - 1.96*Predict_men_se)/(1+exp(Predict_men- 1.96*Predict_men_se))
PredictCI_men_U <- exp(Predict_men + 1.96*Predict_men_se)/(1+exp(Predict_men+ 1.96*Predict_men_se))
cbind(Point_pred_men, PredictCI_men_L, PredictCI_men_U)



Predict_women <- predict(Model_NH9, b, se.fit = TRUE)$fit
Predict_women_se <- predict(Model_NH9, b, se.fit = TRUE)$se.fit
Point_pred_women <- exp(Predict_women)/(1+exp(Predict_women))
PredictCI_women_L <- exp(Predict_women - 1.96*Predict_women_se)/(1+exp(Predict_women- 1.96*Predict_women_se))
PredictCI_women_U <- exp(Predict_women + 1.96*Predict_women_se)/(1+exp(Predict_women+ 1.96*Predict_women_se))
cbind(Point_pred_women, PredictCI_women_L, PredictCI_women_U)
```



# 評價模型的表現 Assessing model performance

在廣義線性迴歸的模型表現中，還有幾個重要的概念，**精準度 (calibration)，變異度 (variation)，和分辨能力 (descrimination)**，本章繼續用二分類結果變量和多個共變量的廣義線性迴歸模型來理解這幾個概念。本章使用邏輯迴歸，也就是 $\text{logit}$ 鏈接方程的 GLM 來解釋，但是實際上使用其他鏈接方程時，這些概念也是一樣通用的。

當用邏輯迴歸模型擬合了觀測數據。我們可以通過擬合的模型來計算每個觀測對象的預測“成功”概率 (the predicted probability of "success" for each subject)。當使用 $\text{logit}$ 作鏈接方程時，每個人的預測概率 (predicted probability) 爲：

$$
\hat\pi_i = \frac{\text{exp}(\hat\alpha + \hat\beta_1x_{i1} + \cdots + \hat\beta_px_{ip})}{1+\text{exp}(\hat\alpha + \hat\beta_1x_{i1} + \cdots + \hat\beta_px_{ip})}
$$


## 精準度 calibration {#calibration}

模型具有良好的精準度時，其計算獲得的每個觀測對象的預測概率，和每個觀測對象本身“成功”的**概率期望值**保持一致。

$$
E(Y|\hat\pi = p) = p
$$

當一個 GLM 具有良好精準度時，我們可以利用它在臨牀醫學中發揮重要的作用 (如預測患者死亡，發病或療效等)。如果模型的精準度不佳，那可能導致的嚴重後果有：治療不必要治療的“健康人”，或者漏掉應該治療的“患者”。當一個模型的預測變量只包含了分類型變量，比較觀測概率和預測概率的過程較爲簡單，比較各個分類變量的排列組合後，不同共變量類型 (covariate pattern) 的患者的觀測值和預測值即可。

這裏再沿用之前 NHANES 的重度飲酒相關的數據 (Section \@ref(NHANESdrinker))來繼續下面對精準度的說明，先擬合一個只有性別作爲預測變量的邏輯迴歸模型：

```{r performance0, cache=TRUE}
NHANES <- read_dta("backupfiles/nhanesglm.dta")
NHANES <- NHANES %>%
  mutate(Gender = ifelse(gender == 1, "Male", "Female")) %>%
    mutate(Gender = factor(Gender, levels = c("Male", "Female")))
with(NHANES, table(Gender))
NHANES <- mutate(NHANES, Heavydrinker = ALQ130 > 5)
Model_perf <- glm(Heavydrinker ~ Gender, data = NHANES, family = binomial(link = "logit"))
logistic.display(Model_perf)
```

完成這個模型之後，在 STATA 裏可以用簡便的 `estat gof, table` 命令獲取模型擬合的觀測值和期待值表格，然而 R 裏面需要用到 [`LogisticDx`](https://cran.r-project.org/web/packages/LogisticDx/index.html) 包裏的診斷命令 `dx` 獲取 ~~(我花了好幾個小時才找到這個命令，不得不說 STATA 對於流行病的傳統計算真的是比較方便)~~：

```{r 09-GLM-5, warning=FALSE, cache=TRUE}
LogisticDx::dx(Model_perf)[, 2:6]
# obtain Pearson's test statistics
chi2 <- sum((LogisticDx::dx(Model_perf)$sPr)^2)
   pval <- pchisq(chi2, 1, lower.tail=FALSE)
   data.frame(test="Pearson chi2(1)",chi.sq=chi2,pvalue=pval)
```


在這個只有性別作預測變量的邏輯迴歸模型裏，當然只有男，女，兩種共變量模式 (covariate patterns)。此時，模型的精準度100% (`y` 是觀測值， `yhat` 是期待值)。接下來，再在模型中加入一個是否體重超重的二分類變量。再獲取其觀測值和期待值表格如下：


```{r 09-GLM-6, warning=FALSE, cache=TRUE}
NHANES <- mutate(NHANES, highbmi = bmi > 25)
Model_perf <- glm(Heavydrinker ~ Gender + highbmi, data = NHANES, family = binomial)
logistic.display(Model_perf)
LogisticDx::dx(Model_perf)[,2:7]

# obtain Pearson's test statistics
chi2 <- sum((LogisticDx::dx(Model_perf)$sPr)^2)
   pval <- pchisq(chi2, 1, lower.tail=FALSE)
   data.frame(test="Pearson chi2(1)",chi.sq=chi2,pvalue=pval)
```

此時的模型有 4 種共變量模式 (covariate patterns)，其實就是性別和超重與否的四種排列組合。這裏報告的 `Pearson's test statisitics`
我們在前一章講邏輯迴歸殘差的部分有講過，它就是 Pearson 標準化殘差的平方和。此處它的卡方檢驗，檢驗零假設是“模型制定正確”。所以，我們無足夠的證據 $(p=0.58)$ 來反對零假設，數據觀測值和模型的期待值似乎也較爲吻合。

但是一旦模型裏加入了新的連續型變量，整個模型的共變量模式 (covariate patterns)，將會變得很難進行上面的觀測值和期待值的比較，由於加入的連續型變量會導致模型的共變量模式變得越來越多，甚至接近與樣本量個數 $n$，也就是每個共變量模式的樣本越來越小，直至等於 $1$。連續型變量的模型中我們 Hosmer-Lemeshow 檢驗 (Section \@ref(gof)) 而不是 Pearson 統計檢驗量。

## 可解釋因變量的變異度及 $R^2$ 決定係數

精準度的確重要，但是模型精準度好，只代表它和過去擬合它的觀測數據之間關係接近，不代表它能準確地預測其他的個體的概率。前文中只有性別作爲預測變量的邏輯迴歸模型就是實例，它和擬合的觀測數據做到了 100% 完美擬合，但是不用大腦思考也知道，除了性別還有其他更多的能預測一個人是否是重度飲酒者的變量，且擁有能提升模型的擬合程度的潛質。只有性別作預測變量的邏輯迴歸模型，最大的問題在於，它只能解釋個體之間**重度飲酒者概率**的**變異度(variation)**中極少的部分。事實上，它**只能解釋能夠用性別解釋的個體之間重度飲酒者概率的變異度**。所以，此處打算引伸出的概念就是類似簡單線性迴歸中的 $R^2$ 決定係數 (Section \@ref(Rsquare)) 的定義。

你應該還能記得，在簡單線性迴歸中決定係數 $R^2$ 的含義是因變量的平方和 (平方和) 中能被模型解釋的部分：


$$
R^2 = \frac{SS_{REG}}{SS_{yy}} = \frac{\sum_{i=1}^n(\hat{y}_i-\bar{y})^2}{\sum_{i=1}^n(y_i-\bar{y})^2} = 1-\frac{\sum_{i=1}^n(y_i-\hat{y}_i)^2}{\sum_{i=1}^n(y_i-\bar{y})^2}
$$

許多前人嘗試過試圖將線性迴歸的決定係數概念擴展到廣義線性迴歸模型中來，但是目前爲止的嘗試都不太成功。所以，只有一些借鑑了簡單線性迴歸的的決定係數思想的概念，得到了擴展，但是要注意，他們本身和決定係數是有區別的。

**“假決定係數 (pseudo-R2)”**，別名 McFadden 的似然比係數 (McFadden's likelihood ratio index) <br> $$R^r_{\text{McFadden}} = 1 - \frac{\ell_c}{\ell_\text{null}}$$ <br> 其中 $\ell_c, \ell_{\text{null}}$ 分別是模型的極大似然值 和零模型時的極大似然值。<br> 假決定係數，之所以被冠名“假”，因爲這個係數你也可以在簡單線性迴歸下計算，但是其大小常常和一般我們熟知的決定係數結果有些差距。所以，常有人質疑其到底是否可用 (因爲它在現實生活中根本不可能取到 $0$ 或 $1$)。

在 R 裏，擬合了邏輯迴歸以後通常也不會報告假決定係數值的大小。所以想要獲得它，需要 `DescTools::PseudoR2()` 命令來獲取：

```{r 09-GLM-7}
PseudoR2(Model_perf)
```

上文中包含了性別和是否超重的模型的假決定係數只有區區 $0.0785$，可見，只有性別和是否超重兩個變量只能解釋結果變量變異度中極少的部分。

## 分辨能力 descrimination

### 敏感度和特異度

評價一個邏輯迴歸的表現，最後的一個手段是，看這個模型對觀測對象的分辨能力。也就是，當我們人爲地指定一個概率值 $p$ 作爲是否患病的閾值，那麼，觀測對象通過模型計算獲得的概率，已經觀測對象本身的觀測概率之間，其實可以用診斷學的敏感度和特異度的概念來評價模型對於觀測對象的分別能力到底如何。所以邏輯迴歸模型的敏感度就是，病例中通過模型計算被判斷爲陽性的概率；特異度是，非病例中，通過模型計算本判斷爲陰性的概率。這個敏感度特異度當然會隨着我們選擇的閾值而變化。

圖 \@ref(fig:ROClogistic) 所示的是，將性別， BMI，和年齡三個變量放入邏輯迴歸模型之後，模型對於觀察對象的分辨能力的 ROC 示意圖。計算所得的 ROC 曲線下面積爲 0.7484。如果一個模型是失敗的，那麼其曲線下面積爲 (接近) 0.5。也就是會十分貼近 $y=x$ 的直線。


```{r ROClogistic, cache=TRUE, echo=TRUE, fig.width=6, fig.height=5.5, fig.cap="Receiver operating curve for model for heavy drinking with gender, age, and BMI", fig.align='center', out.width='100%', warning=FALSE, message=FALSE}
Model_perf <- glm(Heavydrinker ~ Gender + bmi + ageyrs, data = NHANES, family = binomial)
ROC_graph <- lroc(Model_perf, grid.col = "grey", lwd = 3, frame = FALSE)
ROC_graph$auc
```

曲線下面積，AUC 的另一個有用的意義是，從觀測對象中任意選取兩個人，一個是病例 $(y_i = 1)$，一個是非病例 $(y_j = 0)$，那麼曲線下面積就是模型能夠正確將這兩個對象按照是否患病的可能性進行排序的概率。 $\text{AUC} = \text{Pr}(\pi_i > \pi_j | y_i = 1 \& y_j = 0)$

ROC 曲線本身有自己的優點，也有許多侷限性。最近有另外一個用於診斷的新型曲線--預測曲線[@Pepe2007]。預測曲線繪製的是，觀測對象的擬合後概率 $\hat\pi_i$ 和這個概率在所有觀察對象的擬合後概率的百分位數 (percentile) 之間的曲線。一個模型，如果給許多對象相似的概率，那麼不能說這個模型的分辨能力足夠好。同時，此圖也能一目瞭然讓人看到大概多少對象的患病概率是大於一定水平的。

```{r predictiveness, cache=TRUE, echo=TRUE, fig.width=6.5, fig.height=5, fig.cap="Predictiveness curve for model for heavy drinking with gender, age, and BMI as covariate", fig.align='center', out.width='100%', warning=FALSE, message=FALSE}
Predictive <- data.frame(fitted(Model_perf), rank(fitted(Model_perf))/2548)
names(Predictive) <- c("hatpi", "percentile")
ggplot(Predictive, aes(x = percentile, y = hatpi)) + geom_line() +
  ylim(0, 0.4) +
  labs(x = "Risk percentile", y = "Heavy drinker risk")  + theme_bw() +
  theme(axis.title = element_text(size = 17),
       axis.text.x = element_text(size = 15),
  axis.text.y = element_text(size = 15))
```

圖 \@ref(fig:predictiveness) 所示的是，性別，年齡，BMI作爲共變量的邏輯迴歸模型的預測變量，預測重度飲酒概率的模型給出的預測曲線。從圖中可見，大多數人的概率值各不相同。而且，圖中也能告訴我們大約 20% 的觀測對象其重度飲酒的概率大於 0.2。


# 配對實驗數據的分析法

配對實驗是指觀察對象中的一個以上 (通常是2-3個) 以事先確定的條件進行配對 (matched under conditions)。配對實驗中根據條件配對後的觀察對象常常被稱爲一個個區塊 (block)。

**例1：** 配對交叉設計實驗，結果變量爲連續型。

給予五十名實驗對象抗高血壓藥物用於降低其舒張期血壓 (diastolic blood pressure)。舒張期血壓在實驗前 $(y_{i1})$ 和實驗後 $(y_{i2})$ 分別測量。此時的實驗區塊是每個患者的自身前後對照數據。

**例2：** 干預實驗，結果變量爲二分類型。

77名已經有眼底病變的糖尿病患者被選爲實驗對象，每人隨機選取一隻眼睛接受最新的雷射激光治療，另一隻眼睛使用標準治療法。經過五年的隨訪，觀察患者的兩隻眼睛是病變爲全盲 (是/否)。此時的實驗區塊是每個患者自己，左右眼互爲對照。

**例3：** 隊列研究中的配對設計，結果變量爲二分類型。

100 名觀察對像根據性別年齡和 100 名服他汀類藥物 (statin) 的患者，以高膽固醇血癥的有無作爲對照變量 (病例對照同時患病，或同時無病) 一一對應。這 200 名對象被追蹤隨訪 3 年，記錄他們是否罹患心血管疾病。此時的實驗區塊，是 100 個成對的實驗對象。

**例4：** 配對病例對照實驗。

20 名肺癌患者，和另外 20 名沒有肺癌的對照以同年齡，同性別爲條件配對。研究人員詢問每個實驗參與者過去的吸菸史。本實驗的結果變量爲對象是否吸過香菸。此時的實驗區塊是一名肺癌患者和一名同年齡，同性別的對照。



配對實驗中，我們通常認爲在每個區塊裏的個人，或者他們的測量值應該比不同一區塊裏的觀察對象的測量值更加相似。

- **例1** 中，每個個體實驗前後的血壓值，理論上會比另外一個個體的血壓值相比更加接近，無論他是否接受抗高血壓治療，故每個個體本身，構成了“完美”的病例 (實驗前) 和對照 (實驗後)。
- **例3** 中，無論一個人是否服用他汀類藥物，兩個同時都是高膽固醇血癥的人理論上會比無此症狀的人更加有可能罹患心血管疾病。
- **例4** 中，年齡和性別可能既和一個人是否患有肺癌有關係，也和一個人是否吸菸有關。所以，在考察吸菸和肺癌關係的時候，需要在相同年齡，性別的條件下才是公平的。


## 配對的原理

不同的實驗，配對的設計可能有不同的理由：

- 在 RCT 設計中，配對實驗是爲了提升實驗數據對治療的真實效果的估計 (to improve the precision of the estimated effect of the treatment on the outcome)；
- 隊列研究和病例對照研究中，使用配對實驗設計 **主要是爲了在實驗設計階段就控制已知的混雜因素**。當然有時也有人使用配對設計去提升差異估計的精確度。

### 爲了提升估計的精確度

使用配對實驗設計，獲得數據以後就應使用相應的統計手法，從而達到提高差異估計的精確度的目的。因爲配對實驗設計允許我們在分析階段去除掉 “區塊差異 block variability”：

$$
\begin{aligned}
             Y_{ij} & = C_j + P_i + O_{ij} \\
\text{Where } Y_{ij} & = \text{outcome for block } i \text{ under treatment } j\\
                C_j & = \text{component of outcome due to treatment } j \\
                P_i & = \text{component of outcome due to characteristics of block } i\\
             O_{ij} & = \text{residual component of outcome}
\end{aligned}
$$

在上述式子描述的配對實驗設計下，如果成對的觀察值是 $Y_{i1}, Y_{i2} (i = 1,\cdots, n)$，那麼可以把二者的差用於估計治療效果：

$$
\begin{equation}
Y_{i2} - Y_{i1} = C_2 - C_1 + O_{i2} - O_{i1}
\end{equation}
(\#eq:GLM12-1)
$$

所以，配對實驗中，由於區塊 $(P_i)$ 造成的估計的方差被從隨機變異 (random variation) 中去除掉，$C_j$ 之間的差異的估計精確度得到提高。這一結論在結果變量是連續型或是二分類型中同樣適用。


### 控制混雜因素

在病例對照實驗中，常常用配對設計來控制已知的混雜。但是必須強調的是，如果實驗設計中用了配對，那麼統計分析時，也必須用配對實驗的分析方法。

**隊列研究中**： 暴露組對象和非暴露組對象之間的配對根據一些已知的混雜變量，常見的如年齡和性別配對。

**病例對照研究中**：病例和對照之間通過某些特徵配對，從而控制這些特徵的混雜，常見的也是年齡和性別。另外還有的病例會從他/她居住的區域附近中尋找相似的對照，或者從他/她的家庭醫生的患者中尋找相似的對象，這時配對設計爲的是控制那些可能無法精確測量的如社會經濟條件，或環境因子。有些研究會尋找病例同一家族中的非患病者作爲對照，從而達到控制 “遺傳因素” 這一混雜因子的效果。

## 結果變量爲連續型變量的配對實驗

用 $Y_{i1}, Y_{i2}, (i = 1,\cdots, n)$ 標記 $n$ 組配對實驗對象的結果變量的測量值。所以每對實驗對象中的兩個成員，分別被給予不同的實驗條件 (治療或安慰劑，暴露或非暴露)，用數字 $1,2$ 表示。所以，分析此種數據的策略是，計算每個實驗區塊的結果變量之差：

$$
\begin{equation}
Y_{i2} - Y_{i1}, (i = 1, \cdots, n)
\end{equation}
(\#eq:GLM12-2)
$$

那麼，配對實驗的結果變量是連續型變量時，等同於單樣本的假設檢驗，零假設是結果變量在不同實驗條件下的差等於零。

### 一般檢驗方法

常用的有：

1. 均值的配對 $t$ 檢驗。其實就是和 $0$ 作比較的單樣本 $t$ 檢驗 (Section \@ref(OneSampleT))；
2. Wilcoxon 配對檢驗 (Wilcoxon matched pairs test)。此法其實是 Wilcoxon 符號秩和檢驗 (Wilcoxon signed rank test)，在零假設是兩組數據中位數之差等於零的條件下的假設檢驗 (Section \@ref(Wilcoxon-signed-rank-test))。
3. 符號檢驗 (Sign test) (Section \@ref(sign-test))。


例：17名實驗對象同時給予抗高血壓治療，數據記錄了實驗前後收縮壓的測量值：

```{r 09-GLM-8, warning=FALSE}
library(haven)
sbp <- read_dta("backupfiles/sbp.dta")
sbp

## Wilcoxon signed-rank test
wilcox.test(sbp$sbp_A, sbp$sbp_B, paired = TRUE, correct = FALSE)

## 秩和檢驗結果提示，數據提供了顯著性水平低於 1% (0.0038567) 的證據
## 證明實驗前後收縮期血壓值的變化的中位數不等於零。
## 由此可以下結論，數據能夠提供足夠的證據證明實驗前後的收縮期血壓的
## 分佈，是不同的。
## 注意，這不是一個 RCT，所以，這樣的不同不一定是由於抗高血壓治療。

## 3 different methods to conduct sign test

Positive_n <- sum(sbp$diff_AB >0)
total_n <- length(sbp$diff_AB)
2*pbinom(total_n-Positive_n, total_n, 0.5) ## sign test -- just p-value


binom.test(Positive_n, total_n,0.5) ## sign test through binomial test


BSDA::SIGN.test(sbp$sbp_A, sbp$sbp_B) ## sign-test from BSDA package
```

符號檢驗的結果，相比 Wilcoxon 秩和檢驗的結果來說， P 值稍大，由於符號檢驗需要的假設前提比 Wilcoxon 秩和檢驗更少，更穩健 (檢驗效能更低, lacks power)。即便如此，數據依然提供足夠的證據 (p = 0.01273) 證明，實驗前後的收縮期血壓的中位數之差不等於零。

下面是 STATA 中同一數據的 Wilcoxon 秩和檢驗和符號檢驗的結果，和上面的 R 輸出結果作比較：


```
. signrank sbp_A = sbp_B

Wilcoxon signed-rank test

        sign |      obs   sum ranks    expected
-------------+---------------------------------
    positive |       14       137.5        76.5
    negative |        3        15.5        76.5
        zero |        0           0           0
-------------+---------------------------------
         all |       17         153         153

unadjusted variance      446.25
adjustment for ties       -0.63
adjustment for zeros       0.00
                     ----------
adjusted variance        445.63

Ho: sbp_A = sbp_B
             z =   2.890
    Prob > |z| =   0.0039

. signtest sbp_A = sbp_B

Sign test

        sign |    observed    expected
-------------+------------------------
    positive |          14         8.5
    negative |           3         8.5
        zero |           0           0
-------------+------------------------
         all |          17          17

One-sided tests:
  Ho: median of sbp_A - sbp_B = 0 vs.
  Ha: median of sbp_A - sbp_B > 0
      Pr(#positive >= 14) =
         Binomial(n = 17, x >= 14, p = 0.5) =  0.0064

  Ho: median of sbp_A - sbp_B = 0 vs.
  Ha: median of sbp_A - sbp_B < 0
      Pr(#negative >= 3) =
         Binomial(n = 17, x >= 3, p = 0.5) =  0.9988

Two-sided test:
  Ho: median of sbp_A - sbp_B = 0 vs.
  Ha: median of sbp_A - sbp_B != 0
      Pr(#positive >= 14 or #negative >= 14) =
         min(1, 2*Binomial(n = 17, x >= 14, p = 0.5)) =  0.0127
```


### 用迴歸法分析

配對實驗數據還可以使用迴歸手段分析。使用迴歸分析時，需要考慮兩種不同的情形：

1. 配對使用的特徵具有唯一性，即有且只有一個對照。
    - 自己作自己的對照，如實驗前實驗後的觀測值變化；
    - 同一個實驗對象，左右兩眼隨機抽取一隻作病例，一隻作對照；
    - 病例和自己的配偶配對。
2. 配對使用的特徵不具有唯一性，病例可以有多個潛在對照。
    - 病例和性別相同，年齡相近的對照；

**第 1 種情況：配對使用的特徵具有唯一性**

用 $Y_{ij}$ 標記第 $j$ 個配對實驗區塊中第 $i$ 個對象的觀測結果。我們可以使用下面的迴歸模型：

$$
\begin{equation}
Y_{ij} = \beta_0 + \beta_1 X_{ij} + \gamma_j + \varepsilon_{ij}
\end{equation}
(\#eq:GLM12-3)
$$

其中， $\gamma_j$ 是第 $j$ 個**配對實驗區塊的固定效應** (fixed effect)；$\varepsilon_{ij}$ 是殘差。這個模型可以在簡單線性迴歸中直接加入一個代表不同配對實驗區塊的變量 (分類型) 進行調整即可。用簡單線性迴歸擬合 \@ref(eq:GLM12-3) 是一個等同於配對 $t$ 檢驗的迴歸方程。

注意：在迴歸模型中加入代表實驗區塊的分類型變量調整**僅適用**與簡單線性迴歸。**非線性迴歸例如邏輯迴歸，方程中試圖加入區塊變量作爲固定效應是不合適的。**

在模型中加入隨機效應 (random effect)，作爲另一種迴歸手段，則可以同時應用於線性迴歸和非線性迴歸。這種模型被叫做分層迴歸模型 (hierarchical models)，或混合效應模型 (mixed effect model)，或隨機效應模型 (random effect model)。這將會在等級線性回歸 (Section \@ref(Hierarchical)) 這一章節中詳細討論，此處且先按下不表。


**第 2 種情況：配對使用的特徵不具有唯一性**

用 $Y_i$ 標記第 $i$ 個個體的觀測結果， $X_i$ 標記主要關心的暴露變量，$W_i$ 標記用於配對的一系列變量的向量。那麼我們可以擬合兩種迴歸模型，差別在於是否調整配對變量向量：

$$
\begin{equation}
Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i
\end{equation}
(\#eq:GLM12-4)
$$


$$
\begin{equation}
Y_i = \beta_0 + \beta_1 X_i + \beta_2^TW_i + \delta_i
\end{equation}
(\#eq:GLM12-5)
$$

需要指出的是，這兩個模型，都是合理有效的迴歸模型，理論上會給出相同或者十分近似的 $\beta_1$ 估計。因爲配對，意味着在該樣本中，$X_i$ 和 $W_i$ 是無關的，所以加入 $W_i$ 不會影響 $\beta_1$ 的估計值。即使，實驗樣本所來自的潛在人羣 (the unerlying population) 中，$X_i, W_i$  是相關的 (也是最主要的要拿 $W_i$ 進行配對的動機所在)，兩個模型給出的 $\beta_1$ 估計理論上也不會有太大差距。但是，如果說配對是爲了控制混雜 (即人羣中 $X_i, W_i$ 是相關的)，建議應該使用模型 \@ref(eq:GLM12-5)。因爲模型 \@ref(eq:GLM12-5) 給出的 $\beta_1$ 的標準誤估計會比較小 (更小的信賴區間，更精確)。

前一節提到的一般檢驗法，是直接把“配對”這個條件放在檢驗過程中，它們只關心差異大小是否有意義。本小節討論的迴歸方法，則需要一些前提假設 (參考簡單線性迴歸的前提和邏輯迴歸的前提)。當前提條件可以滿足時，我們會更推薦使用迴歸方法對配對數據進行檢驗。因爲通常除了拿來配對的變量，我們對觀察對象還收集了其他的潛在混雜因子數據，使用迴歸方法可以進一步對其餘未用於配對的變量進行調整。

## 結果變量是二分類變量的配對實驗

用 $Y_{i1}, Y_{i2} (i = 1,\cdots,n)$ 標記 $n$ 個配對的二分類型的結果變量，其對應的暴露變量是 $X_{i1}, X_{i2}$。

這樣的數據，有兩種方法來分析暴露和結果之間是否相關：

1. McNemar's test;
2. Odds ratio.

用前文中糖尿病患者眼底病變和是否變盲的例子來說明就是：第 $i$ 個實驗對象，他/她接受標準治療的眼睛是否變盲，決定了 $Y_{i1} = 1 \text{ or } 0$；他/她接受新的治療的那隻眼睛是否變盲決定了 $Y_{i2} = 1 \text{ or } 0$。

但是，用病例對照實驗 (肺癌例) 來解釋時，20 名肺癌患者被一一和同性別，年齡相近的 20 名非肺癌對象配對，每個實驗對象都被詢問其吸菸史。這樣的配對病例對照實驗的設計，決定了其實際上是把我們關心的問題 (吸菸是否導致肺癌) 逆轉了的 (肺癌患者中吸菸的比例是否大於沒有患肺癌的人)。此時應當使用 **比值比 Odds ratio** 來評價吸菸和肺癌之間的關係。

### 第一步 對數據作表格

有兩種方式對結果變量是二分類變量的實驗數據作表格歸納。其一，配對與否的信息被忽略掉 (表格 \@ref(tab:unmatchedGLM12-1a))；其二，包含配對信息 (表格 \@ref(tab:matchedGLM12-1b))。



```{r unmatchedGLM12-1a, echo=FALSE, cache=TRUE}
library(knitr)
library(kableExtra)
dt <- read.csv("backupfiles/GLM12-1.csv", header = T)
names(dt) <- c("", "New treatment", "Standard treatment")
kable(dt, "html",  align = "c", caption = "Unmatched presentation of data from a study with binary outcome and binary treatment") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"),full_width = F, position = "center")
```


```{r matchedGLM12-1b, echo=FALSE, cache=TRUE}
library(knitr)
library(kableExtra)
dt <- read.csv("backupfiles/GLM12-1b.csv", header = T)
names(dt) <- c("","", "Not blind", "Blind", " ")
kable(dt, "html",  align = "c", caption = "Matched presentation of data from a study with binary outcome and binary treatment") %>%
  kable_styling(bootstrap_options = c("striped", "bordered"),full_width = F, position = "center") %>%
  column_spec(1:2, bold = TRUE) %>%
      collapse_rows(columns = c(1)) %>%
  add_header_above(c(" " = 1,"New treatment" = 4))
```

### McNemar's test

下面的表格，是前面表格 \@ref(tab:matchedGLM12-1b) 的一般化形式。可以用於 McNemar 檢驗。在暴露對象中，結果變量等於 $Y_{i1} = 1$ 的配對數量的比例是 $p_1 = (n_{10} + n_{11})/n$；在非暴露對象中，結果變量等於 $Y_{i2} = 2$ 的配對數量的比例是 $p_2 = (n_{01} + n_{11})/n$。


<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>表 54.3 General arrangement of data for McNemar's test</caption>
 <thead>
<tr>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="4"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;">Exposed  $(j = 1)$</div></th>
</tr>
  <tr>
   <th style="text-align:center;">  </th>
   <th style="text-align:center;">  </th>
   <th style="text-align:center;"> Failure <br> $(Y_{i1} = 0)$ </th>
   <th style="text-align:center;"> Success <br> $(Y_{i1} = 1)$ </th>
   <th style="text-align:center;">   </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;font-weight: bold;vertical-align: middle !important;" rowspan="3"> Unexposed <br>$(j = 2)$ </td>
   <td style="text-align:center;"> Failure <br> $(Y_{i2} = 0)$ </td>
   <td style="text-align:center;"> $n_{00}$ </td>
   <td style="text-align:center;"> $n_{10}$ </td>
   <td style="text-align:center;"> $n_{00}+n_{10}$ </td>
  </tr>
  <tr>

   <td style="text-align:center;"> Success <br> $(Y_{i2} = 1)$ </td>
   <td style="text-align:center;"> $n_{01}$ </td>
   <td style="text-align:center;"> $n_{11}$ </td>
   <td style="text-align:center;"> $n_{01}+n_{11}$ </td>
  </tr>
  <tr>

   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> $n_{00}+n_{01}$ </td>
   <td style="text-align:center;"> $n_{10}+n_{11}$ </td>
   <td style="text-align:center;"> $n$ </td>
  </tr>
</tbody>
</table>


McNemar 檢驗的零假設是，$p_2 - p_1 = 0$，其實這等價於比較表格中 $n_{10}, n_{01}$ 是否相等。所以，在零假設條件下：

$$
n_{10} \sim \text{Binomial}(n_{10} + n_{01}, 0.5)
$$

此時既可以選用精確的二項分佈檢驗，也可以用正態分佈近似法進行假設檢驗。用表格 \@ref(tab:matchedGLM12-1b) 的數據進行的檢驗結果如下：


```{r 09-GLM-9}
binom.test(28, 32, 0.5)
```


### 二分類型結果變量配對實驗的比值比

McNemar 檢驗只能用於判斷暴露和結果之間是否有關係。衡量這個關係的大小，還需要用比值比 (odds ratio)。我們已知可以用 Mantel Haenszel 方法來總結以某個分類變量爲條件的分層/合併比值比。同樣的方法也可以用於配對實驗數據的分析。此時的分層變量使用的是配對的實驗區塊 (blocks)。每個實驗區塊的數據可以歸納成下面的表格：

<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>表 54.4 Example of matched data in stratum $i$: numbers of individuals in stratum $i$ with each combination</caption>
 <thead>
  <tr>
   <th style="text-align:center;">  </th>
   <th style="text-align:center;"> Unexposed (0) </th>
   <th style="text-align:center;"> Exposed (1) </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> Outcome 0 </td>
   <td style="text-align:center;"> $a_i$ </td>
   <td style="text-align:center;"> $b_i$ </td>
  </tr>
  <tr>
   <td style="text-align:center;"> Outcome 1 </td>
   <td style="text-align:center;"> $c_i$ </td>
   <td style="text-align:center;"> $d_i$ </td>
  </tr>
</tbody>
</table>

實驗區塊 $i$ 的比值比 OR 是：

$$
\text{OR} = \frac{a_id_i}{b_ic_i}
$$

Mantel Haenszel 合併 OR 是：

$$
\Psi = \frac{\sum_i(a_id_i/n_i)}{\sum_i(b_ic_i/n_i)} \\
\text{where } n_i = 2
$$

可以繼續推導：

$$
\begin{aligned}
\Psi & = \frac{\sum_i(a_id_i/n_i)}{\sum_i(b_ic_i/n_i)} \\
     & = \frac{\text{number of blocks with } Y_{i1} = 1 \;\&\; Y_{i2} = 0}{\text{number of blocks with } Y_{i1} = 0 \;\&\; Y_{i2} = 1} \\
     & = \frac{n_{10}}{n_{01}}
\end{aligned}
$$

所以，從上述推導可知，在配對實驗中，比值比只取決於那些配對中出現了不同結果的數據。這些結果不一致的配對被命名爲**不一致配對 (discordant pairs)**。那些結果變量相同的配對對最終的比值比估計毫無用處。

### 配對實驗比值比的信賴區間

配對實驗比值比信賴區間的精確計算步驟如下：

1. $\pi$ 標記暴露對象中，結果變量等於 $Y_{i1} = 1$，且非暴露對象中，結果變量等於 $Y_{i2} = 0$ 的配對數在全部不一致配對數中所佔的比例：$$\hat\pi = \frac{n_{10}}{n_{10} + n_{01}}$$
2. $\Psi$ 爲不一致配對的比值比：$$\hat\Psi = \frac{n_{10}}{n_{01}}$$
3. $\pi, \Psi$ 之間的關係是：$$\Psi = \frac{\pi}{1-\pi}$$
4. $n_{10}$ 服從二項分佈：$$n_{10}\sim \text{Binomial}(n_{10} + n_{01}, \pi)$$
5. 根據二項分佈的性質計算 $\pi$ 的信賴區間： $$\pi_L, \pi_U$$
6. 所以 $\Psi$ 的信賴區間就可以計算爲：$$(\frac{\pi_L}{1-\pi_L},\frac{\pi_U}{1-\pi_U})$$

用表格\@ref(tab:matchedGLM12-1b) 的數據計算其比值比估計：

$$\hat{\text{OR}} = \frac{n_{10}}{n_{01}} = \frac{4}{28} = 0.14$$

$n_{10} = 4 \sim \text{Binomial}(32, \pi = 4/32 = 0.125)$

所以 $\pi$ 的 95% 信賴區間爲：

```{r 09-GLM-10}
FSA::binCI(4, 32)
```


那麼該比值比的精確 95% 信賴區間爲：

$$
\begin{aligned}
 & (\frac{0.03513065}{1-0.03513065},\frac{0.2899484}{1-0.2899484}) \\
=& (0.036, 0.408)
\end{aligned}
$$

精確計算的結果和 R 裏獲得的結果一致：

```{r 09-GLM-11, message=FALSE}
library(exact2x2)
mcnemar.exact(matrix(c(39, 28, 4, 6),2,2))
```


## 條件 (conditional) 比值比和邊際 (marginal) 比值比

從配對實驗獲得的比值比是**條件比值比 (conditional odds ratio)**，所謂條件比值比，意思就是從配對實驗獲得的比值比是以配對的試驗區塊爲條件的。

用表格 \@ref(tab:matchedGLM12-1b) 的糖尿病患者眼底病變的數據來進一步解釋：該實驗獲得的條件比值比爲 0.143，實驗區塊是每位眼底發生病變的糖尿病患者本身。這個條件比值比應被正確解讀爲：**每位眼底發生病變的患者中**的兩隻眼睛中接受新療法的眼睛最終失明的機率 (odds)，和另一隻接受標準療法的眼睛最終失明的機率的比值是 0.143。數學表達式標記爲：


$$
\text{Conditional OR} = \frac{\frac{\text{Pr(Blind|new, individual) } i}{\text{Pr(Not Blind|new, individual) } i}}{\frac{\text{Pr(Blind|standard, individual) } i}{\text{Pr(Not blind|standard, individual) } i}}
$$

此**條件比值比**被認爲在**不同的發生眼底病變的糖尿病患者$(i)$中保持不變**。需要指出的是這個條件比值比**不等同於認爲在糖尿病人羣中**接受新療法治療的眼睛失明機率和接受標準療法的眼睛失明機率之比爲 0.134 (邊際比值比 marginal odds ratio)。邊際比值比的數學表達式爲：

$$
\text{Marginal OR} = \frac{\text{Pr(Blind | new)/Pr(Not blind | new)}}{\text{Pr(Blind | standard)/Pr(Not blind | standard)}}
$$

如果要估計上式的邊際比值比，我們需要有糖尿病人羣中失明的危險度 (the risk of blindness in the population)，以及失明高危人羣，低危人羣各自接受標準療法的失明概率。假如已知如下的信息：

- 糖尿病人羣中有 50% 的人可以被歸類爲失明高危人羣 (high risk, HR)，另 50% 可以被歸類會失明低危人羣 (low risk, LR)；
- 接受標準療法時，高危人羣失明的概率是 90%，低危人羣失明的概率是 10%。


上述信息告訴我們，總體糖尿病人羣中接受標準療法失明的概率 $\text{Pr(Blind|standard)}$ 是：

$$
\begin{aligned}
\text{Pr(Blind|standard)}  & = \text{Pr(Blind|standard,HR)Pr(HR)} \\
                           & \;\;\;+ \text{Pr(Blind|standard, LR)Pr(LR)} \\
                           & = 0.9\times0.5 + 0.1\times0.5 = 0.5
\end{aligned}
$$

再利用條件比值比 $0.143$ 我們可以計算糖尿病人羣中接受新療法失明的概率 $\text{Pr(Blind | new)}$ 是：

$$
\begin{aligned}
\frac{\text{Pr(Blind|new, HR)}}{\text{PR(Not blind | new, HR)}} & = 0.143 \times \frac{\text{Pr(Blind|standard, HR)}}{\text{Pr(Not blind|standard, HR)}}  \\
 & = 0.143 \times \frac{0.9}{0.1} = 1.287  \\
\frac{\text{Pr(Blind|new, LR)}}{\text{PR(Not blind | new, LR)}} & = 0.143 \times \frac{\text{Pr(Blind|standard, LR)}}{\text{Pr(Not blind|standard, LR)}}  \\
 & = 0.143 \times \frac{0.1}{0.9} = 0.016  \\
\Rightarrow \text{Pr(Blind|new, HR)} & = 1.287/(1+1.287) = 0.563 \\
            \text{Pr(Blind|new, LR)} & = 0/016/(1+0.016) = 0.016 \\
\Rightarrow\;\;\; \text{Pr(Blind | new)}   & = \text{Pr(Blind|new, HR)Pr(HR)} + \text{Pr(Blind|new, LR)PR(LR)} \\
                                     & = 0.563\times0.5 + 0.016\times0.5 =  0.290
\end{aligned}
$$

獲得了 $\text{Pr(Blind|standard), Pr(Blind | new)}$ 之後，邊際比值比 (糖尿病人羣中接受新療法治療的眼睛失明機率和接受標準療法的眼睛失明機率之比)：

$$
\begin{aligned}
\text{Marginal OR} & =  \frac{\text{Pr(Blind | new)/Pr(Not blind | new)}}{\text{Pr(Blind | standard)/Pr(Not blind | standard)}} \\
                   & = \frac{0.5/(1-0.5)}{0.290/(1-0.290)} = 0.408
\end{aligned}
$$

比起條件比值比 (0.143)，邊際比值比 (0.408) 要大出許多來。

# 條件邏輯迴歸 Conditional logistic regression


配對實驗設計可以用於 RCT，隊列研究，病例對照研究：

- RCT實驗設計中，接受治療方案 A 的患者，和接受治療方案 B 的患者，以 1:1 的比例按照他們的某種醫學特徵配對。這種配對可以是同一個患者在交叉設計RCT 實驗中的觀測值，也可以是同一個患者接受治療的前後測量值，當然還可以是同一個患者的左右兩隻眼睛 (手臂，腿，等等)；
- 隊列研究裏，**暴露和非暴露**對象根據事先決定的配對原則配對 (相同性別，年齡接近，或者居住在同一社區，或者是同一家庭中暴露和非暴露的兩個個體)；
- 病例對照研究裏，**病例和非病例**按照事先決定的配對原則配對，一個病例可能和一個或者多個對照相匹配。

本章節着重討論病例對照研究中，條件邏輯迴歸模型的使用。在病例對照研究中，配對設計極爲常見。如同前面提到的那樣，在病例對照研究的設計階段，研究者可能設計一個病例和一個或者多個對照進行配對。要研究的暴露因素變量可以是多種多樣的 (二分類，或連續型)，且可以考慮對多個不同的暴露進行觀察和分析時的調整。相反，隊列研究中能夠進行配對的暴露就只能僅限於二分類變量。所以，病例對照研究中**對某個特徵進行的配對**，其實是對病例-對照這樣的實驗設計本身與生俱來的特質進行了合理的利用。隊列研究則沒有了這樣的優勢，所以隊列研究中使用配對設計的其實不太常見。

配對病例對照研究中，研究者常用一些最常見的混雜因素作爲配對的變量 (如性別年齡)，且這些配對所使用的變量本身不是該實驗主要探討的話題。有些研究者還認爲配對是一個方便地尋找對照組的手段。當然，選取對照組的原則，可以是具有唯一性的配對原則 (使對照有且僅有1-2個)，或者是無唯一性的配對原則 (病例可以有多個潛在的對照)。**唯一性配對原則導致的最大問題是，你可能根本找不到合適的對照**，所以研究者會更傾向於把配對原則放寬一些，以獲取足夠的對照組樣本量，但是這也會帶來別的附加問題，那就是需要用匹配的數學模型來控制殘差之間的依賴性 (residual dependency)。在考慮了生存時間的一些病例對照研究中，原則上還會考慮選取和病例存活相同時間 (年齡) 的人作對照，詳細會繼續在生存分析中深入探討。

## 配對實驗的邏輯迴歸模型

定義 $X_u$ 是一個簡單的二分類暴露變量，$D_u$ 是一個簡單的二分類結果變量，$u = 1, \cdots, n$ 是配對的個數。第 $u\text{th}$ 組中的研究對象，互爲配對。在某些特殊場合，每組配對只有2個研究對象 (例如糖尿病患者的左右兩隻眼睛)。

用概率標記法定義每個患者的概率：

$$
\begin{equation}
\pi_{u;xd} = \text{Pr}(X_u = x, D_u = d)
\end{equation}
(\#eq:GLM13-1)
$$

用 (Section \@ref(GLM8-3)) 中相似的表格來理解，第 $u$ 組 $(u = 1, \cdots, n)$ 配對中的研究對象可以用下表來歸納其概率。


<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>表 55.1: Separate samples from subpopulations $D=0,1$ with relavant conditional probabilities **in a matched case-control study within each pair** </caption>
 <thead>
  <tr>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;"> $D$ </div></th>
</tr>
<tr>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;"> $0$ </th>
   <th style="text-align:center;"> $1$ </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> $X$ </td>
   <td style="text-align:center;"> $0$ </td>
   <td style="text-align:center;"> $\pi_{u;00}$ </td>
   <td style="text-align:center;"> $\pi_{u;01}$ </td>
  </tr>
  <tr>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> $1$ </td>
   <td style="text-align:center;"> $\pi_{u;10}$ </td>
   <td style="text-align:center;"> $\pi_{u;11}$ </td>
  </tr>
  <tr>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> $\text{Pr}(X_u=x|D_u=d)$ </td>
   <td style="text-align:center;"> $\frac{\pi_{u;10}}{\pi_{u;10}+\pi_{u;00}}$ </td>
   <td style="text-align:center;"> $\frac{\pi_{u;11}}{\pi_{u;11}+\pi_{u;01}}$ </td>
  </tr>
</tbody>
</table>


那麼第 $u$ 組配對中，暴露和結果之間真實的比值比 (odds ratio)是：

$$
\begin{equation}
\frac{\pi_{u;11}\pi_{u;00}}{\pi_{u;10}\pi_{u;01}}
\end{equation}
(\#eq:GLM13-2)
$$

所以，在配對病例對照研究中，**我們假設這樣的前提得到滿足：每個配對中的比值比是不變的 (we assume that the true log odds ratio relating exposure to disease is the same for all pairs)**：

$$
\begin{equation}
\frac{\pi_{u;11}\pi_{u;00}}{\pi_{u;10}\pi_{u;01}} = e^\beta
\end{equation}
(\#eq:GLM13-3)
$$

### 配對病例對照研究

在探討**非配對的病例對照研究**時，我們給二分類型暴露變量定義過下列邏輯迴歸模型 (Section  \@ref(GLM8-3-4))：

$$
\begin{equation}
\text{Pr}(X_i = 1 | D_i = d_i) = \frac{e^{\lambda^*+\beta d_i}}{1+e^{\lambda^*+\beta d_i}}\\
\text{Where } i \text{ refers to an individual}
\end{equation}
(\#eq:GLM13-4)
$$

接下來，我們來把這個邏輯回歸模型擴展到配對實驗數據: 每對實驗數據包含一個病例，一個對照。用 $X_{u;0}$ 標記第 $u$ 對配對數據中，對照的某二分類解釋變量的值 (the binary explanatory variable $X$ for the control in the $u$th matched pair)。$X_{u;1}$ 表示該對照的病例的相應二分類解釋變量的值。如此，一個包含了配對的病例和對照二者的邏輯回歸模型可以寫爲:

$$
\begin{equation}
\text{Pr}(X_{u;0} = 1) = \frac{e^{\lambda^*_u}}{1+e^{\lambda^*_u}} ; \text{Pr}(X_{u;1} = 1) = \frac{e^{\lambda^*_u + \beta}}{1+e^{\lambda^*_u + \beta}}
\end{equation}
(\#eq:GLM13-5)
$$

或者你如果願意，可以把它改寫成:


$$
\begin{equation}
\text{Pr}(X_{u;d} = 1)  = \frac{e^{\lambda^*_u + d\beta}}{1+e^{\lambda^*_u + d\beta}}, \;d = 0,1
\end{equation}
(\#eq:GLM13-6)
$$

該模型的參數 $\beta$ 是第 $u$ 配對中的對數比值比 (log-odds ratio)。可是，我們使用它的前提是，默認這個對數比值比在所有的配對數據 $u = 1, \cdots, n$ 中都是相同的。另一個參數 $\lambda^*_u$ 是第 $u$ 組的特徵值。被定義爲第 $u$ 組配對中對照的暴露 $(X = 1)$ 的對數幾率 (log odds of exposure for the exposure in the $u$th pair):

$$
\lambda^*_u = \log(\frac{\pi_{u;10}}{\pi_{u;00}})
$$

在第 $u$ 組配對中，有且只有4種 $(x_{u;1},x_{u;0})$ 結果: 也就是 $(0,0), (1,0), (0,1), (1,1)$。該對數據的似然方程是:


$$
\begin{equation}
\frac{e^{\lambda^*_ux_{u;0}}}{1+e^{\lambda^*_u}}\cdot\frac{e^{(\lambda^*_u + \beta)x_{u;1}}}{1+e^{\lambda^*_u + \beta}}
\end{equation}
(\#eq:GLM13-8)
$$


所以把所有配對的似然相乘可得整個數據的似然方程:

$$
\begin{equation}
\frac{\exp(\sum\lambda^*_ux_{u;0})}{\prod(1+e^{\lambda^*_u})}\cdot\frac{\exp(\sum(\lambda^*_u + \beta)x_{u;1})}{\prod(1+e^{\lambda^*_u+\beta})}
\end{equation}
(\#eq:GLM13-9)
$$

整體數據的似然方程 \@ref(eq:GLM13-9) 中的和 $\sum$ 與積 $\prod$ 分別對應相加與相乘所有的病例與對照的 $n$ 組配對。對於第 $u$ 組來說，它對似然方程的貢獻的部分只是式子 \@ref(eq:GLM13-8) 中包含 $\lambda_u^*$ 的部分。該信息其實就是第 $u$ 組配對自有/特有的信息。但其實每組配對中的病例和對照又與其他組略微不同，他們各自提供的信息其實對於整體的似然來說雖然微小，但是當配對數量越來越多，就變得不可忽略。此時對 \@ref(eq:GLM13-9) 直接進行粗暴的取參數 $\beta$ 的極大值是錯誤的，其導致的後果會在下文中繼續討論。我們需要用另一種新的途徑來求參數 $\beta$。


### 配對隊列研究

這裏簡略地分析一下配對隊列研究中會遇見的和配對病例對照研究相似問題的過程。在配對隊列研究中，一個**接受暴露的研究對象**被配對給另一個**沒有接受暴露的研究對象** (注意在配對病例對照研究中，是一個病例和一個對照做配對)。在第 $u$ 組隊列配對中，用 $D_{u;1}$ 標記暴露對象的追蹤結果 (發病/死亡/事件發生的有無)，用 $D_{u;0}$ 標記非暴露對象的追蹤結果 (發病/死亡/事件發生的有無)。

隊列研究中已知暴露 $X$ 有無的前提下，結果 $D$ 發生的有無的邏輯回歸模型，加入對配對設計的考量是:

$$
\begin{equation}
\text{Pr}(D_{u;0} = 1) = \frac{e^{\lambda_u}}{1+e^{\lambda_u}}\;; \; \text{Pr}(D_{u;1} = 1) = \frac{e^{\lambda_u + \beta}}{1+e^{\lambda_u+\beta}}
\end{equation}
(\#eq:GLM13-10)
$$

正如之前在無配對條件下的隊列研究和病例對照研究中的推導過的那樣 \@ref(GLM8-3-4)，$\lambda_u$ 和 $\lambda_u^*$ 是有**不同涵義**的，但是配對隊列研究和配對病例對照研究則具有相同的對數比值比--參數 $(\beta)$。這是基於一個重要的前提--相同人羣，相同暴露和相同疾病的結果在不同實驗設計 (病例對照和隊列研究) 時使用相同的配對變量。

在配對病例對照研究中，某對暴露和非暴露對象其實驗結果的可能性也只有四種 $(d_{u;1}, d_{u;0})$，該配對的似然是:

$$
\begin{equation}
\frac{e^{\lambda_ud_{u;0}}}{(1+e^{\lambda_ud_{u;0}})}\cdot\frac{e^{(\lambda_u+\beta)d_{u;1}}}{(1+e^{\lambda_u+\beta})}
\end{equation}
(\#eq:GLM13-11)
$$

整體數據的似然方程就是和配對病例對照研究一樣的，將每對這樣的似然相乘。所以，我們就又遇見了和配對病例對照研究相似的問題，此時如果直接對整體似然方程中求極大似然獲得的 $\beta$ 將會是錯誤的。

## 條件邏輯回歸 -- 二分類暴露變量

我們再回到簡單的一對一配對病例對照實驗設計，且研究的實驗暴露是一個簡單的二分類變量。這一節的目的是克服前面遇見的困難 (繞過不需要的 $\lambda_u^*, u = 1, 2, \cdots, n$) ，找到能夠準確估計參數 $\beta$ 的數學方法。

### 充分統計量 sufficient statistics

繞過雜音變量(不需要的變量)，直接估計我們感興趣的參數的過程，需要利用**充分統計量 (sufficient statistics)** 的概念。這裏，噪音變量就是 $\lambda_u^*, u = 1, 2, \cdots, n$。下面是對充分統計量的定義:

假設隨機變量 $\mathbf{y}$ 的概率(密度)方程中含有其他的雜音變量 $\theta_1, \cdots, \theta_p$:

$$
f(\mathbf{y}|\theta_1, \cdots, \theta_9)
$$

如果統計量 $T_k$，是實驗數據中得到的某方程，且 $\mathbf{y}$ 基於 $T_k$ 的條件分布與 $\theta_k$ 無關 (獨立)，那麼該方程被稱作參數 $\theta_k$ 的充分統計量。其實就是，如果 $T_k$ 可以給我們足夠估計 $\theta_k$ 的信息量，我們就稱 $T_k$ 是 $\theta_k$ 的充分統計量。


舉例來說，假設我們手頭的樣本數據 $y_1, y_2, \cdots, y_n$ 可以被認爲從正態分布的人羣中採集，我們希望通過這個樣本來估計總體人羣的均值 $\mu$。此時常常(不自覺地)做總體方差已知的假設。該數據的似然方程是:

$$
\prod_{i = 1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{ -\frac{(y_i-\mu)^2}{2\sigma^2} \}
$$

此時，估計要總體均值 $\mu$ 我們僅需要 $\sum_i y_i$ (或者只要 $\bar{y}$) 就足夠了。這裏我們說 $\sum_i y_i$ 是參數總體均值 $\mu$ 的充分統計量。

### 條件邏輯回歸的推導

在簡單配對病例對照研究的實驗設定下，可以被證明的是，第 $u$ 對配對的暴露變量 $(x_{u;0}, x_{u;1})$ 是雜音變量 $\lambda_u^*$ 的充分統計量。值得注意的是，我們其實不需要知道 $(x_{u;0}, x_{u;1})$ 這一對暴露數據中哪個來自病例，哪個來自對照。對於一個二分類暴露變量，如果我們已知 $(x_{u;0}, x_{u;1})$，那麼我們就知道了每個病例對照配對中暴露的個數。所以，我們完全可以用 $T_u = x_{u;0} + x_{u;1}$ 來替代 $(x_{u;0}, x_{u;1})$，因爲它只有三種取值的可能:

- 0: 病例對照都沒有暴露;
- 1: 病例或者對照其中之一有暴露;
- 2: 病例和對照均有暴露。

利用已知的關於充分統計量的概念，在尋找第 $u$ 對配對對總體似然的貢獻時我們把 $T_u = x_{u;0} + x_{u;1}$ 作條件 (condition on)。有了這個條件，剩下的隨機現象就是暴露在病例和對照中的分布，也就是:

$$
\begin{equation}
\text{Pr}(X_{u;0} = x_{u;0}, X_{u;1} = x_{u;1} | T_u = x_{u;0} + x_{u;1})
\end{equation}
(\#eq:GLM13-13)
$$

如果 $x_{u;0}=x_{u;1}$，也就是當病例和對照同時爲暴露或非暴露時，我們有 100% 的把握對他們的暴露信息加以區分:

$$
\begin{aligned}
& \text{Pr}(X_{u;0} = 0, X_{u;1} = 0| T_u = 0) =  1,\\
& \text{Pr}(X_{u;0} = 1, X_{u;1} = 1| T_u = 2) =  1
\end{aligned}
(\#eq:GLM13-14)
$$

如果 $x_{u;0} \neq x_{u;1}$，也就是 $T_u = 1$，那只有兩種可能性，要麼病例是暴露，對照非暴露，要麼病例是非暴露，對照是暴露:

$$
\begin{aligned}
& \text{Pr}(X_{u;0} = 1, X_{u;1} = 0| T_u = 1),\\
& \text{Pr}(X_{u;0} = 0, X_{u;1} = 1| T_u = 1)
\end{aligned}
(\#eq:GLM13-15)
$$

這兩個概率可以被計算爲:

$$
\begin{aligned}
& \text{Pr}(X_{u;0} = 1, X_{u;1} = 0| T_u = 1) \\ & =  \frac{\text{Pr}(X_{u;0} = 1, X_{u;1} = 0)}{\text{Pr}(X_{u;0} = 1, X_{u;1} = 0) +\text{Pr}(X_{u;0} = 0, X_{u;1} = 1)}
\end{aligned}
(\#eq:GLM13-16)
$$


$$
\begin{aligned}
& \text{Pr}(X_{u;0} = 0, X_{u;1} = 1| T_u = 1) \\ & = \frac{\text{Pr}(X_{u;0} = 0, X_{u;1} = 1)}{\text{Pr}(X_{u;0} = 1, X_{u;1} = 0) +\text{Pr}(X_{u;0} = 0, X_{u;1} = 1)}
\end{aligned}
(\#eq:GLM13-17)
$$

用前面推導過的邏輯回歸模型公式 \@ref(eq:GLM13-5) 可以推導出:

$$
\begin{aligned}
\text{Pr}(X_{u;0} = 1, X_{u;1} = 0| T_u = 1) & = \frac{\frac{e^{\lambda^*_u}}{(1+e^{\lambda^*_u})(1+e^{\lambda^*_u + \beta})}}{\frac{e^{\lambda^*_u}}{(1+e^{\lambda^*_u})(1+e^{\lambda^*_u + \beta})} + \frac{e^{\lambda^*_u + \beta}}{(1+e^{\lambda^*_u})(1+e^{\lambda^*_u + \beta})}} \\
 & = \frac{1}{1+e^\beta}
\end{aligned}
(\#eq:GLM13-18)
$$

類似地:

$$
\begin{aligned}
\text{Pr}(X_{u;0} = 0, X_{u;1} = 1| T_u = 1) = \frac{e^\beta}{1+e^\beta}
\end{aligned}
(\#eq:GLM13-19)
$$


### 條件似然 conditional likelihood

一個簡單設計，暴露變量爲二分類變量的配對病例對照研究，可以用下面的四格表歸納收集的數據:



<table class="table table-striped table-bordered" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>表 55.2: Data from a matched case control study with a single binary </caption>
 <thead>
  <tr>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="border-bottom:hidden" colspan="1"></th>
<th style="text-align:center; border-bottom:hidden; padding-bottom:0; padding-left:3px;padding-right:3px;" colspan="2"><div style="border-bottom: 1px solid #ddd; padding-bottom: 5px;"> $D = 1$ </div></th>
</tr>
<tr>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;">   </th>
   <th style="text-align:center;"> $X=0$ </th>
   <th style="text-align:center;"> $X=1$ </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:center;"> $D=0$ </td>
   <td style="text-align:center;"> $X=0$ </td>
   <td style="text-align:center;"> $n_{00}$ </td>
   <td style="text-align:center;"> $n_{10}$ </td>
  </tr>
  <tr>
   <td style="text-align:center;">  </td>
   <td style="text-align:center;"> $X=1$ </td>
   <td style="text-align:center;"> $n_{01}$ </td>
   <td style="text-align:center;"> $n_{10}$ </td>
  </tr>
</tbody>
</table>

用上之前推導的結論，和上面表格的總結，我們可以知道，對於 1:1 的配對病例對照研究，且暴露爲二分類變量來說，它的似然是:

$$
\begin{equation}
L = (\frac{e^\beta}{1+e^\beta})^{n_{10}}(\frac{1}{1+e^\beta})^{n_{01}}
\end{equation}
(\#eq:GLM13-20)
$$

接下來用我們熟悉的極大似然法就可以推導出 $\beta$ :

$$
\begin{aligned}
\ell & = n_{10}\beta - (n_{10} + n_{01})\frac{e^\beta}{1+e^\beta} \\
\Rightarrow \frac{\text{d}\ell}{\text{d}\beta} & = n_{10} - (n_{10} + n_{01})\frac{e^\beta}{1+e^\beta} \\
\Rightarrow \hat\beta  & = \log\frac{n_{10}}{n_{01}}
\end{aligned}
$$

### 進一步擴展

目前為止推導的條件邏輯回歸模型雖然只是簡單的一對一配對病例對照研究實驗設計，且暴露變量也只是二分類變量。但是經驗告訴我們，這樣的理論基礎可以被進一步擴展到更加復雜的實驗設計:

- 上述理論很容易地可以擴展到一對一配對隊列研究和RCT實驗。我們需要做的只是修改 $X_{u;d}$ 成 $D_{u;x}$ 即可，推導獲得的條件似然是完全相同的。唯一不同的是 $n_{10}, n_{01}$ 在隊列研究和RCT臨牀試驗中的含義從**病例中暴露和對照中非暴露的對數**變成了**暴露中病例和非暴露中對照**的對數。($n_{10}$ becomes the number of pairs in which the exposed individual becomse a case and the unexposed becomes a control, and vice versa for $n_{01}$)。

- 配對病例對照研究常見的可以一個病例配對1-5個對照。

- 也可以在配對病例對照研究中研究(比二分類變量)更加復雜的暴露因素，既可以是非類型變量，也可以是連續型變量。


## 條件邏輯回歸模型的一般化

現在我們拋棄簡單實驗設計思維，考慮在配對實驗中需要研究一個一般的暴露變量 (可以是二分類，多分類，連續型)，或者是一個多種不同變量組成的預測變量的向量。此時我們關心的主要是這些預測變量在病例或者對照的條件下分布 (conditional distribution): $P(X_{u;0} = x), P(X_{u;1} = x)$。假設，某對病例和對照對象中，對照被觀測到有預測變量 $x_{u;0}$，病例則被觀察到的是 $x_{u;1}$，那麼我們關心的條件概率其實是研究對象被觀測到預測變量 $x_{u;0}$ 且他/她本身正好是對照，且同時他/她的病例被觀測到預測變量 $x_{u;1}$ 的概率。此時，充分統計量就是 $(x_{u;0}, x_{u;1})$，且聯合條件分布 (joint conditional distribution) 是:

$$
\begin{aligned}
& \text{P}(X_{u;0} = x_{u;0}, X_{u; 1} = x_{u;1} | T_u = (x_{u;0}, x_{u;1})) \\
=&  \frac{\text{P}(X_{u;0} = x_{u;0})\text{P}(X_{u;1} = x_{u;1})}{\text{P}(X_{u;0} = x_{u;0})\text{P}(X_{u;1} = x_{u;1}) + \text{P}(X_{u;0} = x_{u;1})\text{P}(X_{u;1} = x_{u;0})}
\end{aligned}
(\#eq:GLM13-24)
$$

其實，當且僅當我們在研究**一個簡單二分類預測變量**時，一樣。這裏當我們需要把它一般化的時候，需要來點不太一樣的方法。先用 $D_{u;x}$ 標記第 $u$ 對配對中觀測到預測變量 $x$ 的研究對象的病例/對照狀態。那麼 $D_{u;x}$ 的邏輯回歸模型是:

$$
\begin{aligned}
\text{Pr}(D_{u;x} =1) & = \frac{e^{\lambda_u+\beta^Tx}}{1+e^{\lambda_u+\beta^Tx}} \\
\text{Pr}(D_{u;x} =0) & = \frac{1}{1+e^{\lambda_u+\beta^Tx}}
\end{aligned}
(\#eq:GLM13-25)
$$


應用貝葉斯定理:

$$
\begin{equation}
\text{Pr}(X_{u;1} = x) = \frac{\text{Pr}(D_{u;x} = 1)\times\text{Pr}(X_{u;\cdot} = x)}{\text{Pr}(D_{u;\cdot} = 1)}
\end{equation}
(\#eq:GLM13-26)
$$

其中,

- $\text{Pr}(X_{u;\cdot} = x)$ 指的是預測變量 $X$ 在產生第 $u$ 對病例對照配對的人羣 (subpopulation which generates the $u$th matched set) 中的邊際分布 (marginal distribution，或者叫做非條件分布 unconditional distribution);
- $\text{Pr}(D_{u;\cdot} = 1)$ 指的是在產生第 $u$ 對病例對照配對的人羣中，成爲病例的概率 (unconditional probability of being a case in that sub-population)。

那麼將 \@ref(eq:GLM13-26) 代入 \@ref(eq:GLM13-24) 經過推導和精簡可以得到:

$$
\begin{aligned}
& \text{P}(X_{u;0} = x_{u;0},X_{u;1} = x_{u;1} | T_u = (x_{u;0}, x_{u;1})) \\
= & \frac{\text{Pr}(D_{u;x_{u;0}} = 0)\text{Pr}(D_{u;x_{u;1}} = 1)}{\text{Pr}(D_{u;x_{u;0}} = 0)\text{Pr}(D_{u;x_{u;1}} = 1) + \text{Pr}(D_{u;x_{u;0}} = 1)\text{Pr}(D_{u;x_{u;1}} = 0)}
\end{aligned}
(\#eq:GLM13-27)
$$

此時再帶入 \@ref(eq:GLM13-25)，推導精簡之後可以獲得:

$$
\begin{aligned}
  & \text{P}(X_{u;0} = x_{u;0},X_{u;1} = x_{u;1} | T_u = (x_{u;0}, x_{u;1})) \\
= & \frac{e^{\beta^{T}x_{u;1}}}{e^{\beta^{T}x_{u;1}} + e^{\beta^{T}x_{u;0}}}
\end{aligned}
(\#eq:GLM13-28)
$$

這就是第 $u$ 組病例對照配對數據對條件似然 (conditional likelihood) 的貢獻。那麼對於完整的整套數據來說，整體似然就是把所有的病例對照配對的似然相乘:

$$
\begin{equation}
L_{\text{matched}} = \prod_{u}\frac{\exp{(\beta^{T}x_{u;1})}}{\exp{(\beta^{T}x_{u;1})} + \exp{(\beta^{T}x_{u;0})}}
\end{equation}
(\#eq:GLM13-29)
$$

這樣的一對一病例對照研究的似然可以擴展到 1:c 的情況，也就是一個病例和 c 個對照相配對的情況，其條件邏輯回歸的似然是:

$$
\begin{equation}
L_{\text{matched}} = \prod_{u}\frac{\exp{(\beta^{T}x_{u;1})}}{\exp{(\beta^{T}x_{u;1})} + \sum_{k=1}^c\exp{(\beta^{T}x_{u;0k})}}
\end{equation}
$$

# Multinomial Logistic Regression

# Ordinal Logistic Regression
