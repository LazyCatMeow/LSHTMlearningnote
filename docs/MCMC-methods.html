<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 84 章 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言 | 醫學統計學</title>
  <meta name="description" content="在LSHTM的學習筆記" />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="第 84 章 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言 | 醫學統計學" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="img/cover.jpg" />
  <meta property="og:description" content="在LSHTM的學習筆記" />
  <meta name="github-repo" content="winterwang/LSHTMlearningnote" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 84 章 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言 | 醫學統計學" />
  
  <meta name="twitter:description" content="在LSHTM的學習筆記" />
  <meta name="twitter:image" content="img/cover.jpg" />

<meta name="author" content="王 超辰 Chaochen Wang" />


<meta name="date" content="2020-01-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="共軛先驗概率-conjugate-priors.html"/>
<link rel="next" href="建模和模型的檢查.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/kePrint/kePrint.js"></script>
<script src="libs/htmlwidgets/htmlwidgets.js"></script>
<script src="libs/plotly-binding/plotly.js"></script>
<script src="libs/typedarray/typedarray.min.js"></script>
<link href="libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main/plotly-latest.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">在LSHTM的學習筆記</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>前言</a></li>
<li class="chapter" data-level="" data-path="author.html"><a href="author.html"><i class="fa fa-check"></i>我是誰</a></li>
<li class="part"><span><b>I 概率論 Probability</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> 概率論入門：定義與公理</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#三個概率公理"><i class="fa fa-check"></i><b>1.1</b> 三個概率公理：</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#conditonalProb"><i class="fa fa-check"></i><b>1.2</b> 條件概率 Conditional probability</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#獨立-independence-的定義"><i class="fa fa-check"></i><b>1.3</b> 獨立 (independence) 的定義</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#賭博問題"><i class="fa fa-check"></i><b>1.4</b> 賭博問題</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#賭博問題的答案"><i class="fa fa-check"></i><b>1.5</b> 賭博問題的答案</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="Bayes-Definition.html"><a href="Bayes-Definition.html"><i class="fa fa-check"></i><b>2</b> Bayes 貝葉斯理論的概念</a></li>
<li class="chapter" data-level="3" data-path="期望-expectation-或均值-or-mean-和-方差-variance.html"><a href="期望-expectation-或均值-or-mean-和-方差-variance.html"><i class="fa fa-check"></i><b>3</b> 期望 Expectation (或均值 or mean) 和 方差 Variance</a><ul>
<li class="chapter" data-level="3.1" data-path="期望-expectation-或均值-or-mean-和-方差-variance.html"><a href="期望-expectation-或均值-or-mean-和-方差-variance.html#方差的性質"><i class="fa fa-check"></i><b>3.1</b> 方差的性質：</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="bernoulli.html"><a href="bernoulli.html"><i class="fa fa-check"></i><b>4</b> 伯努利分佈 Bernoulli distribution</a></li>
<li class="chapter" data-level="5" data-path="binomial.html"><a href="binomial.html"><i class="fa fa-check"></i><b>5</b> 二項分佈的概念 Binomial distribution</a><ul>
<li class="chapter" data-level="5.1" data-path="binomial.html"><a href="binomial.html#二項分佈的期望和方差"><i class="fa fa-check"></i><b>5.1</b> 二項分佈的期望和方差</a></li>
<li class="chapter" data-level="5.2" data-path="binomial.html"><a href="binomial.html#hyperdist"><i class="fa fa-check"></i><b>5.2</b> 超幾何分佈 hypergeometric distribution</a></li>
<li class="chapter" data-level="5.3" data-path="binomial.html"><a href="binomial.html#樂透中獎概率問題"><i class="fa fa-check"></i><b>5.3</b> 樂透中獎概率問題：</a><ul>
<li class="chapter" data-level="5.3.1" data-path="binomial.html"><a href="binomial.html#如果我只想中其中的-3-個號碼概率有多大"><i class="fa fa-check"></i><b>5.3.1</b> 如果我只想中其中的 <span class="math inline">\(3\)</span> 個號碼，概率有多大？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="poisson.html"><a href="poisson.html"><i class="fa fa-check"></i><b>6</b> 泊松分佈 Poisson Distribution</a></li>
<li class="chapter" data-level="7" data-path="normaldistr.html"><a href="normaldistr.html"><i class="fa fa-check"></i><b>7</b> 正態分佈 Normal Distribution</a><ul>
<li class="chapter" data-level="7.1" data-path="normaldistr.html"><a href="normaldistr.html#概率密度曲線-probability-density-function-pdf"><i class="fa fa-check"></i><b>7.1</b> 概率密度曲線 probability density function， PDF</a></li>
<li class="chapter" data-level="7.2" data-path="normaldistr.html"><a href="normaldistr.html#正態分佈"><i class="fa fa-check"></i><b>7.2</b> 正態分佈</a></li>
<li class="chapter" data-level="7.3" data-path="normaldistr.html"><a href="normaldistr.html#standardNormal"><i class="fa fa-check"></i><b>7.3</b> 標準正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="CLT.html"><a href="CLT.html"><i class="fa fa-check"></i><b>8</b> 中心極限定理 the Central Limit Theorem</a><ul>
<li class="chapter" data-level="8.1" data-path="CLT.html"><a href="CLT.html#covariance"><i class="fa fa-check"></i><b>8.1</b> 協方差 Covariance</a></li>
<li class="chapter" data-level="8.2" data-path="CLT.html"><a href="CLT.html#correlation"><i class="fa fa-check"></i><b>8.2</b> 相關 Correlation</a></li>
<li class="chapter" data-level="8.3" data-path="CLT.html"><a href="CLT.html#中心極限定理-the-central-limit-theorem"><i class="fa fa-check"></i><b>8.3</b> 中心極限定理 the Central Limit Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="CLT.html"><a href="CLT.html#binomial-normal-approx"><i class="fa fa-check"></i><b>8.4</b> 二項分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.5" data-path="CLT.html"><a href="CLT.html#泊松分佈的正態分佈近似"><i class="fa fa-check"></i><b>8.5</b> 泊松分佈的正態分佈近似</a></li>
<li class="chapter" data-level="8.6" data-path="CLT.html"><a href="CLT.html#continuity-correction"><i class="fa fa-check"></i><b>8.6</b> 正態分佈模擬的校正：continuity corrections</a><ul>
<li class="chapter" data-level="8.6.1" data-path="CLT.html"><a href="CLT.html#例題"><i class="fa fa-check"></i><b>8.6.1</b> 例題</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="CLT.html"><a href="CLT.html#兩個連續隨機變量"><i class="fa fa-check"></i><b>8.7</b> 兩個連續隨機變量</a></li>
<li class="chapter" data-level="8.8" data-path="CLT.html"><a href="CLT.html#兩個連續隨機變量-例子"><i class="fa fa-check"></i><b>8.8</b> 兩個連續隨機變量 例子：</a></li>
<li class="chapter" data-level="8.9" data-path="CLT.html"><a href="CLT.html#條件分佈和邊緣分佈的概念"><i class="fa fa-check"></i><b>8.9</b> 條件分佈和邊緣分佈的概念</a></li>
<li class="chapter" data-level="8.10" data-path="CLT.html"><a href="CLT.html#條件分佈和邊緣分佈的例子"><i class="fa fa-check"></i><b>8.10</b> 條件分佈和邊緣分佈的例子</a><ul>
<li class="chapter" data-level="8.10.1" data-path="CLT.html"><a href="CLT.html#例題-1"><i class="fa fa-check"></i><b>8.10.1</b> 例題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 統計推斷 Inference</b></span></li>
<li class="chapter" data-level="9" data-path="統計推斷的概念.html"><a href="統計推斷的概念.html"><i class="fa fa-check"></i><b>9</b> 統計推斷的概念</a><ul>
<li class="chapter" data-level="9.1" data-path="統計推斷的概念.html"><a href="統計推斷的概念.html#人羣與樣本-population-and-sample"><i class="fa fa-check"></i><b>9.1</b> 人羣與樣本 (population and sample)</a></li>
<li class="chapter" data-level="9.2" data-path="統計推斷的概念.html"><a href="統計推斷的概念.html#樣本和統計量-sample-and-statistic"><i class="fa fa-check"></i><b>9.2</b> 樣本和統計量 (sample and statistic)</a></li>
<li class="chapter" data-level="9.3" data-path="統計推斷的概念.html"><a href="統計推斷的概念.html#估計-estimation"><i class="fa fa-check"></i><b>9.3</b> 估計 Estimation</a></li>
<li class="chapter" data-level="9.4" data-path="統計推斷的概念.html"><a href="統計推斷的概念.html#信賴區間-confidence-intervals"><i class="fa fa-check"></i><b>9.4</b> 信賴區間 confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="估計和精確度-estimation-and-precision.html"><a href="估計和精確度-estimation-and-precision.html"><i class="fa fa-check"></i><b>10</b> 估計和精確度 Estimation and Precision</a><ul>
<li class="chapter" data-level="10.1" data-path="估計和精確度-estimation-and-precision.html"><a href="估計和精確度-estimation-and-precision.html#CI-for-sample-mean"><i class="fa fa-check"></i><b>10.1</b> 估計量和他們的樣本分佈</a></li>
<li class="chapter" data-level="10.2" data-path="估計和精確度-estimation-and-precision.html"><a href="估計和精確度-estimation-and-precision.html#估計量的特質"><i class="fa fa-check"></i><b>10.2</b> 估計量的特質</a><ul>
<li class="chapter" data-level="10.2.1" data-path="估計和精確度-estimation-and-precision.html"><a href="估計和精確度-estimation-and-precision.html#bias"><i class="fa fa-check"></i><b>10.2.1</b> 偏倚</a></li>
<li class="chapter" data-level="10.2.2" data-path="估計和精確度-estimation-and-precision.html"><a href="估計和精確度-estimation-and-precision.html#估計量的效能-efficiency"><i class="fa fa-check"></i><b>10.2.2</b> 估計量的效能 Efficiency</a></li>
<li class="chapter" data-level="10.2.3" data-path="估計和精確度-estimation-and-precision.html"><a href="估計和精確度-estimation-and-precision.html#均值和中位數的相對效能"><i class="fa fa-check"></i><b>10.2.3</b> 均值和中位數的相對效能</a></li>
<li class="chapter" data-level="10.2.4" data-path="估計和精確度-estimation-and-precision.html"><a href="估計和精確度-estimation-and-precision.html#均方差-mean-square-error-mse"><i class="fa fa-check"></i><b>10.2.4</b> 均方差 mean square error (MSE)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="估計和精確度-estimation-and-precision.html"><a href="估計和精確度-estimation-and-precision.html#samplevarbias"><i class="fa fa-check"></i><b>10.3</b> 總體方差的估計，自由度</a></li>
<li class="chapter" data-level="10.4" data-path="估計和精確度-estimation-and-precision.html"><a href="估計和精確度-estimation-and-precision.html#samplevar"><i class="fa fa-check"></i><b>10.4</b> 樣本方差的樣本分佈</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html"><i class="fa fa-check"></i><b>11</b> 卡方分佈 Chi-square distribution</a><ul>
<li class="chapter" data-level="11.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的期望和方差的證明"><i class="fa fa-check"></i><b>11.1</b> 卡方分佈的期望和方差的證明</a></li>
<li class="chapter" data-level="11.2" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的期望"><i class="fa fa-check"></i><b>11.2</b> 卡方分佈的期望</a></li>
<li class="chapter" data-level="11.3" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#卡方分佈的方差"><i class="fa fa-check"></i><b>11.3</b> 卡方分佈的方差</a><ul>
<li class="chapter" data-level="11.3.1" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#下面來求-ex_14"><i class="fa fa-check"></i><b>11.3.1</b> 下面來求 <span class="math inline">\(E(X_1^4)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chi-square-distribution.html"><a href="chi-square-distribution.html#把上面的推導擴展"><i class="fa fa-check"></i><b>11.4</b> 把上面的推導擴展</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="likelihood-definition.html"><a href="likelihood-definition.html"><i class="fa fa-check"></i><b>12</b> 似然 Likelihood</a><ul>
<li class="chapter" data-level="12.1" data-path="likelihood-definition.html"><a href="likelihood-definition.html#概率-vs.推斷-probability-vs.inference"><i class="fa fa-check"></i><b>12.1</b> 概率 vs. 推斷 Probability vs. Inference</a></li>
<li class="chapter" data-level="12.2" data-path="likelihood-definition.html"><a href="likelihood-definition.html#似然和極大似然估計-likelihood-and-maximum-likelihood-estimators"><i class="fa fa-check"></i><b>12.2</b> 似然和極大似然估計 Likelihood and maximum likelihood estimators</a></li>
<li class="chapter" data-level="12.3" data-path="likelihood-definition.html"><a href="likelihood-definition.html#似然方程的一般化定義"><i class="fa fa-check"></i><b>12.3</b> 似然方程的一般化定義</a></li>
<li class="chapter" data-level="12.4" data-path="likelihood-definition.html"><a href="likelihood-definition.html#對數似然方程-log-likelihood"><i class="fa fa-check"></i><b>12.4</b> 對數似然方程 log-likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="likelihood-definition.html"><a href="likelihood-definition.html#極大似然估計-maximum-likelihood-estimator-mle-的性質"><i class="fa fa-check"></i><b>12.5</b> 極大似然估計 (maximum likelihood estimator, MLE) 的性質：</a></li>
<li class="chapter" data-level="12.6" data-path="likelihood-definition.html"><a href="likelihood-definition.html#likelihood-poi"><i class="fa fa-check"></i><b>12.6</b> 率的似然估計 Likelihood for a rate</a></li>
<li class="chapter" data-level="12.7" data-path="likelihood-definition.html"><a href="likelihood-definition.html#有-n-個獨立觀察時的似然方程和對數似然方程"><i class="fa fa-check"></i><b>12.7</b> 有 <span class="math inline">\(n\)</span> 個獨立觀察時的似然方程和對數似然方程</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="llr.html"><a href="llr.html"><i class="fa fa-check"></i><b>13</b> 對數似然比 Log-likelihood ratio</a><ul>
<li class="chapter" data-level="13.1" data-path="llr.html"><a href="llr.html#正態分佈數據的極大似然和對數似然比"><i class="fa fa-check"></i><b>13.1</b> 正態分佈數據的極大似然和對數似然比</a></li>
<li class="chapter" data-level="13.2" data-path="llr.html"><a href="llr.html#llr-chi1"><i class="fa fa-check"></i><b>13.2</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比</a></li>
<li class="chapter" data-level="13.3" data-path="llr.html"><a href="llr.html#llr-chi"><i class="fa fa-check"></i><b>13.3</b> <span class="math inline">\(n\)</span> 個獨立正態分佈樣本的對數似然比的分佈</a></li>
<li class="chapter" data-level="13.4" data-path="llr.html"><a href="llr.html#似然比信賴區間"><i class="fa fa-check"></i><b>13.4</b> 似然比信賴區間</a><ul>
<li class="chapter" data-level="13.4.1" data-path="llr.html"><a href="llr.html#binomial-ex"><i class="fa fa-check"></i><b>13.4.1</b> 以二項分佈數據爲例</a></li>
<li class="chapter" data-level="13.4.2" data-path="llr.html"><a href="llr.html#normal-ex"><i class="fa fa-check"></i><b>13.4.2</b> 以正態分佈數據爲例</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="llr.html"><a href="llr.html#練習題"><i class="fa fa-check"></i><b>13.5</b> 練習題</a><ul>
<li class="chapter" data-level="13.5.1" data-path="llr.html"><a href="llr.html#q1"><i class="fa fa-check"></i><b>13.5.1</b> Q1</a></li>
<li class="chapter" data-level="13.5.2" data-path="llr.html"><a href="llr.html#q2"><i class="fa fa-check"></i><b>13.5.2</b> Q2</a></li>
<li class="chapter" data-level="13.5.3" data-path="llr.html"><a href="llr.html#q3"><i class="fa fa-check"></i><b>13.5.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="quadratic-llr.html"><a href="quadratic-llr.html"><i class="fa fa-check"></i><b>14</b> 二次方程近似法求對數似然比 approximate log-likelihood ratios</a><ul>
<li class="chapter" data-level="14.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-llr2"><i class="fa fa-check"></i><b>14.1</b> 正態近似法求對數似然 Normal approximation to the log-likelihood</a><ul>
<li class="chapter" data-level="14.1.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#近似法估算對數似然比的信賴區間"><i class="fa fa-check"></i><b>14.1.1</b> 近似法估算對數似然比的信賴區間</a></li>
<li class="chapter" data-level="14.1.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#以泊松分佈爲例"><i class="fa fa-check"></i><b>14.1.2</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.1.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#quadratic-binomial-approx"><i class="fa fa-check"></i><b>14.1.3</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#para-trans"><i class="fa fa-check"></i><b>14.2</b> 參數转换 parameter transformations</a><ul>
<li class="chapter" data-level="14.2.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#Possion-log-transform"><i class="fa fa-check"></i><b>14.2.1</b> 以泊松分佈爲例</a></li>
<li class="chapter" data-level="14.2.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#以二項分佈爲例"><i class="fa fa-check"></i><b>14.2.2</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="quadratic-llr.html"><a href="quadratic-llr.html#練習題-1"><i class="fa fa-check"></i><b>14.3</b> 練習題</a><ul>
<li class="chapter" data-level="14.3.1" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q1-1"><i class="fa fa-check"></i><b>14.3.1</b> Q1</a></li>
<li class="chapter" data-level="14.3.2" data-path="quadratic-llr.html"><a href="quadratic-llr.html#q2-1"><i class="fa fa-check"></i><b>14.3.2</b> Q2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html"><i class="fa fa-check"></i><b>15</b> 假設檢驗的構建 Construction of a hypothesis test</a><ul>
<li class="chapter" data-level="15.1" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#null-and-alter"><i class="fa fa-check"></i><b>15.1</b> 什麼是假設檢驗 Hypothesis testing</a></li>
<li class="chapter" data-level="15.2" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#錯誤概率和效能方程-error-probabilities-and-the-power-function"><i class="fa fa-check"></i><b>15.2</b> 錯誤概率和效能方程 error probabilities and the power function</a><ul>
<li class="chapter" data-level="15.2.1" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#以二項分佈爲例-1"><i class="fa fa-check"></i><b>15.2.1</b> 以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#Neyman-Pearson"><i class="fa fa-check"></i><b>15.3</b> 如何選擇要檢驗的統計量</a><ul>
<li class="chapter" data-level="15.3.1" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#以已知方差的正態分佈爲例"><i class="fa fa-check"></i><b>15.3.1</b> 以已知方差的正態分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#複合假設-composite-hypotheses"><i class="fa fa-check"></i><b>15.4</b> 複合假設 composite hypotheses</a><ul>
<li class="chapter" data-level="15.4.1" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#單側替代假設"><i class="fa fa-check"></i><b>15.4.1</b> 單側替代假設</a></li>
<li class="chapter" data-level="15.4.2" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#雙側替代假設"><i class="fa fa-check"></i><b>15.4.2</b> 雙側替代假設</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#爲反對零假設-h_0-的證據定量"><i class="fa fa-check"></i><b>15.5</b> 爲反對零假設 <span class="math inline">\(H_0\)</span> 的證據定量</a><ul>
<li class="chapter" data-level="15.5.1" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#normal-mean-compare"><i class="fa fa-check"></i><b>15.5.1</b> 回到正態分佈的均值比較問題上來(單側替代假設)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#雙側替代假設情況下雙側-p-值的定量方法"><i class="fa fa-check"></i><b>15.6</b> 雙側替代假設情況下，雙側 <span class="math inline">\(p\)</span> 值的定量方法</a></li>
<li class="chapter" data-level="15.7" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#test-summary"><i class="fa fa-check"></i><b>15.7</b> 假設檢驗構建之總結</a></li>
<li class="chapter" data-level="15.8" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#練習題-2"><i class="fa fa-check"></i><b>15.8</b> 練習題</a><ul>
<li class="chapter" data-level="15.8.1" data-path="假設檢驗的構建-construction-of-a-hypothesis-test.html"><a href="假設檢驗的構建-construction-of-a-hypothesis-test.html#q1-2"><i class="fa fa-check"></i><b>15.8.1</b> Q1</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html"><i class="fa fa-check"></i><b>16</b> 假設檢驗的近似方法</a><ul>
<li class="chapter" data-level="16.1" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#近似和精確檢驗-approximate-and-exact-tests"><i class="fa fa-check"></i><b>16.1</b> 近似和精確檢驗 approximate and exact tests</a></li>
<li class="chapter" data-level="16.2" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#LRT"><i class="fa fa-check"></i><b>16.2</b> 精確檢驗法之 – 似然比檢驗法 Likelihood ratio test</a></li>
<li class="chapter" data-level="16.3" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#練習題-3"><i class="fa fa-check"></i><b>16.3</b> 練習題</a></li>
<li class="chapter" data-level="16.4" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#Wald"><i class="fa fa-check"></i><b>16.4</b> 近似檢驗法之 – Wald 檢驗</a><ul>
<li class="chapter" data-level="16.4.1" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#再以二項分佈爲例"><i class="fa fa-check"></i><b>16.4.1</b> 再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#Score"><i class="fa fa-check"></i><b>16.5</b> 近似檢驗法之 – Score 检验</a><ul>
<li class="chapter" data-level="16.5.1" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#再再以二項分佈爲例"><i class="fa fa-check"></i><b>16.5.1</b> 再再以二項分佈爲例</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#LRTwaldScore-Compare"><i class="fa fa-check"></i><b>16.6</b> LRT, Wald, Score 檢驗三者的比較</a></li>
<li class="chapter" data-level="16.7" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#練習題-4"><i class="fa fa-check"></i><b>16.7</b> 練習題</a><ul>
<li class="chapter" data-level="16.7.1" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#q1-3"><i class="fa fa-check"></i><b>16.7.1</b> Q1</a></li>
<li class="chapter" data-level="16.7.2" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#q2-2"><i class="fa fa-check"></i><b>16.7.2</b> Q2</a></li>
<li class="chapter" data-level="16.7.3" data-path="假設檢驗的近似方法.html"><a href="假設檢驗的近似方法.html#q3-1"><i class="fa fa-check"></i><b>16.7.3</b> Q3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="正態誤差模型-normal-error-models.html"><a href="正態誤差模型-normal-error-models.html"><i class="fa fa-check"></i><b>17</b> 正態誤差模型 Normal error models</a><ul>
<li class="chapter" data-level="17.1" data-path="正態誤差模型-normal-error-models.html"><a href="正態誤差模型-normal-error-models.html#服從正態分佈的隨機變量"><i class="fa fa-check"></i><b>17.1</b> 服從正態分佈的隨機變量</a></li>
<li class="chapter" data-level="17.2" data-path="正態誤差模型-normal-error-models.html"><a href="正態誤差模型-normal-error-models.html#Fandtdistr"><i class="fa fa-check"></i><b>17.2</b> <span class="math inline">\(F\)</span> 分佈和 <span class="math inline">\(t\)</span> 分佈的概念</a></li>
<li class="chapter" data-level="17.3" data-path="正態誤差模型-normal-error-models.html"><a href="正態誤差模型-normal-error-models.html#兩個參數的模型"><i class="fa fa-check"></i><b>17.3</b> 兩個參數的模型</a><ul>
<li class="chapter" data-level="17.3.1" data-path="正態誤差模型-normal-error-models.html"><a href="正態誤差模型-normal-error-models.html#一組數據兩個參數"><i class="fa fa-check"></i><b>17.3.1</b> 一組數據兩個參數</a></li>
<li class="chapter" data-level="17.3.2" data-path="正態誤差模型-normal-error-models.html"><a href="正態誤差模型-normal-error-models.html#兩組數據各一個參數"><i class="fa fa-check"></i><b>17.3.2</b> 兩組數據各一個參數</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="正態誤差模型-normal-error-models.html"><a href="正態誤差模型-normal-error-models.html#正態分佈概率密度方程中總體均值和方差都未知-單樣本-t-檢驗-one-sample-t-test-的統計學推導"><i class="fa fa-check"></i><b>17.4</b> 正態分佈概率密度方程中總體均值和方差都未知 (單樣本 <span class="math inline">\(t\)</span> 檢驗 one sample <span class="math inline">\(t\)</span> test 的統計學推導)</a></li>
<li class="chapter" data-level="17.5" data-path="正態誤差模型-normal-error-models.html"><a href="正態誤差模型-normal-error-models.html#比較兩組獨立數據的均值-two-sample-t-test-with-equal-unknown-sigma2"><i class="fa fa-check"></i><b>17.5</b> 比較兩組獨立數據的均值 two sample <span class="math inline">\(t\)</span> test with equal unknown <span class="math inline">\(\sigma^2\)</span></a></li>
<li class="chapter" data-level="17.6" data-path="正態誤差模型-normal-error-models.html"><a href="正態誤差模型-normal-error-models.html#各個統計分佈之間的關係"><i class="fa fa-check"></i><b>17.6</b> 各個統計分佈之間的關係</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="多個參數時的統計推斷-inference-with-multiple-parameters-i.html"><a href="多個參數時的統計推斷-inference-with-multiple-parameters-i.html"><i class="fa fa-check"></i><b>18</b> 多個參數時的統計推斷 Inference with multiple parameters I</a><ul>
<li class="chapter" data-level="18.1" data-path="多個參數時的統計推斷-inference-with-multiple-parameters-i.html"><a href="多個參數時的統計推斷-inference-with-multiple-parameters-i.html#多參數-multiple-parameters---lrt"><i class="fa fa-check"></i><b>18.1</b> 多參數 multiple parameters - LRT</a><ul>
<li class="chapter" data-level="18.1.1" data-path="多個參數時的統計推斷-inference-with-multiple-parameters-i.html"><a href="多個參數時的統計推斷-inference-with-multiple-parameters-i.html#似然-likelihood"><i class="fa fa-check"></i><b>18.1.1</b> 似然 likelihood</a></li>
<li class="chapter" data-level="18.1.2" data-path="多個參數時的統計推斷-inference-with-multiple-parameters-i.html"><a href="多個參數時的統計推斷-inference-with-multiple-parameters-i.html#對數似然比檢驗"><i class="fa fa-check"></i><b>18.1.2</b> 對數似然比檢驗</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="多個參數時的統計推斷-inference-with-multiple-parameters-i.html"><a href="多個參數時的統計推斷-inference-with-multiple-parameters-i.html#多參數-wald-檢驗---wald-test"><i class="fa fa-check"></i><b>18.2</b> 多參數 Wald 檢驗 - Wald test</a></li>
<li class="chapter" data-level="18.3" data-path="多個參數時的統計推斷-inference-with-multiple-parameters-i.html"><a href="多個參數時的統計推斷-inference-with-multiple-parameters-i.html#多參數-score-檢驗---score-test"><i class="fa fa-check"></i><b>18.3</b> 多參數 Score 檢驗 - Score test</a></li>
<li class="chapter" data-level="18.4" data-path="多個參數時的統計推斷-inference-with-multiple-parameters-i.html"><a href="多個參數時的統計推斷-inference-with-multiple-parameters-i.html#condilikeli"><i class="fa fa-check"></i><b>18.4</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="18.5" data-path="多個參數時的統計推斷-inference-with-multiple-parameters-i.html"><a href="多個參數時的統計推斷-inference-with-multiple-parameters-i.html#練習"><i class="fa fa-check"></i><b>18.5</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html"><i class="fa fa-check"></i><b>19</b> 多個參數時的統計推斷 – 子集似然函數 profile log-likelihoods</a><ul>
<li class="chapter" data-level="19.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集似然法推導的過程總結"><i class="fa fa-check"></i><b>19.1</b> 子集似然法推導的過程總結</a><ul>
<li class="chapter" data-level="19.1.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然方程的分佈"><i class="fa fa-check"></i><b>19.1.1</b> 子集對數似然方程的分佈</a></li>
<li class="chapter" data-level="19.1.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#假設檢驗過程舉例"><i class="fa fa-check"></i><b>19.1.2</b> 假設檢驗過程舉例</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然比的近似"><i class="fa fa-check"></i><b>19.2</b> 子集對數似然比的近似</a><ul>
<li class="chapter" data-level="19.2.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#子集對數似然比近似的一般化"><i class="fa fa-check"></i><b>19.2.1</b> 子集對數似然比近似的一般化</a></li>
<li class="chapter" data-level="19.2.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#事件發生率之比的-wald-檢驗統計量"><i class="fa fa-check"></i><b>19.2.2</b> 事件發生率之比的 Wald 檢驗統計量</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#練習-practical"><i class="fa fa-check"></i><b>19.3</b> 練習 Practical</a></li>
<li class="chapter" data-level="19.4" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#總結"><i class="fa fa-check"></i><b>19.4</b> 總結</a><ul>
<li class="chapter" data-level="19.4.1" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#快速複習"><i class="fa fa-check"></i><b>19.4.1</b> 快速複習</a></li>
<li class="chapter" data-level="19.4.2" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#試爲下面的醫學研究問題提出合適的統計學模型"><i class="fa fa-check"></i><b>19.4.2</b> 試爲下面的醫學研究問題提出合適的統計學模型</a></li>
<li class="chapter" data-level="19.4.3" data-path="profile-log-likelihood.html"><a href="profile-log-likelihood.html#醫生來找統計學家問問題"><i class="fa fa-check"></i><b>19.4.3</b> 醫生來找統計學家問問題</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III 統計分析方法 Analytical Techniques</b></span></li>
<li class="chapter" data-level="20" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html"><i class="fa fa-check"></i><b>20</b> 探索數據和簡單描述</a><ul>
<li class="chapter" data-level="20.1" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#數據分析的流程"><i class="fa fa-check"></i><b>20.1</b> 數據分析的流程</a><ul>
<li class="chapter" data-level="20.1.1" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#研究設計和實施"><i class="fa fa-check"></i><b>20.1.1</b> 研究設計和實施</a></li>
<li class="chapter" data-level="20.1.2" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#數據分析"><i class="fa fa-check"></i><b>20.1.2</b> 數據分析</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#數據類型"><i class="fa fa-check"></i><b>20.2</b> 數據類型</a></li>
<li class="chapter" data-level="20.3" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#如何總結並展示數據"><i class="fa fa-check"></i><b>20.3</b> 如何總結並展示數據</a><ul>
<li class="chapter" data-level="20.3.1" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#離散型分類型數據的描述---頻數分佈表-frequency-table"><i class="fa fa-check"></i><b>20.3.1</b> 離散型分類型數據的描述 - 頻數分佈表 frequency table</a></li>
<li class="chapter" data-level="20.3.2" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#連續型變量"><i class="fa fa-check"></i><b>20.3.2</b> 連續型變量</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#數據總結方案位置分散偏度和峰度"><i class="fa fa-check"></i><b>20.4</b> 數據總結方案：位置，分散，偏度，和峰度</a><ul>
<li class="chapter" data-level="20.4.1" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#位置"><i class="fa fa-check"></i><b>20.4.1</b> 位置</a></li>
<li class="chapter" data-level="20.4.2" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#分散"><i class="fa fa-check"></i><b>20.4.2</b> 分散</a></li>
<li class="chapter" data-level="20.4.3" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#偏度-skewness"><i class="fa fa-check"></i><b>20.4.3</b> 偏度 skewness</a></li>
<li class="chapter" data-level="20.4.4" data-path="探索數據和簡單描述.html"><a href="探索數據和簡單描述.html#峯度-kurtosis"><i class="fa fa-check"></i><b>20.4.4</b> 峯度 kurtosis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html"><i class="fa fa-check"></i><b>21</b> 信賴區間 confidence intervals</a><ul>
<li class="chapter" data-level="21.1" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#定義"><i class="fa fa-check"></i><b>21.1</b> 定義</a></li>
<li class="chapter" data-level="21.2" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#利用總體參數的樣本分佈求信賴區間"><i class="fa fa-check"></i><b>21.2</b> 利用總體參數的樣本分佈求信賴區間</a></li>
<li class="chapter" data-level="21.3" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#情況1已知方差的正態分佈數據均值的信賴區間"><i class="fa fa-check"></i><b>21.3</b> 情況1：已知方差的正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.4" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#CImean"><i class="fa fa-check"></i><b>21.4</b> 信賴區間的意義</a></li>
<li class="chapter" data-level="21.5" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#AT2-5"><i class="fa fa-check"></i><b>21.5</b> 情況2：未知方差，但是已知服從正態分佈數據均值的信賴區間</a></li>
<li class="chapter" data-level="21.6" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#varCI"><i class="fa fa-check"></i><b>21.6</b> 情況3：服從正態分佈的隨機變量方差的信賴區間</a></li>
<li class="chapter" data-level="21.7" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#當樣本量足夠大時"><i class="fa fa-check"></i><b>21.7</b> 當樣本量足夠大時</a></li>
<li class="chapter" data-level="21.8" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#情況4求人羣百分比的信賴區間"><i class="fa fa-check"></i><b>21.8</b> 情況4：求人羣百分比的信賴區間</a><ul>
<li class="chapter" data-level="21.8.1" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#一般原則"><i class="fa fa-check"></i><b>21.8.1</b> 一般原則</a></li>
<li class="chapter" data-level="21.8.2" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#exactprop"><i class="fa fa-check"></i><b>21.8.2</b> 二項分佈的“精確法”計算信賴區間</a></li>
<li class="chapter" data-level="21.8.3" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#二項分佈的近似法計算信賴區間"><i class="fa fa-check"></i><b>21.8.3</b> 二項分佈的近似法計算信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="21.9" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#CIrate"><i class="fa fa-check"></i><b>21.9</b> 率的信賴區間</a><ul>
<li class="chapter" data-level="21.9.1" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#利用泊松分佈精確計算"><i class="fa fa-check"></i><b>21.9.1</b> 利用泊松分佈精確計算</a></li>
<li class="chapter" data-level="21.9.2" data-path="信賴區間-confidence-intervals-1.html"><a href="信賴區間-confidence-intervals-1.html#利用正態近似法計算"><i class="fa fa-check"></i><b>21.9.2</b> 利用正態近似法計算</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="假設檢驗.html"><a href="假設檢驗.html"><i class="fa fa-check"></i><b>22</b> 假設檢驗</a><ul>
<li class="chapter" data-level="22.1" data-path="假設檢驗.html"><a href="假設檢驗.html#拋硬幣的例子"><i class="fa fa-check"></i><b>22.1</b> 拋硬幣的例子</a><ul>
<li class="chapter" data-level="22.1.1" data-path="假設檢驗.html"><a href="假設檢驗.html#單側和雙側檢驗"><i class="fa fa-check"></i><b>22.1.1</b> 單側和雙側檢驗</a></li>
<li class="chapter" data-level="22.1.2" data-path="假設檢驗.html"><a href="假設檢驗.html#p-值的意義"><i class="fa fa-check"></i><b>22.1.2</b> <span class="math inline">\(p\)</span> 值的意義</a></li>
<li class="chapter" data-level="22.1.3" data-path="假設檢驗.html"><a href="假設檢驗.html#p-值和信賴區間的關係"><i class="fa fa-check"></i><b>22.1.3</b> <span class="math inline">\(p\)</span> 值和信賴區間的關係</a></li>
</ul></li>
<li class="chapter" data-level="22.2" data-path="假設檢驗.html"><a href="假設檢驗.html#二項分佈的精確假設檢驗"><i class="fa fa-check"></i><b>22.2</b> 二項分佈的精確假設檢驗</a></li>
<li class="chapter" data-level="22.3" data-path="假設檢驗.html"><a href="假設檢驗.html#當樣本量較大"><i class="fa fa-check"></i><b>22.3</b> 當樣本量較大</a></li>
<li class="chapter" data-level="22.4" data-path="假設檢驗.html"><a href="假設檢驗.html#二項分佈的正態近似法假設檢驗"><i class="fa fa-check"></i><b>22.4</b> 二項分佈的正態近似法假設檢驗</a><ul>
<li class="chapter" data-level="22.4.1" data-path="假設檢驗.html"><a href="假設檢驗.html#連續性校正-continuity-correction"><i class="fa fa-check"></i><b>22.4.1</b> 連續性校正 continuity correction</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="假設檢驗.html"><a href="假設檢驗.html#AT3-5"><i class="fa fa-check"></i><b>22.5</b> 情況1：對均值進行假設檢驗 (方差已知)</a></li>
<li class="chapter" data-level="22.6" data-path="假設檢驗.html"><a href="假設檢驗.html#OneSampleT"><i class="fa fa-check"></i><b>22.6</b> 情況2：對均值進行假設檢驗 (方差未知) the one-sample t-test</a></li>
<li class="chapter" data-level="22.7" data-path="假設檢驗.html"><a href="假設檢驗.html#情況3對配對實驗數據的均值差進行假設檢驗-the-paired-t-test"><i class="fa fa-check"></i><b>22.7</b> 情況3：對配對實驗數據的均值差進行假設檢驗 the paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="相關-association.html"><a href="相關-association.html"><i class="fa fa-check"></i><b>23</b> 相關 association</a><ul>
<li class="chapter" data-level="23.1" data-path="相關-association.html"><a href="相關-association.html#背景介紹"><i class="fa fa-check"></i><b>23.1</b> 背景介紹</a></li>
<li class="chapter" data-level="23.2" data-path="相關-association.html"><a href="相關-association.html#兩個連續型變量的相關分析"><i class="fa fa-check"></i><b>23.2</b> 兩個連續型變量的相關分析</a><ul>
<li class="chapter" data-level="23.2.1" data-path="相關-association.html"><a href="相關-association.html#相關係數的定義"><i class="fa fa-check"></i><b>23.2.1</b> 相關係數的定義</a></li>
<li class="chapter" data-level="23.2.2" data-path="相關-association.html"><a href="相關-association.html#相關係數的性質"><i class="fa fa-check"></i><b>23.2.2</b> 相關係數的性質</a></li>
<li class="chapter" data-level="23.2.3" data-path="相關-association.html"><a href="相關-association.html#對相關係數是否爲零進行假設檢驗"><i class="fa fa-check"></i><b>23.2.3</b> 對相關係數是否爲零進行假設檢驗</a></li>
<li class="chapter" data-level="23.2.4" data-path="相關-association.html"><a href="相關-association.html#相關係數的-95-信賴區間"><i class="fa fa-check"></i><b>23.2.4</b> 相關係數的 <span class="math inline">\(95\%\)</span> 信賴區間</a></li>
<li class="chapter" data-level="23.2.5" data-path="相關-association.html"><a href="相關-association.html#比較兩個相關係數是否相等"><i class="fa fa-check"></i><b>23.2.5</b> 比較兩個相關係數是否相等</a></li>
<li class="chapter" data-level="23.2.6" data-path="相關-association.html"><a href="相關-association.html#相關係數那些事兒"><i class="fa fa-check"></i><b>23.2.6</b> 相關係數那些事兒</a></li>
<li class="chapter" data-level="23.2.7" data-path="相關-association.html"><a href="相關-association.html#在-r-裏面計算相關係數"><i class="fa fa-check"></i><b>23.2.7</b> 在 R 裏面計算相關係數</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="相關-association.html"><a href="相關-association.html#二元變量之間的相關性-association-between-pairs-of-binary-variables"><i class="fa fa-check"></i><b>23.3</b> 二元變量之間的相關性 association between pairs of binary variables</a><ul>
<li class="chapter" data-level="23.3.1" data-path="相關-association.html"><a href="相關-association.html#or-的信賴區間"><i class="fa fa-check"></i><b>23.3.1</b> OR 的信賴區間</a></li>
<li class="chapter" data-level="23.3.2" data-path="相關-association.html"><a href="相關-association.html#比值比的假設檢驗"><i class="fa fa-check"></i><b>23.3.2</b> 比值比的假設檢驗</a></li>
<li class="chapter" data-level="23.3.3" data-path="相關-association.html"><a href="相關-association.html#chisquaretest"><i class="fa fa-check"></i><b>23.3.3</b> 兩個百分比的卡方檢驗</a></li>
<li class="chapter" data-level="23.3.4" data-path="相關-association.html"><a href="相關-association.html#確切檢驗法-fishers-exact-test"><i class="fa fa-check"></i><b>23.3.4</b> 確切檢驗法 Fisher’s “exact” test</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="相關-association.html"><a href="相關-association.html#多分類-無排序-的情況-mtimes-n-表格"><i class="fa fa-check"></i><b>23.4</b> 多分類 (無排序) 的情況 <span class="math inline">\(M\times N\)</span> 表格</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="比較-comparisons.html"><a href="比較-comparisons.html"><i class="fa fa-check"></i><b>24</b> 比較 Comparisons</a><ul>
<li class="chapter" data-level="24.1" data-path="比較-comparisons.html"><a href="比較-comparisons.html#比較兩個均值-comparing-two-population-means"><i class="fa fa-check"></i><b>24.1</b> 比較兩個均值 comparing two population means</a><ul>
<li class="chapter" data-level="24.1.1" data-path="比較-comparisons.html"><a href="比較-comparisons.html#當方差已知且數據服從正態分佈-z-test"><i class="fa fa-check"></i><b>24.1.1</b> 當方差已知，且數據服從正態分佈 Z-test</a></li>
<li class="chapter" data-level="24.1.2" data-path="比較-comparisons.html"><a href="比較-comparisons.html#當方差未知但是方差可以被認爲相等且數據服從正態分佈-two-sample-t-test"><i class="fa fa-check"></i><b>24.1.2</b> 當方差未知，但是方差可以被認爲相等，且數據服從正態分佈 two sample <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="24.1.3" data-path="比較-comparisons.html"><a href="比較-comparisons.html#練習-1"><i class="fa fa-check"></i><b>24.1.3</b> 練習</a></li>
<li class="chapter" data-level="24.1.4" data-path="比較-comparisons.html"><a href="比較-comparisons.html#當方差未知但是方差不可以被認爲相等且數據服從正態分佈"><i class="fa fa-check"></i><b>24.1.4</b> 當方差未知，但是方差<strong>不可以</strong>被認爲相等，且數據服從正態分佈</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="比較-comparisons.html"><a href="比較-comparisons.html#兩個人羣的方差比較"><i class="fa fa-check"></i><b>24.2</b> 兩個人羣的方差比較</a><ul>
<li class="chapter" data-level="24.2.1" data-path="比較-comparisons.html"><a href="比較-comparisons.html#Ftest"><i class="fa fa-check"></i><b>24.2.1</b> 方差比值檢驗 variance ratio test</a></li>
<li class="chapter" data-level="24.2.2" data-path="比較-comparisons.html"><a href="比較-comparisons.html#信賴區間"><i class="fa fa-check"></i><b>24.2.2</b> 信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="比較-comparisons.html"><a href="比較-comparisons.html#比較兩個百分比"><i class="fa fa-check"></i><b>24.3</b> 比較兩個百分比</a><ul>
<li class="chapter" data-level="24.3.1" data-path="比較-comparisons.html"><a href="比較-comparisons.html#proportiontest"><i class="fa fa-check"></i><b>24.3.1</b> 兩個百分比差是否爲零的推斷 Risk difference</a></li>
<li class="chapter" data-level="24.3.2" data-path="比較-comparisons.html"><a href="比較-comparisons.html#兩個百分比商是否爲-1-的推斷-relative-riskrisk-ratio"><i class="fa fa-check"></i><b>24.3.2</b> 兩個百分比商是否爲 1 的推斷 relative risk/risk ratio</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html"><i class="fa fa-check"></i><b>25</b> 前提和數據轉換 Assumptions and transformations</a><ul>
<li class="chapter" data-level="25.1" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html#穩健性"><i class="fa fa-check"></i><b>25.1</b> 穩健性</a></li>
<li class="chapter" data-level="25.2" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html#正態性"><i class="fa fa-check"></i><b>25.2</b> 正態性</a><ul>
<li class="chapter" data-level="25.2.1" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html#normalplot"><i class="fa fa-check"></i><b>25.2.1</b> 正態分佈圖 normal plot</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html#總結連續型變量不服從正態分佈時的處理方案"><i class="fa fa-check"></i><b>25.3</b> 總結連續型變量不服從正態分佈時的處理方案</a></li>
<li class="chapter" data-level="25.4" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html#數學冪轉換-power-transformations"><i class="fa fa-check"></i><b>25.4</b> 數學冪轉換 power transformations</a><ul>
<li class="chapter" data-level="25.4.1" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html#對數轉換-logarithmic-transformation"><i class="fa fa-check"></i><b>25.4.1</b> 對數轉換 logarithmic Transformation</a></li>
<li class="chapter" data-level="25.4.2" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html#逆轉換信賴區間-back-transformation-of-cis"><i class="fa fa-check"></i><b>25.4.2</b> 逆轉換信賴區間 back-transformation of CIs</a></li>
<li class="chapter" data-level="25.4.3" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html#對數正態分佈-log-normal-distribution"><i class="fa fa-check"></i><b>25.4.3</b> 對數正態分佈 log-normal distribution</a></li>
<li class="chapter" data-level="25.4.4" data-path="前提和數據轉換-assumptions-and-transformations.html"><a href="前提和數據轉換-assumptions-and-transformations.html#百分比的轉換"><i class="fa fa-check"></i><b>25.4.4</b> 百分比的轉換</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV 線性迴歸 Linear Regression</b></span></li>
<li class="chapter" data-level="26" data-path="lm.html"><a href="lm.html"><i class="fa fa-check"></i><b>26</b> 簡單線性迴歸 Simple Linear Regression</a><ul>
<li class="chapter" data-level="26.1" data-path="lm.html"><a href="lm.html#一些背景和術語"><i class="fa fa-check"></i><b>26.1</b> 一些背景和術語</a></li>
<li class="chapter" data-level="26.2" data-path="lm.html"><a href="lm.html#簡單線性迴歸模型-simple-linear-regression-model"><i class="fa fa-check"></i><b>26.2</b> 簡單線性迴歸模型 simple linear regression model</a><ul>
<li class="chapter" data-level="26.2.1" data-path="lm.html"><a href="lm.html#數據-a"><i class="fa fa-check"></i><b>26.2.1</b> 數據 A</a></li>
<li class="chapter" data-level="26.2.2" data-path="lm.html"><a href="lm.html#數據-b"><i class="fa fa-check"></i><b>26.2.2</b> 數據 B</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="lm.html"><a href="lm.html#區分因變量和預測變量"><i class="fa fa-check"></i><b>26.3</b> 區分因變量和預測變量</a><ul>
<li class="chapter" data-level="26.3.1" data-path="lm.html"><a href="lm.html#meanfunction"><i class="fa fa-check"></i><b>26.3.1</b> 均值 (期待值) 公式</a></li>
<li class="chapter" data-level="26.3.2" data-path="lm.html"><a href="lm.html#條件分佈和方差-the-conditional-distribution-and-the-variance-function"><i class="fa fa-check"></i><b>26.3.2</b> 條件分佈和方差 the conditional distribution and the variance function</a></li>
<li class="chapter" data-level="26.3.3" data-path="lm.html"><a href="lm.html#defLM"><i class="fa fa-check"></i><b>26.3.3</b> 定義簡單線性迴歸模型</a></li>
<li class="chapter" data-level="26.3.4" data-path="lm.html"><a href="lm.html#殘差-residuals"><i class="fa fa-check"></i><b>26.3.4</b> 殘差 residuals</a></li>
</ul></li>
<li class="chapter" data-level="26.4" data-path="lm.html"><a href="lm.html#參數的估計-estimation-of-parameters"><i class="fa fa-check"></i><b>26.4</b> 參數的估計 estimation of parameters</a><ul>
<li class="chapter" data-level="26.4.1" data-path="lm.html"><a href="lm.html#MLEalphabeta"><i class="fa fa-check"></i><b>26.4.1</b> 普通最小二乘法估計 <span class="math inline">\(\alpha, \beta\)</span></a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="lm.html"><a href="lm.html#ResidualVar"><i class="fa fa-check"></i><b>26.5</b> 殘差方差的估計 Estimation of the residual variance <span class="math inline">\((\sigma^2)\)</span></a></li>
<li class="chapter" data-level="26.6" data-path="lm.html"><a href="lm.html#growgam"><i class="fa fa-check"></i><b>26.6</b> R 演示 例 1： 圖 @ref(fig:age-wt) 數據</a></li>
<li class="chapter" data-level="26.7" data-path="lm.html"><a href="lm.html#binarylms"><i class="fa fa-check"></i><b>26.7</b> R 演示 例 2： 表@ref(tab:walk) 數據</a></li>
<li class="chapter" data-level="26.8" data-path="lm.html"><a href="lm.html#exeChol"><i class="fa fa-check"></i><b>26.8</b> 練習</a><ul>
<li class="chapter" data-level="26.8.1" data-path="lm.html"><a href="lm.html#兩次測量的膽固醇水平分別用-c_1-c_2-來標記的話考慮這樣的簡單線性迴歸模型c_2alphabeta-c_2-varepsilon我們進行這樣迴歸的前提假設有哪些"><i class="fa fa-check"></i><b>26.8.1</b> 兩次測量的膽固醇水平分別用 <span class="math inline">\(C_1, C_2\)</span> 來標記的話，考慮這樣的簡單線性迴歸模型：<span class="math inline">\(C_2=\alpha+\beta C_2 + \varepsilon\)</span>。我們進行這樣迴歸的前提假設有哪些？</a></li>
<li class="chapter" data-level="26.8.2" data-path="lm.html"><a href="lm.html#計算普通最小二乘法-ols-下截距和斜率的估計值-hatalpha-hatbeta"><i class="fa fa-check"></i><b>26.8.2</b> 計算普通最小二乘法 (OLS) 下，截距和斜率的估計值 <span class="math inline">\(\hat\alpha, \hat\beta\)</span></a></li>
<li class="chapter" data-level="26.8.3" data-path="lm.html"><a href="lm.html#和迴歸模型計算的結果作比較解釋這些估計值的含義"><i class="fa fa-check"></i><b>26.8.3</b> 和迴歸模型計算的結果作比較，解釋這些估計值的含義</a></li>
<li class="chapter" data-level="26.8.4" data-path="lm.html"><a href="lm.html#加上計算的估計值直線-即迴歸直線"><i class="fa fa-check"></i><b>26.8.4</b> 加上計算的估計值直線 (即迴歸直線)</a></li>
<li class="chapter" data-level="26.8.5" data-path="lm.html"><a href="lm.html#diagnosis"><i class="fa fa-check"></i><b>26.8.5</b> 下面的代碼用於模型的假設診斷</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><i class="fa fa-check"></i><b>27</b> 最小二乘估計的性質和推斷 Ordinary Least Squares Estimators and Inference</a><ul>
<li class="chapter" data-level="27.1" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#ols-估計量的性質"><i class="fa fa-check"></i><b>27.1</b> OLS 估計量的性質</a></li>
<li class="chapter" data-level="27.2" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#beta"><i class="fa fa-check"></i><b>27.2</b> <span class="math inline">\(\hat\beta\)</span> 的性質</a><ul>
<li class="chapter" data-level="27.2.1" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#randbeta"><i class="fa fa-check"></i><b>27.2.1</b> <span class="math inline">\(Y\)</span> 對 <span class="math inline">\(X\)</span> 迴歸， 和 <span class="math inline">\(X\)</span> 對 <span class="math inline">\(Y\)</span> 迴歸</a></li>
<li class="chapter" data-level="27.2.2" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#例-1-還是圖-reffigage-wt-數據"><i class="fa fa-check"></i><b>27.2.2</b> 例 1： 還是圖 @ref(fig:age-wt) 數據</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#截距和迴歸係數的方差協方差"><i class="fa fa-check"></i><b>27.3</b> 截距和迴歸係數的方差，協方差</a><ul>
<li class="chapter" data-level="27.3.1" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#centring"><i class="fa fa-check"></i><b>27.3.1</b> 中心化 centring</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#alpha-beta-的推斷"><i class="fa fa-check"></i><b>27.4</b> <span class="math inline">\(\alpha, \beta\)</span> 的推斷</a><ul>
<li class="chapter" data-level="27.4.1" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#對迴歸係數進行假設檢驗"><i class="fa fa-check"></i><b>27.4.1</b> 對迴歸係數進行假設檢驗</a></li>
<li class="chapter" data-level="27.4.2" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#迴歸係數截距的信賴區間"><i class="fa fa-check"></i><b>27.4.2</b> 迴歸係數，截距的信賴區間</a></li>
<li class="chapter" data-level="27.4.3" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#預測值的信賴區間-置信帶---測量迴歸曲線本身的不確定性"><i class="fa fa-check"></i><b>27.4.3</b> 預測值的信賴區間 (置信帶) - 測量迴歸曲線本身的不確定性</a></li>
<li class="chapter" data-level="27.4.4" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#預測帶-reference-range---包含了-95-觀察值的區間"><i class="fa fa-check"></i><b>27.4.4</b> 預測帶 Reference range - 包含了 95% 觀察值的區間</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#rsquare"><i class="fa fa-check"></i><b>27.5</b> 線性迴歸模型和 Pearson 相關係數</a><ul>
<li class="chapter" data-level="27.5.1" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#r2-可以理解爲因變量平方和被模型解釋的比例"><i class="fa fa-check"></i><b>27.5.1</b> <span class="math inline">\(r^2\)</span> 可以理解爲因變量平方和被模型解釋的比例</a></li>
</ul></li>
<li class="chapter" data-level="27.6" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#t-r2-F"><i class="fa fa-check"></i><b>27.6</b> Pearson 相關係數和模型迴歸係數的檢驗統計量 <span class="math inline">\(t\)</span> 之間的關係</a></li>
<li class="chapter" data-level="27.7" data-path="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html"><a href="最小二乘估計的性質和推斷-ordinary-least-squares-estimators-and-inference.html#練習-2"><i class="fa fa-check"></i><b>27.7</b> 練習</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="ANOVA.html"><a href="ANOVA.html"><i class="fa fa-check"></i><b>28</b> 方差分析 Introduction to Analysis of Variance</a><ul>
<li class="chapter" data-level="28.1" data-path="ANOVA.html"><a href="ANOVA.html#背景"><i class="fa fa-check"></i><b>28.1</b> 背景</a></li>
<li class="chapter" data-level="28.2" data-path="ANOVA.html"><a href="ANOVA.html#簡單線性迴歸模型的方差分析"><i class="fa fa-check"></i><b>28.2</b> 簡單線性迴歸模型的方差分析</a><ul>
<li class="chapter" data-level="28.2.1" data-path="ANOVA.html"><a href="ANOVA.html#兩個模型的參數估計"><i class="fa fa-check"></i><b>28.2.1</b> 兩個模型的參數估計</a></li>
<li class="chapter" data-level="28.2.2" data-path="ANOVA.html"><a href="ANOVA.html#分割零假設模型的殘差平方和"><i class="fa fa-check"></i><b>28.2.2</b> 分割零假設模型的殘差平方和</a></li>
<li class="chapter" data-level="28.2.3" data-path="ANOVA.html"><a href="ANOVA.html#Rsquare"><i class="fa fa-check"></i><b>28.2.3</b> <span class="math inline">\(R^2\)</span> – 我的名字叫<strong>決定係數</strong> coefficient of determination</a></li>
<li class="chapter" data-level="28.2.4" data-path="ANOVA.html"><a href="ANOVA.html#方差分析表格-the-anova-table"><i class="fa fa-check"></i><b>28.2.4</b> 方差分析表格 the ANOVA table</a></li>
<li class="chapter" data-level="28.2.5" data-path="ANOVA.html"><a href="ANOVA.html#用-anova-進行假設檢驗"><i class="fa fa-check"></i><b>28.2.5</b> 用 ANOVA 進行假設檢驗</a></li>
<li class="chapter" data-level="28.2.6" data-path="ANOVA.html"><a href="ANOVA.html#lm-Ftest"><i class="fa fa-check"></i><b>28.2.6</b> 簡單線性迴歸時的 <span class="math inline">\(F\)</span> 檢驗</a></li>
<li class="chapter" data-level="28.2.7" data-path="ANOVA.html"><a href="ANOVA.html#F-t-same"><i class="fa fa-check"></i><b>28.2.7</b> 簡單線性迴歸時 <span class="math inline">\(F\)</span> 檢驗和 <span class="math inline">\(t\)</span> 檢驗的一致性</a></li>
</ul></li>
<li class="chapter" data-level="28.3" data-path="ANOVA.html"><a href="ANOVA.html#分類變量用作預測變量時的-anova"><i class="fa fa-check"></i><b>28.3</b> 分類變量用作預測變量時的 ANOVA</a><ul>
<li class="chapter" data-level="28.3.1" data-path="ANOVA.html"><a href="ANOVA.html#一個二分類預測變量"><i class="fa fa-check"></i><b>28.3.1</b> 一個二分類預測變量</a></li>
<li class="chapter" data-level="28.3.2" data-path="ANOVA.html"><a href="ANOVA.html#一個模型兩種表述"><i class="fa fa-check"></i><b>28.3.2</b> 一個模型，兩種表述</a></li>
<li class="chapter" data-level="28.3.3" data-path="ANOVA.html"><a href="ANOVA.html#分組變量的平方和"><i class="fa fa-check"></i><b>28.3.3</b> 分組變量的平方和</a></li>
<li class="chapter" data-level="28.3.4" data-path="ANOVA.html"><a href="ANOVA.html#簡單模型的分組變量大於兩組的情況"><i class="fa fa-check"></i><b>28.3.4</b> 簡單模型的分組變量大於兩組的情況</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html"><i class="fa fa-check"></i><b>29</b> 多元模型分析 Multivariable Models</a><ul>
<li class="chapter" data-level="29.1" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#兩個預測變量的線性迴歸模型"><i class="fa fa-check"></i><b>29.1</b> 兩個預測變量的線性迴歸模型</a><ul>
<li class="chapter" data-level="29.1.1" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#數學標記法和解釋"><i class="fa fa-check"></i><b>29.1.1</b> 數學標記法和解釋</a></li>
<li class="chapter" data-level="29.1.2" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#最小平方和估計-least-squares-estimation"><i class="fa fa-check"></i><b>29.1.2</b> 最小平方和估計 Least Squares Estimation</a></li>
</ul></li>
<li class="chapter" data-level="29.2" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#線性回歸模型中使用分組變量"><i class="fa fa-check"></i><b>29.2</b> 線性回歸模型中使用分組變量</a></li>
<li class="chapter" data-level="29.3" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#協方差分析模型-the-analysis-of-covariance-ancova-model"><i class="fa fa-check"></i><b>29.3</b> 協方差分析模型 the Analysis of Covariance (ANCOVA) Model</a></li>
<li class="chapter" data-level="29.4" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#偏回歸係數的變化"><i class="fa fa-check"></i><b>29.4</b> 偏回歸係數的變化</a><ul>
<li class="chapter" data-level="29.4.1" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#情況1-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.1</b> 情況1： <span class="math inline">\(\beta_1 &gt; \beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.2" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#情況2beta_1beta_1"><i class="fa fa-check"></i><b>29.4.2</b> 情況2：<span class="math inline">\(\beta_1&lt;\beta_1^*\)</span></a></li>
<li class="chapter" data-level="29.4.3" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#情況3-beta_1-beta_1"><i class="fa fa-check"></i><b>29.4.3</b> 情況3： <span class="math inline">\(\beta_1 = \beta_1^*\)</span></a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#confounding"><i class="fa fa-check"></i><b>29.5</b> 混雜 confounding</a><ul>
<li class="chapter" data-level="29.5.1" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#作為媒介-mediation-effect"><i class="fa fa-check"></i><b>29.5.1</b> 作為媒介 mediation effect</a></li>
<li class="chapter" data-level="29.5.2" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#兩個預測變量之間的關係"><i class="fa fa-check"></i><b>29.5.2</b> 兩個預測變量之間的關係</a></li>
<li class="chapter" data-level="29.5.3" data-path="多元模型分析-multivariable-models.html"><a href="多元模型分析-multivariable-models.html#rct臨床實驗是個特例"><i class="fa fa-check"></i><b>29.5.3</b> RCT臨床實驗是個特例</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html"><i class="fa fa-check"></i><b>30</b> 多元模型分析：矩陣標記與其意義</a><ul>
<li class="chapter" data-level="30.1" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#線性回歸模型的矩陣非矩陣標記法"><i class="fa fa-check"></i><b>30.1</b> 線性回歸模型的矩陣/非矩陣標記法</a><ul>
<li class="chapter" data-level="30.1.1" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#模型標記"><i class="fa fa-check"></i><b>30.1.1</b> 模型標記：</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#解讀參數"><i class="fa fa-check"></i><b>30.2</b> 解讀參數</a><ul>
<li class="chapter" data-level="30.2.1" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#最小二乘估計"><i class="fa fa-check"></i><b>30.2.1</b> 最小二乘估計</a></li>
<li class="chapter" data-level="30.2.2" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#因變量的期待值-mathbfhat-y"><i class="fa fa-check"></i><b>30.2.2</b> 因變量的期待值 <span class="math inline">\(\mathbf{\hat Y}\)</span></a></li>
<li class="chapter" data-level="30.2.3" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#殘差"><i class="fa fa-check"></i><b>30.2.3</b> 殘差</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#方差分析一般化和-f-檢驗"><i class="fa fa-check"></i><b>30.3</b> 方差分析一般化和 <span class="math inline">\(F\)</span> 檢驗</a><ul>
<li class="chapter" data-level="30.3.1" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#多元線性迴歸時的決定係數和殘差方差"><i class="fa fa-check"></i><b>30.3.1</b> 多元線性迴歸時的決定係數和殘差方差</a></li>
<li class="chapter" data-level="30.3.2" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#方差分析表格"><i class="fa fa-check"></i><b>30.3.2</b> 方差分析表格</a></li>
<li class="chapter" data-level="30.3.3" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#globalsig"><i class="fa fa-check"></i><b>30.3.3</b> 迴歸方程的顯著性檢驗</a></li>
<li class="chapter" data-level="30.3.4" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#partialF"><i class="fa fa-check"></i><b>30.3.4</b> <span class="math inline">\(\text{partial }F\)</span> 檢驗</a></li>
</ul></li>
<li class="chapter" data-level="30.4" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#添加新變量對迴歸模型的影響"><i class="fa fa-check"></i><b>30.4</b> 添加新變量對迴歸模型的影響</a><ul>
<li class="chapter" data-level="30.4.1" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#偏迴歸係數方差的改變"><i class="fa fa-check"></i><b>30.4.1</b> 偏迴歸係數方差的改變</a></li>
<li class="chapter" data-level="30.4.2" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#偏迴歸係數檢驗結果的改變"><i class="fa fa-check"></i><b>30.4.2</b> 偏迴歸係數檢驗結果的改變</a></li>
<li class="chapter" data-level="30.4.3" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#擬合值的改變"><i class="fa fa-check"></i><b>30.4.3</b> 擬合值的改變</a></li>
<li class="chapter" data-level="30.4.4" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#決定係數的改變"><i class="fa fa-check"></i><b>30.4.4</b> 決定係數的改變</a></li>
<li class="chapter" data-level="30.4.5" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#共線性-collinearity"><i class="fa fa-check"></i><b>30.4.5</b> 共線性 collinearity</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#實戰演習"><i class="fa fa-check"></i><b>30.5</b> 實戰演習</a><ul>
<li class="chapter" data-level="30.5.1" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#血清維生素-c-濃度的預測變量"><i class="fa fa-check"></i><b>30.5.1</b> 血清維生素 C 濃度的預測變量</a></li>
<li class="chapter" data-level="30.5.2" data-path="多元模型分析矩陣標記與其意義.html"><a href="多元模型分析矩陣標記與其意義.html#紅細胞容積與血紅蛋白"><i class="fa fa-check"></i><b>30.5.2</b> 紅細胞容積與血紅蛋白</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html"><i class="fa fa-check"></i><b>31</b> 線性迴歸的模型診斷</a><ul>
<li class="chapter" data-level="31.1" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#線性迴歸模型的前提條件"><i class="fa fa-check"></i><b>31.1</b> 線性迴歸模型的前提條件</a></li>
<li class="chapter" data-level="31.2" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#用圖形來視覺診斷"><i class="fa fa-check"></i><b>31.2</b> 用圖形來視覺診斷</a></li>
<li class="chapter" data-level="31.3" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#殘差圖"><i class="fa fa-check"></i><b>31.3</b> 殘差圖</a></li>
<li class="chapter" data-level="31.4" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#殘差正態圖-normal-plot-of-residuals"><i class="fa fa-check"></i><b>31.4</b> 殘差正態圖 normal plot of residuals</a><ul>
<li class="chapter" data-level="31.4.1" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#模型診斷實例"><i class="fa fa-check"></i><b>31.4.1</b> 模型診斷實例</a></li>
</ul></li>
<li class="chapter" data-level="31.5" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#前提條件的統計學檢驗"><i class="fa fa-check"></i><b>31.5</b> 前提條件的統計學檢驗</a><ul>
<li class="chapter" data-level="31.5.1" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#二次方程迴歸法檢驗非線性"><i class="fa fa-check"></i><b>31.5.1</b> 二次方程迴歸法檢驗非線性</a></li>
<li class="chapter" data-level="31.5.2" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#非線性關係模型"><i class="fa fa-check"></i><b>31.5.2</b> 非線性關係模型</a></li>
</ul></li>
<li class="chapter" data-level="31.6" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#異常值槓桿值和庫克距離"><i class="fa fa-check"></i><b>31.6</b> 異常值，槓桿值，和庫克距離</a><ul>
<li class="chapter" data-level="31.6.1" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#standardres"><i class="fa fa-check"></i><b>31.6.1</b> 異常值和標準化殘差</a></li>
<li class="chapter" data-level="31.6.2" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#槓桿值-leverage"><i class="fa fa-check"></i><b>31.6.2</b> 槓桿值 Leverage</a></li>
<li class="chapter" data-level="31.6.3" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#庫克距離-cooks-distance"><i class="fa fa-check"></i><b>31.6.3</b> 庫克距離 Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="31.7" data-path="線性迴歸的模型診斷.html"><a href="線性迴歸的模型診斷.html#在統計忍者包裏面對模型診斷作圖"><i class="fa fa-check"></i><b>31.7</b> 在統計忍者包裏面對模型診斷作圖</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>32</b> 交互作用 Interactions</a><ul>
<li class="chapter" data-level="32.1" data-path="interaction.html"><a href="interaction.html#兩個預測變量之間的線性模型交互作用"><i class="fa fa-check"></i><b>32.1</b> 兩個預測變量之間的線性模型交互作用</a><ul>
<li class="chapter" data-level="32.1.1" data-path="interaction.html"><a href="interaction.html#交互作用線性模型的一般表達式"><i class="fa fa-check"></i><b>32.1.1</b> 交互作用線性模型的一般表達式</a></li>
<li class="chapter" data-level="32.1.2" data-path="interaction.html"><a href="interaction.html#interaction-cont-bin"><i class="fa fa-check"></i><b>32.1.2</b> 連續型變量和二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.3" data-path="interaction.html"><a href="interaction.html#兩個二分類變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.3</b> 兩個二分類變量之間的交互作用</a></li>
<li class="chapter" data-level="32.1.4" data-path="interaction.html"><a href="interaction.html#兩個連續變量之間的交互作用"><i class="fa fa-check"></i><b>32.1.4</b> 兩個連續變量之間的交互作用</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V 臨床實驗 Clinical Trials</b></span></li>
<li class="chapter" data-level="33" data-path="sample-size.html"><a href="sample-size.html"><i class="fa fa-check"></i><b>33</b> 樣本量計算問題</a><ul>
<li class="chapter" data-level="33.1" data-path="sample-size.html"><a href="sample-size.html#背景-1"><i class="fa fa-check"></i><b>33.1</b> 背景</a></li>
<li class="chapter" data-level="33.2" data-path="sample-size.html"><a href="sample-size.html#決定所需樣本量大小的統計學因素"><i class="fa fa-check"></i><b>33.2</b> 決定所需樣本量大小的統計學因素</a></li>
<li class="chapter" data-level="33.3" data-path="sample-size.html"><a href="sample-size.html#第一類和第二類錯誤-type-i-and-type-ii-errors"><i class="fa fa-check"></i><b>33.3</b> 第一類和第二類錯誤 Type I and type II errors</a></li>
<li class="chapter" data-level="33.4" data-path="sample-size.html"><a href="sample-size.html#比較兩組之間的百分比-percentages-or-proportions"><i class="fa fa-check"></i><b>33.4</b> 比較兩組之間的百分比 (percentages or proportions)</a><ul>
<li class="chapter" data-level="33.4.1" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式-使用顯著水平-5-和檢驗效能-90"><i class="fa fa-check"></i><b>33.4.1</b> 樣本量計算公式 (使用顯著水平 5%, 和檢驗效能 90%)</a></li>
<li class="chapter" data-level="33.4.2" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式的一般化-不同的顯著水平和檢驗效能條件下"><i class="fa fa-check"></i><b>33.4.2</b> 樣本量計算公式的一般化 (不同的顯著水平和檢驗效能條件下)</a></li>
</ul></li>
<li class="chapter" data-level="33.5" data-path="sample-size.html"><a href="sample-size.html#比較兩組之間的均值"><i class="fa fa-check"></i><b>33.5</b> 比較兩組之間的均值</a><ul>
<li class="chapter" data-level="33.5.1" data-path="sample-size.html"><a href="sample-size.html#樣本量計算公式"><i class="fa fa-check"></i><b>33.5.1</b> 樣本量計算公式</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path="sample-size.html"><a href="sample-size.html#樣本量計算的調整"><i class="fa fa-check"></i><b>33.6</b> 樣本量計算的調整</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="baseline-adjustment-using-ancova.html"><a href="baseline-adjustment-using-ancova.html"><i class="fa fa-check"></i><b>34</b> Baseline Adjustment using ANCOVA</a></li>
<li class="part"><span><b>VI 穩健統計方法 Robust Statistic Methods</b></span></li>
<li class="chapter" data-level="35" data-path="穩健統計方法入門.html"><a href="穩健統計方法入門.html"><i class="fa fa-check"></i><b>35</b> 穩健統計方法入門</a></li>
<li class="chapter" data-level="36" data-path="基於秩次的非參數檢驗.html"><a href="基於秩次的非參數檢驗.html"><i class="fa fa-check"></i><b>36</b> 基於秩次的非參數檢驗</a><ul>
<li class="chapter" data-level="36.1" data-path="基於秩次的非參數檢驗.html"><a href="基於秩次的非參數檢驗.html#sign-test"><i class="fa fa-check"></i><b>36.1</b> 符號檢驗 the Sign test</a><ul>
<li class="chapter" data-level="36.1.1" data-path="基於秩次的非參數檢驗.html"><a href="基於秩次的非參數檢驗.html#符號檢驗的特點"><i class="fa fa-check"></i><b>36.1.1</b> 符號檢驗的特點</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="基於秩次的非參數檢驗.html"><a href="基於秩次的非參數檢驗.html#Wilcoxon-signed-rank-test"><i class="fa fa-check"></i><b>36.2</b> Wilcoxon 符號秩和檢驗，the Wilcoxon signed-rank test</a></li>
<li class="chapter" data-level="36.3" data-path="基於秩次的非參數檢驗.html"><a href="基於秩次的非參數檢驗.html#wilcoxon-mann-whitney-wmw-檢驗"><i class="fa fa-check"></i><b>36.3</b> Wilcoxon-Mann-Whitney (WMW) 檢驗</a></li>
<li class="chapter" data-level="36.4" data-path="基於秩次的非參數檢驗.html"><a href="基於秩次的非參數檢驗.html#秩相關spearmans-rank-correlation-coefficient"><i class="fa fa-check"></i><b>36.4</b> 秩相關，Spearman’s Rank Correlation Coefficient</a></li>
<li class="chapter" data-level="36.5" data-path="基於秩次的非參數檢驗.html"><a href="基於秩次的非參數檢驗.html#基於秩次的非參數檢驗的優缺點"><i class="fa fa-check"></i><b>36.5</b> 基於秩次的非參數檢驗的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html"><i class="fa fa-check"></i><b>37</b> 排列置換法 Permutation procedures</a><ul>
<li class="chapter" data-level="37.1" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html#背景介紹-1"><i class="fa fa-check"></i><b>37.1</b> 背景介紹</a></li>
<li class="chapter" data-level="37.2" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html#直接上實例"><i class="fa fa-check"></i><b>37.2</b> 直接上實例</a></li>
<li class="chapter" data-level="37.3" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html#排列置換法三板斧"><i class="fa fa-check"></i><b>37.3</b> 排列置換法三板斧</a><ul>
<li class="chapter" data-level="37.3.1" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html#該如何選用合適的檢驗統計量-t"><i class="fa fa-check"></i><b>37.3.1</b> 該如何選用合適的檢驗統計量 <span class="math inline">\(T\)</span>？</a></li>
<li class="chapter" data-level="37.3.2" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html#可以在排列置換法中對其他變量進行統計學調整-adjustment-嗎"><i class="fa fa-check"></i><b>37.3.2</b> 可以在排列置換法中對其他變量進行統計學調整 (adjustment) 嗎？</a></li>
<li class="chapter" data-level="37.3.3" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html#排列置換法基於秩次的非參數檢驗之間的關係"><i class="fa fa-check"></i><b>37.3.3</b> 排列置換法，基於秩次的非參數檢驗之間的關係</a></li>
<li class="chapter" data-level="37.3.4" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html#排列置換檢驗法是一種精確檢驗"><i class="fa fa-check"></i><b>37.3.4</b> 排列置換檢驗法，是一種精確檢驗</a></li>
</ul></li>
<li class="chapter" data-level="37.4" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html#基於排序置換檢驗法計算信賴區間"><i class="fa fa-check"></i><b>37.4</b> 基於排序置換檢驗法計算信賴區間</a></li>
<li class="chapter" data-level="37.5" data-path="排列置換法-permutation-procedures.html"><a href="排列置換法-permutation-procedures.html#排序置換法的優缺點"><i class="fa fa-check"></i><b>37.5</b> 排序置換法的優缺點</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="自助重抽法-the-bootstrap.html"><a href="自助重抽法-the-bootstrap.html"><i class="fa fa-check"></i><b>38</b> 自助重抽法 The bootstrap</a><ul>
<li class="chapter" data-level="38.1" data-path="自助重抽法-the-bootstrap.html"><a href="自助重抽法-the-bootstrap.html#定義-1"><i class="fa fa-check"></i><b>38.1</b> 定義</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="the-sandwich-estimator.html"><a href="the-sandwich-estimator.html"><i class="fa fa-check"></i><b>39</b> The sandwich estimator</a></li>
<li class="part"><span><b>VII 貝葉斯統計</b></span></li>
<li class="chapter" data-level="40" data-path="intro-Bayes.html"><a href="intro-Bayes.html"><i class="fa fa-check"></i><b>40</b> 貝葉斯統計入門</a><ul>
<li class="chapter" data-level="40.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#概率論推斷的複習"><i class="fa fa-check"></i><b>40.1</b> 概率論推斷的複習</a></li>
<li class="chapter" data-level="40.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#貝葉斯概率推理逆概率-bayesian-reasoninginverse-probability"><i class="fa fa-check"></i><b>40.2</b> 貝葉斯概率推理/逆概率 Bayesian reasoning/inverse probability</a><ul>
<li class="chapter" data-level="40.2.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#演繹推理-deductive-reasoning-和-三段論-weak-syllogisms"><i class="fa fa-check"></i><b>40.2.1</b> 演繹推理 deductive reasoning 和 三段論 weak syllogisms</a></li>
<li class="chapter" data-level="40.2.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#如何給可能性定量-quantifying-plausibility"><i class="fa fa-check"></i><b>40.2.2</b> 如何給可能性定量 Quantifying plausibility</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="intro-Bayes.html"><a href="intro-Bayes.html#貝葉斯推理的統計學實現"><i class="fa fa-check"></i><b>40.3</b> 貝葉斯推理的統計學實現</a><ul>
<li class="chapter" data-level="40.3.1" data-path="intro-Bayes.html"><a href="intro-Bayes.html#醫學診斷測試-diagnostic-testing"><i class="fa fa-check"></i><b>40.3.1</b> 醫學診斷測試 diagnostic testing</a></li>
<li class="chapter" data-level="40.3.2" data-path="intro-Bayes.html"><a href="intro-Bayes.html#hiv-檢查時的應用"><i class="fa fa-check"></i><b>40.3.2</b> HIV 檢查時的應用</a></li>
<li class="chapter" data-level="40.3.3" data-path="intro-Bayes.html"><a href="intro-Bayes.html#說點小歷史"><i class="fa fa-check"></i><b>40.3.3</b> 說點小歷史</a></li>
</ul></li>
<li class="chapter" data-level="40.4" data-path="intro-Bayes.html"><a href="intro-Bayes.html#練習題-5"><i class="fa fa-check"></i><b>40.4</b> 練習題</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html"><i class="fa fa-check"></i><b>41</b> 貝葉斯定理的應用：單一參數模型</a><ul>
<li class="chapter" data-level="41.1" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#貝葉斯理論下的事後二項分佈概率密度方程-notation-for-probability-density-functions"><i class="fa fa-check"></i><b>41.1</b> 貝葉斯理論下的事後二項分佈概率密度方程 notation for probability density functions</a></li>
<li class="chapter" data-level="41.2" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#theta-的先驗概率"><i class="fa fa-check"></i><b>41.2</b> <span class="math inline">\(\theta\)</span> 的先驗概率</a><ul>
<li class="chapter" data-level="41.2.1" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#beta-distribution-intro"><i class="fa fa-check"></i><b>41.2.1</b> beta 分佈 the beta distribution</a></li>
<li class="chapter" data-level="41.2.2" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#conjugate"><i class="fa fa-check"></i><b>41.2.2</b> 二項分佈數據事後概率分佈的一般化：共軛性</a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#附贈加量不加價"><i class="fa fa-check"></i><b>41.3</b> 附贈–加量不加價</a></li>
<li class="chapter" data-level="41.4" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#練習題-6"><i class="fa fa-check"></i><b>41.4</b> 練習題</a><ul>
<li class="chapter" data-level="41.4.1" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#q1-4"><i class="fa fa-check"></i><b>41.4.1</b> Q1</a></li>
<li class="chapter" data-level="41.4.2" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#q2-3"><i class="fa fa-check"></i><b>41.4.2</b> Q2</a></li>
<li class="chapter" data-level="41.4.3" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#q3-2"><i class="fa fa-check"></i><b>41.4.3</b> Q3</a></li>
<li class="chapter" data-level="41.4.4" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#q4"><i class="fa fa-check"></i><b>41.4.4</b> Q4</a></li>
<li class="chapter" data-level="41.4.5" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#q5"><i class="fa fa-check"></i><b>41.4.5</b> Q5</a></li>
<li class="chapter" data-level="41.4.6" data-path="貝葉斯定理的應用單一參數模型.html"><a href="貝葉斯定理的應用單一參數模型.html#q6"><i class="fa fa-check"></i><b>41.4.6</b> Q6</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html"><a href="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html"><i class="fa fa-check"></i><b>42</b> 貝葉斯理論在正態分布數據中的應用 Normal distribution applying Bayes’ Theorem</a><ul>
<li class="chapter" data-level="42.1" data-path="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html"><a href="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html#事後概率的總結方法"><i class="fa fa-check"></i><b>42.1</b> 事後概率的總結方法</a></li>
<li class="chapter" data-level="42.2" data-path="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html"><a href="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html#貝葉斯統計推斷中的正態分布"><i class="fa fa-check"></i><b>42.2</b> 貝葉斯統計推斷中的正態分布</a><ul>
<li class="chapter" data-level="42.2.1" data-path="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html"><a href="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html#n-independent-identically-distributed-observations"><i class="fa fa-check"></i><b>42.2.1</b> <span class="math inline">\(n\)</span> independent identically distributed observations</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html"><a href="貝葉斯理論在正態分布數據中的應用-normal-distribution-applying-bayes-theorem.html#貝葉斯預測分布"><i class="fa fa-check"></i><b>42.3</b> 貝葉斯預測分布</a></li>
</ul></li>
<li class="part"><span><b>VIII 廣義線性迴歸模型 Generalised Linear Regression</b></span></li>
<li class="chapter" data-level="43" data-path="重要概念複習.html"><a href="重要概念複習.html"><i class="fa fa-check"></i><b>43</b> 重要概念複習</a><ul>
<li class="chapter" data-level="43.1" data-path="重要概念複習.html"><a href="重要概念複習.html#概率論學派統計推斷要點複習"><i class="fa fa-check"></i><b>43.1</b> 概率論學派統計推斷要點複習</a></li>
<li class="chapter" data-level="43.2" data-path="重要概念複習.html"><a href="重要概念複習.html#似然"><i class="fa fa-check"></i><b>43.2</b> 似然</a></li>
<li class="chapter" data-level="43.3" data-path="重要概念複習.html"><a href="重要概念複習.html#極大似然估計"><i class="fa fa-check"></i><b>43.3</b> 極大似然估計</a></li>
<li class="chapter" data-level="43.4" data-path="重要概念複習.html"><a href="重要概念複習.html#關於假設檢驗的複習"><i class="fa fa-check"></i><b>43.4</b> 關於假設檢驗的複習</a><ul>
<li class="chapter" data-level="43.4.1" data-path="重要概念複習.html"><a href="重要概念複習.html#子集似然函數"><i class="fa fa-check"></i><b>43.4.1</b> 子集似然函數</a></li>
</ul></li>
<li class="chapter" data-level="43.5" data-path="重要概念複習.html"><a href="重要概念複習.html#線性迴歸複習"><i class="fa fa-check"></i><b>43.5</b> 線性迴歸複習</a><ul>
<li class="chapter" data-level="43.5.1" data-path="重要概念複習.html"><a href="重要概念複習.html#簡單線性迴歸"><i class="fa fa-check"></i><b>43.5.1</b> 簡單線性迴歸</a></li>
<li class="chapter" data-level="43.5.2" data-path="重要概念複習.html"><a href="重要概念複習.html#多元線性迴歸"><i class="fa fa-check"></i><b>43.5.2</b> 多元線性迴歸</a></li>
<li class="chapter" data-level="43.5.3" data-path="重要概念複習.html"><a href="重要概念複習.html#score-equations"><i class="fa fa-check"></i><b>43.5.3</b> 簡單線性迴歸的統計推斷</a></li>
</ul></li>
<li class="chapter" data-level="43.6" data-path="重要概念複習.html"><a href="重要概念複習.html#glm-practical-01"><i class="fa fa-check"></i><b>43.6</b> GLM-Practical 01</a><ul>
<li class="chapter" data-level="43.6.1" data-path="重要概念複習.html"><a href="重要概念複習.html#建立似然方程"><i class="fa fa-check"></i><b>43.6.1</b> 建立似然方程</a></li>
<li class="chapter" data-level="43.6.2" data-path="重要概念複習.html"><a href="重要概念複習.html#建立對數似然方程"><i class="fa fa-check"></i><b>43.6.2</b> 建立對數似然方程</a></li>
<li class="chapter" data-level="43.6.3" data-path="重要概念複習.html"><a href="重要概念複習.html#線性回歸模型"><i class="fa fa-check"></i><b>43.6.3</b> 線性回歸模型</a></li>
<li class="chapter" data-level="43.6.4" data-path="重要概念複習.html"><a href="重要概念複習.html#似然比檢驗wald-檢驗score-檢驗"><i class="fa fa-check"></i><b>43.6.4</b> 似然比檢驗，Wald 檢驗，Score 檢驗</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="44" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html"><i class="fa fa-check"></i><b>44</b> 廣義線性迴歸入門</a><ul>
<li class="chapter" data-level="44.1" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#指數分佈家族"><i class="fa fa-check"></i><b>44.1</b> 指數分佈家族</a><ul>
<li class="chapter" data-level="44.1.1" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#泊松分佈和二項分佈的指數分佈家族屬性"><i class="fa fa-check"></i><b>44.1.1</b> 泊松分佈和二項分佈的指數分佈家族屬性</a></li>
<li class="chapter" data-level="44.1.2" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#exercise.-exponential-distribution"><i class="fa fa-check"></i><b>44.1.2</b> Exercise. Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#defineaGLM"><i class="fa fa-check"></i><b>44.2</b> 廣義線性迴歸模型之定義</a></li>
<li class="chapter" data-level="44.3" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#注意"><i class="fa fa-check"></i><b>44.3</b> 注意</a></li>
<li class="chapter" data-level="44.4" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#如何在-r-裏擬合-glm"><i class="fa fa-check"></i><b>44.4</b> 如何在 R 裏擬合 “GLM”</a><ul>
<li class="chapter" data-level="44.4.1" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#margins-命令"><i class="fa fa-check"></i><b>44.4.1</b> <code>margins</code> 命令</a></li>
<li class="chapter" data-level="44.4.2" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#ggplot2geom_smoothmethod-loess-命令"><i class="fa fa-check"></i><b>44.4.2</b> <code>ggplot2::geom_smooth(method = &quot;loess&quot;)</code> 命令</a></li>
</ul></li>
<li class="chapter" data-level="44.5" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#glm-practical-02"><i class="fa fa-check"></i><b>44.5</b> GLM-Practical 02</a><ul>
<li class="chapter" data-level="44.5.1" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#思考本章中指數分布家族的參數設置假如有一個觀測值-y-來自指數家族試求證"><i class="fa fa-check"></i><b>44.5.1</b> 思考本章中指數分布家族的參數設置。假如，有一個觀測值 <span class="math inline">\(y\)</span> 來自指數家族。試求證:</a></li>
<li class="chapter" data-level="44.5.2" data-path="廣義線性迴歸入門.html"><a href="廣義線性迴歸入門.html#r-練習"><i class="fa fa-check"></i><b>44.5.2</b> R 練習</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="45" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><i class="fa fa-check"></i><b>45</b> 二項分佈數據的廣義線性迴歸模型 logistic regression model</a><ul>
<li class="chapter" data-level="45.1" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#彙總後個人-grouped-individual-的二項分佈數據"><i class="fa fa-check"></i><b>45.1</b> 彙總後/個人 (grouped / individual) 的二項分佈數據</a></li>
<li class="chapter" data-level="45.2" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#二項分佈數據的廣義線性迴歸模型"><i class="fa fa-check"></i><b>45.2</b> 二項分佈數據的廣義線性迴歸模型</a></li>
<li class="chapter" data-level="45.3" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#logit-or-log"><i class="fa fa-check"></i><b>45.3</b> 注</a><ul>
<li class="chapter" data-level="45.3.1" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#exercise.-link-functions."><i class="fa fa-check"></i><b>45.3.1</b> Exercise. Link functions.</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#邏輯迴歸模型迴歸係數的實際意義"><i class="fa fa-check"></i><b>45.4</b> 邏輯迴歸模型迴歸係數的實際意義</a></li>
<li class="chapter" data-level="45.5" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#BSEinfection"><i class="fa fa-check"></i><b>45.5</b> 邏輯迴歸實際案例</a><ul>
<li class="chapter" data-level="45.5.1" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#分析目的"><i class="fa fa-check"></i><b>45.5.1</b> 分析目的</a></li>
<li class="chapter" data-level="45.5.2" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#模型-1-飼料-羣"><i class="fa fa-check"></i><b>45.5.2</b> 模型 1 飼料 + 羣</a></li>
<li class="chapter" data-level="45.5.3" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#模型-2-增加交互作用項-飼料-times-羣"><i class="fa fa-check"></i><b>45.5.3</b> 模型 2 增加交互作用項 飼料 <span class="math inline">\(\times\)</span> 羣</a></li>
</ul></li>
<li class="chapter" data-level="45.6" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#glm-practical-03"><i class="fa fa-check"></i><b>45.6</b> GLM-Practical 03</a><ul>
<li class="chapter" data-level="45.6.1" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#昆蟲的死亡率"><i class="fa fa-check"></i><b>45.6.1</b> 昆蟲的死亡率</a></li>
<li class="chapter" data-level="45.6.2" data-path="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html"><a href="二項分佈數據的廣義線性迴歸模型-logistic-regression-model.html#哮喘門診數據"><i class="fa fa-check"></i><b>45.6.2</b> 哮喘門診數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="46" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html"><i class="fa fa-check"></i><b>46</b> 模型比較和擬合優度</a><ul>
<li class="chapter" data-level="46.1" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#嵌套式模型的比較-nested-models"><i class="fa fa-check"></i><b>46.1</b> 嵌套式模型的比較 nested models</a></li>
<li class="chapter" data-level="46.2" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#嵌套式模型比較實例"><i class="fa fa-check"></i><b>46.2</b> 嵌套式模型比較實例</a></li>
<li class="chapter" data-level="46.3" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#飽和模型模型的偏差擬合優度"><i class="fa fa-check"></i><b>46.3</b> 飽和模型，模型的偏差，擬合優度</a><ul>
<li class="chapter" data-level="46.3.1" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#飽和模型-saturated-model"><i class="fa fa-check"></i><b>46.3.1</b> 飽和模型 saturated model</a></li>
<li class="chapter" data-level="46.3.2" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#deviance"><i class="fa fa-check"></i><b>46.3.2</b> 模型偏差 deviance</a></li>
<li class="chapter" data-level="46.3.3" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#彙總型二項分佈數據-aggregatedgrouped-binary-data"><i class="fa fa-check"></i><b>46.3.3</b> 彙總型二項分佈數據 aggregated/grouped binary data</a></li>
</ul></li>
<li class="chapter" data-level="46.4" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#gof"><i class="fa fa-check"></i><b>46.4</b> 個人數據擬合模型的優度檢驗</a></li>
<li class="chapter" data-level="46.5" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#glm-practical-04"><i class="fa fa-check"></i><b>46.5</b> GLM Practical 04</a><ul>
<li class="chapter" data-level="46.5.1" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#回到之前的昆蟲數據嘗試評價該模型的擬合優度"><i class="fa fa-check"></i><b>46.5.1</b> 回到之前的昆蟲數據，嘗試評價該模型的擬合優度。</a></li>
<li class="chapter" data-level="46.5.2" data-path="模型比較和擬合優度.html"><a href="模型比較和擬合優度.html#低出生體重數據"><i class="fa fa-check"></i><b>46.5.2</b> 低出生體重數據</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="47" data-path="計數型因變量-poisson-regression.html"><a href="計數型因變量-poisson-regression.html"><i class="fa fa-check"></i><b>47</b> 計數型因變量 Poisson regression</a><ul>
<li class="chapter" data-level="47.1" data-path="計數型因變量-poisson-regression.html"><a href="計數型因變量-poisson-regression.html#泊松-glm"><i class="fa fa-check"></i><b>47.1</b> 泊松 GLM</a></li>
<li class="chapter" data-level="47.2" data-path="計數型因變量-poisson-regression.html"><a href="計數型因變量-poisson-regression.html#泊松迴歸實例"><i class="fa fa-check"></i><b>47.2</b> 泊松迴歸實例</a></li>
<li class="chapter" data-level="47.3" data-path="計數型因變量-poisson-regression.html"><a href="計數型因變量-poisson-regression.html#過度離散-overdispersion"><i class="fa fa-check"></i><b>47.3</b> 過度離散 overdispersion</a><ul>
<li class="chapter" data-level="47.3.1" data-path="計數型因變量-poisson-regression.html"><a href="計數型因變量-poisson-regression.html#過度離散怎麼查"><i class="fa fa-check"></i><b>47.3.1</b> 過度離散怎麼查？</a></li>
<li class="chapter" data-level="47.3.2" data-path="計數型因變量-poisson-regression.html"><a href="計數型因變量-poisson-regression.html#負二項式分佈模型-negative-binomial-model"><i class="fa fa-check"></i><b>47.3.2</b> 負二項式分佈模型 negative binomial model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="48" data-path="率的廣義線性迴歸-poisson-glm-for-rates.html"><a href="率的廣義線性迴歸-poisson-glm-for-rates.html"><i class="fa fa-check"></i><b>48</b> 率的廣義線性迴歸 Poisson GLM for rates</a><ul>
<li class="chapter" data-level="48.1" data-path="率的廣義線性迴歸-poisson-glm-for-rates.html"><a href="率的廣義線性迴歸-poisson-glm-for-rates.html#醫學中的率"><i class="fa fa-check"></i><b>48.1</b> 醫學中的率</a></li>
<li class="chapter" data-level="48.2" data-path="率的廣義線性迴歸-poisson-glm-for-rates.html"><a href="率的廣義線性迴歸-poisson-glm-for-rates.html#泊松過程"><i class="fa fa-check"></i><b>48.2</b> 泊松過程</a></li>
<li class="chapter" data-level="48.3" data-path="率的廣義線性迴歸-poisson-glm-for-rates.html"><a href="率的廣義線性迴歸-poisson-glm-for-rates.html#率的模型"><i class="fa fa-check"></i><b>48.3</b> 率的模型</a></li>
<li class="chapter" data-level="48.4" data-path="率的廣義線性迴歸-poisson-glm-for-rates.html"><a href="率的廣義線性迴歸-poisson-glm-for-rates.html#率的-glm"><i class="fa fa-check"></i><b>48.4</b> 率的 GLM</a></li>
<li class="chapter" data-level="48.5" data-path="率的廣義線性迴歸-poisson-glm-for-rates.html"><a href="率的廣義線性迴歸-poisson-glm-for-rates.html#實戰演練"><i class="fa fa-check"></i><b>48.5</b> 實戰演練</a><ul>
<li class="chapter" data-level="48.5.1" data-path="率的廣義線性迴歸-poisson-glm-for-rates.html"><a href="率的廣義線性迴歸-poisson-glm-for-rates.html#模型-1"><i class="fa fa-check"></i><b>48.5.1</b> 模型 1</a></li>
<li class="chapter" data-level="48.5.2" data-path="率的廣義線性迴歸-poisson-glm-for-rates.html"><a href="率的廣義線性迴歸-poisson-glm-for-rates.html#模型-2"><i class="fa fa-check"></i><b>48.5.2</b> 模型 2</a></li>
<li class="chapter" data-level="48.5.3" data-path="率的廣義線性迴歸-poisson-glm-for-rates.html"><a href="率的廣義線性迴歸-poisson-glm-for-rates.html#模型-3"><i class="fa fa-check"></i><b>48.5.3</b> 模型 3</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="49" data-path="混雜的調整交互作用和模型的可壓縮性.html"><a href="混雜的調整交互作用和模型的可壓縮性.html"><i class="fa fa-check"></i><b>49</b> 混雜的調整，交互作用，和模型的可壓縮性</a><ul>
<li class="chapter" data-level="49.1" data-path="混雜的調整交互作用和模型的可壓縮性.html"><a href="混雜的調整交互作用和模型的可壓縮性.html#混雜因素的調整"><i class="fa fa-check"></i><b>49.1</b> 混雜因素的調整</a><ul>
<li class="chapter" data-level="49.1.1" data-path="混雜的調整交互作用和模型的可壓縮性.html"><a href="混雜的調整交互作用和模型的可壓縮性.html#woolf-法估算合併比值比"><i class="fa fa-check"></i><b>49.1.1</b> Woolf 法估算合併比值比</a></li>
</ul></li>
<li class="chapter" data-level="49.2" data-path="混雜的調整交互作用和模型的可壓縮性.html"><a href="混雜的調整交互作用和模型的可壓縮性.html#交互作用"><i class="fa fa-check"></i><b>49.2</b> 交互作用</a></li>
<li class="chapter" data-level="49.3" data-path="混雜的調整交互作用和模型的可壓縮性.html"><a href="混雜的調整交互作用和模型的可壓縮性.html#可壓縮性-collapsibility"><i class="fa fa-check"></i><b>49.3</b> 可壓縮性 collapsibility</a><ul>
<li class="chapter" data-level="49.3.1" data-path="混雜的調整交互作用和模型的可壓縮性.html"><a href="混雜的調整交互作用和模型的可壓縮性.html#線性迴歸的可壓縮性"><i class="fa fa-check"></i><b>49.3.1</b> 線性迴歸的可壓縮性</a></li>
<li class="chapter" data-level="49.3.2" data-path="混雜的調整交互作用和模型的可壓縮性.html"><a href="混雜的調整交互作用和模型的可壓縮性.html#collapsibility"><i class="fa fa-check"></i><b>49.3.2</b> 邏輯鏈接方程時的不可壓縮性</a></li>
</ul></li>
<li class="chapter" data-level="49.4" data-path="混雜的調整交互作用和模型的可壓縮性.html"><a href="混雜的調整交互作用和模型的可壓縮性.html#interaction-depend-scale"><i class="fa fa-check"></i><b>49.4</b> 交互作用對尺度的依賴性</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html"><i class="fa fa-check"></i><b>50</b> 流行病學中的邏輯迴歸</a><ul>
<li class="chapter" data-level="50.1" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#流行病學研究最常用的實驗設計"><i class="fa fa-check"></i><b>50.1</b> 流行病學研究最常用的實驗設計</a></li>
<li class="chapter" data-level="50.2" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#GLM8-3"><i class="fa fa-check"></i><b>50.2</b> 以簡單二分類暴露變量爲例</a><ul>
<li class="chapter" data-level="50.2.1" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#先決條件"><i class="fa fa-check"></i><b>50.2.1</b> 先決條件</a></li>
<li class="chapter" data-level="50.2.2" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#比值比-odds-ratios"><i class="fa fa-check"></i><b>50.2.2</b> 比值比 Odds ratios</a></li>
<li class="chapter" data-level="50.2.3" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#GLM8-3-4"><i class="fa fa-check"></i><b>50.2.3</b> 邏輯迴歸應用於病例對照研究的合理性</a></li>
</ul></li>
<li class="chapter" data-level="50.3" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#拓展到多個暴露變量的邏輯迴歸模型"><i class="fa fa-check"></i><b>50.3</b> 拓展到多個暴露變量的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="50.3.1" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#mantel-haenszel-法"><i class="fa fa-check"></i><b>50.3.1</b> Mantel Haenszel 法</a></li>
<li class="chapter" data-level="50.3.2" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#隊列研究和病例對照研究的似然"><i class="fa fa-check"></i><b>50.3.2</b> 隊列研究和病例對照研究的似然</a></li>
<li class="chapter" data-level="50.3.3" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#病例對照研究中的邏輯迴歸"><i class="fa fa-check"></i><b>50.3.3</b> 病例對照研究中的邏輯迴歸</a></li>
</ul></li>
<li class="chapter" data-level="50.4" data-path="流行病學中的邏輯迴歸.html"><a href="流行病學中的邏輯迴歸.html#流行病學研究中變量的調整策略"><i class="fa fa-check"></i><b>50.4</b> 流行病學研究中變量的調整策略</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="分析策略.html"><a href="分析策略.html"><i class="fa fa-check"></i><b>51</b> 分析策略</a><ul>
<li class="chapter" data-level="51.1" data-path="分析策略.html"><a href="分析策略.html#明確分析目的"><i class="fa fa-check"></i><b>51.1</b> 明確分析目的</a></li>
<li class="chapter" data-level="51.2" data-path="分析策略.html"><a href="分析策略.html#分析目的-1.1-估計-rct-中治療效果-treatment-effect"><i class="fa fa-check"></i><b>51.2</b> 分析目的 1.1 – 估計 RCT 中治療效果 (treatment effect)</a><ul>
<li class="chapter" data-level="51.2.1" data-path="分析策略.html"><a href="分析策略.html#rct-數據分析的一些不成熟的小建議"><i class="fa fa-check"></i><b>51.2.1</b> RCT 數據分析的一些不成熟的小建議</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path="分析策略.html"><a href="分析策略.html#分析目的-1.2-估計流行病學研究中暴露變量和結果變量的關係-exposure-effect"><i class="fa fa-check"></i><b>51.3</b> 分析目的 1.2 – 估計流行病學研究中暴露變量和結果變量的關係 (exposure effect)</a><ul>
<li class="chapter" data-level="51.3.1" data-path="分析策略.html"><a href="分析策略.html#不成熟的小策略"><i class="fa fa-check"></i><b>51.3.1</b> 不成熟的小策略</a></li>
<li class="chapter" data-level="51.3.2" data-path="分析策略.html"><a href="分析策略.html#補充"><i class="fa fa-check"></i><b>51.3.2</b> 補充</a></li>
</ul></li>
<li class="chapter" data-level="51.4" data-path="分析策略.html"><a href="分析策略.html#分析目的-2-和-3-建立預測模型-predictive-models"><i class="fa fa-check"></i><b>51.4</b> 分析目的 2 和 3 – 建立預測模型 (predictive models)</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="檢查你的模型-model-checking-glm.html"><a href="檢查你的模型-model-checking-glm.html"><i class="fa fa-check"></i><b>52</b> 檢查你的模型 Model Checking - GLM</a><ul>
<li class="chapter" data-level="52.1" data-path="檢查你的模型-model-checking-glm.html"><a href="檢查你的模型-model-checking-glm.html#線性預測方程的定義"><i class="fa fa-check"></i><b>52.1</b> 線性預測方程的定義</a><ul>
<li class="chapter" data-level="52.1.1" data-path="檢查你的模型-model-checking-glm.html"><a href="檢查你的模型-model-checking-glm.html#殘差-1"><i class="fa fa-check"></i><b>52.1.1</b> 殘差</a></li>
<li class="chapter" data-level="52.1.2" data-path="檢查你的模型-model-checking-glm.html"><a href="檢查你的模型-model-checking-glm.html#glm-在-r-裏獲取殘差"><i class="fa fa-check"></i><b>52.1.2</b> GLM 在 R 裏獲取殘差</a></li>
<li class="chapter" data-level="52.1.3" data-path="檢查你的模型-model-checking-glm.html"><a href="檢查你的模型-model-checking-glm.html#如何利用獲得的殘差"><i class="fa fa-check"></i><b>52.1.3</b> 如何利用獲得的殘差</a></li>
</ul></li>
<li class="chapter" data-level="52.2" data-path="檢查你的模型-model-checking-glm.html"><a href="檢查你的模型-model-checking-glm.html#共變量模式殘差-covariate-pattern-residuals"><i class="fa fa-check"></i><b>52.2</b> 共變量模式殘差 covariate pattern residuals</a></li>
<li class="chapter" data-level="52.3" data-path="檢查你的模型-model-checking-glm.html"><a href="檢查你的模型-model-checking-glm.html#鏈接方程"><i class="fa fa-check"></i><b>52.3</b> 鏈接方程</a></li>
<li class="chapter" data-level="52.4" data-path="檢查你的模型-model-checking-glm.html"><a href="檢查你的模型-model-checking-glm.html#NHANESdrinker"><i class="fa fa-check"></i><b>52.4</b> NHANES 飲酒量數據實例</a></li>
<li class="chapter" data-level="52.5" data-path="檢查你的模型-model-checking-glm.html"><a href="檢查你的模型-model-checking-glm.html#practical-10"><i class="fa fa-check"></i><b>52.5</b> Practical 10</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="評價模型的表現-assessing-model-performance.html"><a href="評價模型的表現-assessing-model-performance.html"><i class="fa fa-check"></i><b>53</b> 評價模型的表現 Assessing model performance</a><ul>
<li class="chapter" data-level="53.1" data-path="評價模型的表現-assessing-model-performance.html"><a href="評價模型的表現-assessing-model-performance.html#calibration"><i class="fa fa-check"></i><b>53.1</b> 精準度 calibration</a></li>
<li class="chapter" data-level="53.2" data-path="評價模型的表現-assessing-model-performance.html"><a href="評價模型的表現-assessing-model-performance.html#可解釋因變量的變異度及-r2-決定係數"><i class="fa fa-check"></i><b>53.2</b> 可解釋因變量的變異度及 <span class="math inline">\(R^2\)</span> 決定係數</a></li>
<li class="chapter" data-level="53.3" data-path="評價模型的表現-assessing-model-performance.html"><a href="評價模型的表現-assessing-model-performance.html#分辨能力-descrimination"><i class="fa fa-check"></i><b>53.3</b> 分辨能力 descrimination</a><ul>
<li class="chapter" data-level="53.3.1" data-path="評價模型的表現-assessing-model-performance.html"><a href="評價模型的表現-assessing-model-performance.html#敏感度和特異度"><i class="fa fa-check"></i><b>53.3.1</b> 敏感度和特異度</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html"><i class="fa fa-check"></i><b>54</b> 配對實驗數據的分析法</a><ul>
<li class="chapter" data-level="54.1" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#配對的原理"><i class="fa fa-check"></i><b>54.1</b> 配對的原理</a><ul>
<li class="chapter" data-level="54.1.1" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#爲了提升估計的精確度"><i class="fa fa-check"></i><b>54.1.1</b> 爲了提升估計的精確度</a></li>
<li class="chapter" data-level="54.1.2" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#控制混雜因素"><i class="fa fa-check"></i><b>54.1.2</b> 控制混雜因素</a></li>
</ul></li>
<li class="chapter" data-level="54.2" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#結果變量爲連續型變量的配對實驗"><i class="fa fa-check"></i><b>54.2</b> 結果變量爲連續型變量的配對實驗</a><ul>
<li class="chapter" data-level="54.2.1" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#一般檢驗方法"><i class="fa fa-check"></i><b>54.2.1</b> 一般檢驗方法</a></li>
<li class="chapter" data-level="54.2.2" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#用迴歸法分析"><i class="fa fa-check"></i><b>54.2.2</b> 用迴歸法分析</a></li>
</ul></li>
<li class="chapter" data-level="54.3" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#結果變量是二分類變量的配對實驗"><i class="fa fa-check"></i><b>54.3</b> 結果變量是二分類變量的配對實驗</a><ul>
<li class="chapter" data-level="54.3.1" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#第一步-對數據作表格"><i class="fa fa-check"></i><b>54.3.1</b> 第一步 對數據作表格</a></li>
<li class="chapter" data-level="54.3.2" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#mcnemars-test"><i class="fa fa-check"></i><b>54.3.2</b> McNemar’s test</a></li>
<li class="chapter" data-level="54.3.3" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#二分類型結果變量配對實驗的比值比"><i class="fa fa-check"></i><b>54.3.3</b> 二分類型結果變量配對實驗的比值比</a></li>
<li class="chapter" data-level="54.3.4" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#配對實驗比值比的信賴區間"><i class="fa fa-check"></i><b>54.3.4</b> 配對實驗比值比的信賴區間</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="配對實驗數據的分析法.html"><a href="配對實驗數據的分析法.html#條件-conditional-比值比和邊際-marginal-比值比"><i class="fa fa-check"></i><b>54.4</b> 條件 (conditional) 比值比和邊際 (marginal) 比值比</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html"><i class="fa fa-check"></i><b>55</b> 條件邏輯迴歸 Conditional logistic regression</a><ul>
<li class="chapter" data-level="55.1" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html#配對實驗的邏輯迴歸模型"><i class="fa fa-check"></i><b>55.1</b> 配對實驗的邏輯迴歸模型</a><ul>
<li class="chapter" data-level="55.1.1" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html#配對病例對照研究"><i class="fa fa-check"></i><b>55.1.1</b> 配對病例對照研究</a></li>
<li class="chapter" data-level="55.1.2" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html#配對隊列研究"><i class="fa fa-check"></i><b>55.1.2</b> 配對隊列研究</a></li>
</ul></li>
<li class="chapter" data-level="55.2" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html#條件邏輯回歸-二分類暴露變量"><i class="fa fa-check"></i><b>55.2</b> 條件邏輯回歸 – 二分類暴露變量</a><ul>
<li class="chapter" data-level="55.2.1" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html#充分統計量-sufficient-statistics"><i class="fa fa-check"></i><b>55.2.1</b> 充分統計量 sufficient statistics</a></li>
<li class="chapter" data-level="55.2.2" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html#條件邏輯回歸的推導"><i class="fa fa-check"></i><b>55.2.2</b> 條件邏輯回歸的推導</a></li>
<li class="chapter" data-level="55.2.3" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html#條件似然-conditional-likelihood"><i class="fa fa-check"></i><b>55.2.3</b> 條件似然 conditional likelihood</a></li>
<li class="chapter" data-level="55.2.4" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html#進一步擴展"><i class="fa fa-check"></i><b>55.2.4</b> 進一步擴展</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="條件邏輯迴歸-conditional-logistic-regression.html"><a href="條件邏輯迴歸-conditional-logistic-regression.html#條件邏輯回歸模型的一般化"><i class="fa fa-check"></i><b>55.3</b> 條件邏輯回歸模型的一般化</a></li>
</ul></li>
<li class="chapter" data-level="56" data-path="multinomial-logistic-regression.html"><a href="multinomial-logistic-regression.html"><i class="fa fa-check"></i><b>56</b> Multinomial Logistic Regression</a></li>
<li class="chapter" data-level="57" data-path="ordinal-logistic-regression.html"><a href="ordinal-logistic-regression.html"><i class="fa fa-check"></i><b>57</b> Ordinal Logistic Regression</a></li>
<li class="part"><span><b>IX 等級線性迴歸模型 analysis of hierarchical and other dependent data</b></span></li>
<li class="chapter" data-level="58" data-path="Hierarchical.html"><a href="Hierarchical.html"><i class="fa fa-check"></i><b>58</b> 相互依賴數據及簡單的應對方案</a><ul>
<li class="chapter" data-level="58.1" data-path="Hierarchical.html"><a href="Hierarchical.html#相互依賴的數據"><i class="fa fa-check"></i><b>58.1</b> 相互依賴的數據</a></li>
<li class="chapter" data-level="58.2" data-path="Hierarchical.html"><a href="Hierarchical.html#依賴性的來源在哪裏"><i class="fa fa-check"></i><b>58.2</b> 依賴性的來源在哪裏</a></li>
<li class="chapter" data-level="58.3" data-path="Hierarchical.html"><a href="Hierarchical.html#數據有依賴性導致的結果"><i class="fa fa-check"></i><b>58.3</b> 數據有依賴性導致的結果</a></li>
<li class="chapter" data-level="58.4" data-path="Hierarchical.html"><a href="Hierarchical.html#邊際模型和條件模型-marginal-and-conditional-models"><i class="fa fa-check"></i><b>58.4</b> 邊際模型和條件模型 marginal and conditional models</a><ul>
<li class="chapter" data-level="58.4.1" data-path="Hierarchical.html"><a href="Hierarchical.html#標記法-notation"><i class="fa fa-check"></i><b>58.4.1</b> 標記法 notation</a></li>
<li class="chapter" data-level="58.4.2" data-path="Hierarchical.html"><a href="Hierarchical.html#合並每個階層"><i class="fa fa-check"></i><b>58.4.2</b> 合並每個階層</a></li>
<li class="chapter" data-level="58.4.3" data-path="Hierarchical.html"><a href="Hierarchical.html#生物學悖論-ecological-fallacy"><i class="fa fa-check"></i><b>58.4.3</b> 生物學悖論 ecological fallacy</a></li>
<li class="chapter" data-level="58.4.4" data-path="Hierarchical.html"><a href="Hierarchical.html#分解層級數據"><i class="fa fa-check"></i><b>58.4.4</b> 分解層級數據</a></li>
<li class="chapter" data-level="58.4.5" data-path="Hierarchical.html"><a href="Hierarchical.html#固定效應模型-fixed-effect-model"><i class="fa fa-check"></i><b>58.4.5</b> 固定效應模型 fixed effect model</a></li>
</ul></li>
<li class="chapter" data-level="58.5" data-path="Hierarchical.html"><a href="Hierarchical.html#簡單線性迴歸複習"><i class="fa fa-check"></i><b>58.5</b> 簡單線性迴歸複習</a></li>
<li class="chapter" data-level="58.6" data-path="Hierarchical.html"><a href="Hierarchical.html#練習題-7"><i class="fa fa-check"></i><b>58.6</b> 練習題</a><ul>
<li class="chapter" data-level="58.6.1" data-path="Hierarchical.html"><a href="Hierarchical.html#數據"><i class="fa fa-check"></i><b>58.6.1</b> 數據</a></li>
<li class="chapter" data-level="58.6.2" data-path="Hierarchical.html"><a href="Hierarchical.html#問題"><i class="fa fa-check"></i><b>58.6.2</b> 問題</a></li>
<li class="chapter" data-level="58.6.3" data-path="Hierarchical.html"><a href="Hierarchical.html#將-high-school-and-beyond-數據導入-r-中熟悉數據結構及內容特別要注意觀察每個學校的學生特徵"><i class="fa fa-check"></i><b>58.6.3</b> 將 High-School-and-Beyond 數據導入 R 中，熟悉數據結構及內容，特別要注意觀察每個學校的學生特徵。</a></li>
<li class="chapter" data-level="58.6.4" data-path="Hierarchical.html"><a href="Hierarchical.html#爲了簡便起見接下來的分析只節選數據中前五所學校-188-名學生的數學成績和-ses分別計算每所學校的數學成績及-ses-的平均值"><i class="fa fa-check"></i><b>58.6.4</b> 爲了簡便起見，接下來的分析只節選數據中前五所學校 188 名學生的數學成績，和 SES。分別計算每所學校的數學成績,及 SES 的平均值。</a></li>
<li class="chapter" data-level="58.6.5" data-path="Hierarchical.html"><a href="Hierarchical.html#先無視掉學校這一分層變量把所有學生看作是相互獨立的擬合總體的-ses-和數學成績的線性迴歸-total-regression-model把該總體模型的預測值提取並存儲在數據庫中"><i class="fa fa-check"></i><b>58.6.5</b> 先無視掉學校這一分層變量，把所有學生看作是相互獨立的，擬合總體的 SES 和數學成績的線性迴歸 <strong>(Total regression model)</strong>。把該總體模型的預測值提取並存儲在數據庫中。</a></li>
<li class="chapter" data-level="58.6.6" data-path="Hierarchical.html"><a href="Hierarchical.html#用各個學校-ses-和數學成績的均值擬合一個學校間的線性迴歸模型-between-regression-model"><i class="fa fa-check"></i><b>58.6.6</b> 用各個學校 SES 和數學成績的均值擬合一個學校間的線性迴歸模型 <strong>(between regression model)</strong>。</a></li>
<li class="chapter" data-level="58.6.7" data-path="Hierarchical.html"><a href="Hierarchical.html#分別對每個學校內的學生進行-ses-和數學成績擬合線性迴歸模型"><i class="fa fa-check"></i><b>58.6.7</b> 分別對每個學校內的學生進行 SES 和數學成績擬合線性迴歸模型。</a></li>
<li class="chapter" data-level="58.6.8" data-path="Hierarchical.html"><a href="Hierarchical.html#比較三種模型計算的數學成績的擬合值他們一致還是有所不同爲什麼會有不同"><i class="fa fa-check"></i><b>58.6.8</b> 比較三種模型計算的數學成績的擬合值，他們一致？還是有所不同？爲什麼會有不同？</a></li>
<li class="chapter" data-level="58.6.9" data-path="Hierarchical.html"><a href="Hierarchical.html#把三種模型的數學成績擬合值散點圖繪製在同一張圖內"><i class="fa fa-check"></i><b>58.6.9</b> 把三種模型的數學成績擬合值散點圖繪製在同一張圖內。</a></li>
<li class="chapter" data-level="58.6.10" data-path="Hierarchical.html"><a href="Hierarchical.html#用這-5-個學校的數據擬合一個固定效應線性迴歸模型"><i class="fa fa-check"></i><b>58.6.10</b> 用這 5 個學校的數據擬合一個固定效應線性迴歸模型</a></li>
<li class="chapter" data-level="58.6.11" data-path="Hierarchical.html"><a href="Hierarchical.html#讀入-pefr-數據"><i class="fa fa-check"></i><b>58.6.11</b> 讀入 PEFR 數據。</a></li>
<li class="chapter" data-level="58.6.12" data-path="Hierarchical.html"><a href="Hierarchical.html#求每個患者的-wp-兩次測量平均值"><i class="fa fa-check"></i><b>58.6.12</b> 求每個患者的 <code>wp</code> 兩次測量平均值</a></li>
<li class="chapter" data-level="58.6.13" data-path="Hierarchical.html"><a href="Hierarchical.html#在-r-裏先用-anova-分析個人的-wp-變異再用-lme4lmer-擬合用-id-作隨機效應的混合效應模型確認後者報告的-std.dev-for-id-effect-其實可以用-anova-結果的-sqrtfractextmms-msen-n-是每個個體重複測量值的個數"><i class="fa fa-check"></i><b>58.6.13</b> 在 R 裏先用 ANOVA 分析個人的 <code>wp</code> 變異。再用 <code>lme4::lmer</code> 擬合用 <code>id</code> 作隨機效應的混合效應模型。確認後者報告的 <code>Std.Dev for id effect</code> 其實可以用 ANOVA 結果的 <span class="math inline">\(\sqrt{\frac{\text{MMS-MSE}}{n}}\)</span> (n 是每個個體重複測量值的個數)。</a></li>
<li class="chapter" data-level="58.6.14" data-path="Hierarchical.html"><a href="Hierarchical.html#擬合結果變量爲-wp解釋變量爲-id-的簡單線性迴歸模型用數學表達式描述這個模型"><i class="fa fa-check"></i><b>58.6.14</b> 擬合結果變量爲 <code>wp</code>，解釋變量爲 <code>id</code> 的簡單線性迴歸模型。用數學表達式描述這個模型。</a></li>
<li class="chapter" data-level="58.6.15" data-path="Hierarchical.html"><a href="Hierarchical.html#將-wp-中心化之後重新擬合相同的模型把截距去除掉寫下這個模型的數學表達式"><i class="fa fa-check"></i><b>58.6.15</b> 將 <code>wp</code> 中心化之後，重新擬合相同的模型，把截距去除掉。寫下這個模型的數學表達式。</a></li>
<li class="chapter" data-level="58.6.16" data-path="Hierarchical.html"><a href="Hierarchical.html#計算這些迴歸係數-其實是不同羣之間的隨機截距-的均值和標準差"><i class="fa fa-check"></i><b>58.6.16</b> 計算這些迴歸係數 (其實是不同羣之間的隨機截距) 的均值和標準差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="59" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html"><i class="fa fa-check"></i><b>59</b> 隨機截距模型 random intercept model</a><ul>
<li class="chapter" data-level="59.1" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#隨機截距模型的定義"><i class="fa fa-check"></i><b>59.1</b> 隨機截距模型的定義</a></li>
<li class="chapter" data-level="59.2" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#隨機截距模型的參數估計"><i class="fa fa-check"></i><b>59.2</b> 隨機截距模型的參數估計</a></li>
<li class="chapter" data-level="59.3" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#如何在-r-中進行隨機截距模型的擬合"><i class="fa fa-check"></i><b>59.3</b> 如何在 R 中進行隨機截距模型的擬合</a></li>
<li class="chapter" data-level="59.4" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#隨機截距模型中的統計推斷"><i class="fa fa-check"></i><b>59.4</b> 隨機截距模型中的統計推斷</a><ul>
<li class="chapter" data-level="59.4.1" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#fixed-inference"><i class="fa fa-check"></i><b>59.4.1</b> 固定效應部分的推斷</a></li>
<li class="chapter" data-level="59.4.2" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#隨機效應部分的推斷"><i class="fa fa-check"></i><b>59.4.2</b> 隨機效應部分的推斷</a></li>
</ul></li>
<li class="chapter" data-level="59.5" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#練習題-8"><i class="fa fa-check"></i><b>59.5</b> 練習題</a><ul>
<li class="chapter" data-level="59.5.1" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#數據-1"><i class="fa fa-check"></i><b>59.5.1</b> 數據</a></li>
<li class="chapter" data-level="59.5.2" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#讀入-ghq-數據探索其內容該數據是否是平衡數據-balanced計算每名學生的兩次問卷成績平均分"><i class="fa fa-check"></i><b>59.5.2</b> 讀入 GHQ 數據，探索其內容，該數據是否是平衡數據 (balanced)？計算每名學生的兩次問卷成績平均分。</a></li>
<li class="chapter" data-level="59.5.3" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#把數據從寬-wide-改變成長-long-的形式"><i class="fa fa-check"></i><b>59.5.3</b> 把數據從寬 (wide) 改變成長 (long) 的形式</a></li>
<li class="chapter" data-level="59.5.4" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#對數據按照-id-分層進行-anova"><i class="fa fa-check"></i><b>59.5.4</b> 對數據按照 <code>id</code> 分層進行 ANOVA</a></li>
<li class="chapter" data-level="59.5.5" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#用-r-裏的-nlme-包使用限制性極大似然法-restricted-maximum-likelihood-reml-擬合截距混合效應模型比較其結果和前文中隨機效應-anova-的結果"><i class="fa fa-check"></i><b>59.5.5</b> 用 R 裏的 <code>nlme</code> 包，使用限制性極大似然法 (restricted maximum likelihood, REML) 擬合截距混合效應模型，比較其結果和前文中隨機效應 ANOVA 的結果</a></li>
<li class="chapter" data-level="59.5.6" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#用極大似然法-maximum-likelihood-ml-method-ml-重新擬合前面的混合效應模型比較結果有什麼不同"><i class="fa fa-check"></i><b>59.5.6</b> 用極大似然法 (maximum likelihood, ML) <code>method = &quot;ML&quot;</code> 重新擬合前面的混合效應模型，比較結果有什麼不同。</a></li>
<li class="chapter" data-level="59.5.7" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#用簡單線性迴歸擬合一個固定效應模型"><i class="fa fa-check"></i><b>59.5.7</b> 用簡單線性迴歸擬合一個固定效應模型</a></li>
<li class="chapter" data-level="59.5.8" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#計算這些隨機截距的均值和標準差"><i class="fa fa-check"></i><b>59.5.8</b> 計算這些隨機截距的均值和標準差</a></li>
<li class="chapter" data-level="59.5.9" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#忽略掉所有的分層和解釋變量擬合-ghq-的簡單線性迴歸"><i class="fa fa-check"></i><b>59.5.9</b> 忽略掉所有的分層和解釋變量擬合 <code>GHQ</code> 的簡單線性迴歸</a></li>
<li class="chapter" data-level="59.5.10" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#用分層的穩健法-三明治標準誤法-計算簡單線性迴歸時截距的標準誤差和簡單線性迴歸時的結果作比較"><i class="fa fa-check"></i><b>59.5.10</b> 用分層的穩健法 (三明治標準誤法) 計算簡單線性迴歸時，截距的標準誤差，和簡單線性迴歸時的結果作比較</a></li>
<li class="chapter" data-level="59.5.11" data-path="隨機截距模型-random-intercept-model.html"><a href="隨機截距模型-random-intercept-model.html#讀入-siblings-數據先總結嬰兒的出生體重思考這個數據中嬰兒出生體重之間是否可能存在關聯性它的來源是哪裏用這個數據擬合兩個混合效應模型-ml-reml不加入任何解釋變量"><i class="fa fa-check"></i><b>59.5.11</b> 讀入 <code>siblings</code> 數據。先總結嬰兒的出生體重，思考這個數據中嬰兒出生體重之間是否可能存在關聯性？它的來源是哪裏。用這個數據擬合兩個混合效應模型 (ML, REML)，不加入任何解釋變量。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="60" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><i class="fa fa-check"></i><b>60</b> 隨機截距模型中加入共變量 random intercept model with covariates</a><ul>
<li class="chapter" data-level="60.1" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#多元線性回歸模型的延伸"><i class="fa fa-check"></i><b>60.1</b> 多元線性回歸模型的延伸</a></li>
<li class="chapter" data-level="60.2" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#siblings-數據中新生兒體重的實例"><i class="fa fa-check"></i><b>60.2</b> <code>siblings</code> 數據中新生兒體重的實例</a></li>
<li class="chapter" data-level="60.3" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#賦值予隨機效應成分"><i class="fa fa-check"></i><b>60.3</b> 賦值予隨機效應成分</a><ul>
<li class="chapter" data-level="60.3.1" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#簡單預測-simple-prediction"><i class="fa fa-check"></i><b>60.3.1</b> 簡單預測 simple prediction</a></li>
<li class="chapter" data-level="60.3.2" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#eb-預測值"><i class="fa fa-check"></i><b>60.3.2</b> EB 預測值</a></li>
</ul></li>
<li class="chapter" data-level="60.4" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#混合效應模型的診斷"><i class="fa fa-check"></i><b>60.4</b> 混合效應模型的診斷</a></li>
<li class="chapter" data-level="60.5" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#第二層級-cluster-levellevel-2-的協方差"><i class="fa fa-check"></i><b>60.5</b> 第二層級 (cluster level/level 2) 的協方差</a></li>
<li class="chapter" data-level="60.6" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#層內層間效應估計"><i class="fa fa-check"></i><b>60.6</b> 層內層間效應估計</a></li>
<li class="chapter" data-level="60.7" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#到底選擇固定還是混合模型"><i class="fa fa-check"></i><b>60.7</b> 到底選擇固定還是混合模型？</a></li>
<li class="chapter" data-level="60.8" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#練習題目"><i class="fa fa-check"></i><b>60.8</b> 練習題目</a><ul>
<li class="chapter" data-level="60.8.1" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#把-high-school-and-beyond-數據讀入-r-中"><i class="fa fa-check"></i><b>60.8.1</b> 把 High-school-and-Beyond 數據讀入 R 中。</a></li>
<li class="chapter" data-level="60.8.2" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#擬合兩個隨機截距模型-ml-reml結果變量用-mathach解釋變量用-ses觀察結果是否不同"><i class="fa fa-check"></i><b>60.8.2</b> 擬合兩個隨機截距模型 (ML, REML)，結果變量用 <code>mathach</code>，解釋變量用 <code>ses</code>。觀察結果是否不同。</a></li>
<li class="chapter" data-level="60.8.3" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#觀察學校類型是否爲天主教學校-sector-的分佈把它加入剛擬合的兩個隨機截距模型它們估計的隨機效應標準差-hatsigma_u和隨機誤差標準差-hatsigma_e和之前有什麼不同-mlreml-的選用對結果有影響嗎"><i class="fa fa-check"></i><b>60.8.3</b> 觀察學校類型是否爲天主教學校 <code>sector</code> 的分佈，把它加入剛擬合的兩個隨機截距模型，它們估計的隨機效應標準差 <span class="math inline">\(\hat\sigma_u\)</span>，和隨機誤差標準差 <span class="math inline">\(\hat\sigma_e\)</span>，和之前有什麼不同？ “ML，REML” 的選用對結果有影響嗎？</a></li>
<li class="chapter" data-level="60.8.4" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#現在把學校規模-size-這一變量加入混合效應模型的固定效應部分記得先把該變量中心化並除以-100會有助於對結果的解釋-比平均值每增加100名學生仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化"><i class="fa fa-check"></i><b>60.8.4</b> 現在把學校規模 <code>size</code> 這一變量加入混合效應模型的固定效應部分，記得先把該變量中心化，並除以 100，會有助於對結果的解釋 (比平均值每增加100名學生)。仔細觀察模型結果中隨機效應標準差和隨機誤差標準殘差的變化。</a></li>
<li class="chapter" data-level="60.8.5" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#在模型的固定效應部分增加-sizesector-的交互作用項觀察輸出結果中該交互作用項是否有意義用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據"><i class="fa fa-check"></i><b>60.8.5</b> 在模型的固定效應部分增加 <code>size*sector</code> 的交互作用項。觀察輸出結果中該交互作用項是否有意義。用什麼檢驗方法判斷這個交互作用項能否幫助模型更加擬合數據？</a></li>
<li class="chapter" data-level="60.8.6" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#把上面八個模型估計的隨機效應標準差和隨機誤差標準差總結成表格它們之間有什麼規律嗎"><i class="fa fa-check"></i><b>60.8.6</b> 把上面八個模型估計的隨機效應標準差，和隨機誤差標準差總結成表格，它們之間有什麼規律嗎？</a></li>
<li class="chapter" data-level="60.8.7" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#在混合效應模型的固定效應部分增加學生性別-female和學生是否是少數族裔-minority-兩個變量再觀察-hatsigma_u-hatsigma_e-是否發生變化"><i class="fa fa-check"></i><b>60.8.7</b> 在混合效應模型的固定效應部分增加學生性別 <code>female</code>，和學生是否是少數族裔 <code>minority</code> 兩個變量。再觀察 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span> 是否發生變化？</a></li>
<li class="chapter" data-level="60.8.8" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#檢查學生性別和族裔是否和學校是否是天主教會學校有關係先作分類型數據的分佈表格然後把它們各自與-sector-的交互作用項加入混合效應模型中的固定效應部分記錄下此時的-hatsigma_u-hatsigma_e"><i class="fa fa-check"></i><b>60.8.8</b> 檢查學生性別和族裔是否和學校是否是天主教會學校有關係，先作分類型數據的分佈表格，然後把它們各自與 <code>sector</code> 的交互作用項加入混合效應模型中的固定效應部分，記錄下此時的 <span class="math inline">\(\hat\sigma_u, \hat\sigma_e\)</span></a></li>
<li class="chapter" data-level="60.8.9" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#對上面最後一個模型進行殘差分析和模型的診斷"><i class="fa fa-check"></i><b>60.8.9</b> 對上面最後一個模型進行殘差分析和模型的診斷。</a></li>
<li class="chapter" data-level="60.8.10" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#通過剛剛所求的隨機效應方差的殘差確認哪個學校存在相對極端的值"><i class="fa fa-check"></i><b>60.8.10</b> 通過剛剛所求的隨機效應方差的殘差，確認哪個學校存在相對極端的值。</a></li>
<li class="chapter" data-level="60.8.11" data-path="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html"><a href="隨機截距模型中加入共變量-random-intercept-model-with-covariates.html#計算學校水平的-ses-平均值以及每個學生自己和所在學校均值之間的差值大小分別擬合兩個不同的混合效應模型一個只用-ses另一個換做使用新計算的組均值和組內均差"><i class="fa fa-check"></i><b>60.8.11</b> 計算學校水平的 SES 平均值，以及每個學生自己和所在學校均值之間的差值大小。分別擬合兩個不同的混合效應模型，一個只用 <code>SES</code>，另一個換做使用新計算的組均值和組內均差。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="61" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html"><i class="fa fa-check"></i><b>61</b> 隨機回歸系數模型 random coefficient model</a><ul>
<li class="chapter" data-level="61.1" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#gcse-scores-實例"><i class="fa fa-check"></i><b>61.1</b> GCSE scores 實例</a></li>
<li class="chapter" data-level="61.2" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#隨機回歸系數的實質"><i class="fa fa-check"></i><b>61.2</b> 隨機回歸系數的實質</a></li>
<li class="chapter" data-level="61.3" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#繼續-gcse-scores-實例"><i class="fa fa-check"></i><b>61.3</b> 繼續 GCSE scores 實例</a></li>
<li class="chapter" data-level="61.4" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#使用模型結果推斷"><i class="fa fa-check"></i><b>61.4</b> 使用模型結果推斷</a></li>
<li class="chapter" data-level="61.5" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#random-var"><i class="fa fa-check"></i><b>61.5</b> 隨機效應的方差</a></li>
<li class="chapter" data-level="61.6" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#模型效果評估"><i class="fa fa-check"></i><b>61.6</b> 模型效果評估</a></li>
<li class="chapter" data-level="61.7" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#練習題-9"><i class="fa fa-check"></i><b>61.7</b> 練習題</a><ul>
<li class="chapter" data-level="61.7.1" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#將數據導入軟件裏"><i class="fa fa-check"></i><b>61.7.1</b> 　將數據導入軟件裏，</a></li>
<li class="chapter" data-level="61.7.2" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#先忽略學校編號爲-48-的學校擬合一個只有固定效應-簡單線性回歸模型結果變量是-gcse解釋變量是-lrt-和學校"><i class="fa fa-check"></i><b>61.7.2</b> 先忽略學校編號爲 48 的學校，擬合一個只有固定效應 (簡單線性回歸模型)，結果變量是 GCSE，解釋變量是 LRT 和學校。</a></li>
<li class="chapter" data-level="61.7.3" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#僅有固定效應模型的學校變量變更爲學校類型-男校女校或混合校從這個新模型的結果來看你是否認爲學校類型和學校編號本身相比能夠解釋相同的學校層面的方差-lrt-的估計回歸參數發生了怎樣的變化"><i class="fa fa-check"></i><b>61.7.3</b> 僅有固定效應模型的學校變量變更爲學校類型 (男校女校或混合校)，從這個新模型的結果來看，你是否認爲學校類型，和學校編號本身相比能夠解釋相同的學校層面的方差？ <code>lrt</code> 的估計回歸參數發生了怎樣的變化？</a></li>
<li class="chapter" data-level="61.7.4" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#使用限制性極大似然法擬合一個隨機截距模型記錄此時的限制性對數似然的大小-log-likelihood用-lmertestrand-命令對隨機效應部分的方差是否爲零做檢驗指明該檢驗的零假設是什麼並解釋其結果的含義"><i class="fa fa-check"></i><b>61.7.4</b> 使用限制性極大似然法擬合一個隨機截距模型。記錄此時的限制性對數似然的大小 (log-likelihood)。用 <code>lmerTest::rand</code> 命令對隨機效應部分的方差是否爲零做檢驗，指明該檢驗的零假設是什麼，並解釋其結果的含義。</a></li>
<li class="chapter" data-level="61.7.5" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#在前一題的隨機截距模型中加入-schgend-變量作爲解釋隨機截距的一個自變量觀察輸出結果解釋其是否有意義記錄這個模型的限制性似然"><i class="fa fa-check"></i><b>61.7.5</b> 在前一題的隨機截距模型中加入 <code>schgend</code> 變量，作爲解釋隨機截距的一個自變量，觀察輸出結果，解釋其是否有意義。記錄這個模型的限制性似然。</a></li>
<li class="chapter" data-level="61.7.6" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#擬合隨機截距隨機斜率模型固定效應部分的-lrt-也加入進隨機效應部分"><i class="fa fa-check"></i><b>61.7.6</b> 擬合隨機截距隨機斜率模型，固定效應部分的 <code>lrt</code> 也加入進隨機效應部分。</a></li>
<li class="chapter" data-level="61.7.7" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#通過上面幾個模型計算獲得的似然嘗試檢驗隨機斜率標準差以及該標準差和隨機截距標準差的協相關是否有意義"><i class="fa fa-check"></i><b>61.7.7</b> 通過上面幾個模型計算獲得的似然，嘗試檢驗隨機斜率標準差，以及該標準差和隨機截距標準差的協相關是否有意義。</a></li>
<li class="chapter" data-level="61.7.8" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#模型中的-schgend-改成-mean_girl-會給出怎樣的結果呢"><i class="fa fa-check"></i><b>61.7.8</b> 模型中的 <code>schgend</code> 改成 <code>mean_girl</code> 會給出怎樣的結果呢？</a></li>
<li class="chapter" data-level="61.7.9" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#現在我們把注意力改爲關心學校編號爲-48-的學校的情況用且禁用它一所學校的數據擬合一個簡單線性回歸結果變量是-gcse解釋變量是-lrt"><i class="fa fa-check"></i><b>61.7.9</b> 現在我們把注意力改爲關心學校編號爲 48 的學校的情況。用且禁用它一所學校的數據，擬合一個簡單線性回歸，結果變量是 <code>gcse</code>，解釋變量是 <code>lrt</code>。</a></li>
<li class="chapter" data-level="61.7.10" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#這次不排除-48-號學校擬合所有學校的數據進入-fixed_reml2-模型中去結果有發生顯著的變化嗎"><i class="fa fa-check"></i><b>61.7.10</b> 這次不排除 48 號學校，擬合所有學校的數據進入 <code>Fixed_reml2</code> 模型中去，結果有發生顯著的變化嗎？</a></li>
<li class="chapter" data-level="61.7.11" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#計算這個模型的第二階級level-2-school-level的殘差"><i class="fa fa-check"></i><b>61.7.11</b> 計算這個模型的第二階級(level 2, <code>school</code> level)的殘差。</a></li>
<li class="chapter" data-level="61.7.12" data-path="隨機回歸系數模型-random-coefficient-model.html"><a href="隨機回歸系數模型-random-coefficient-model.html#計算這個模型的第一階級level-1-student殘差分析其分布查看第48所學校的殘差表現如何"><i class="fa fa-check"></i><b>61.7.12</b> 計算這個模型的第一階級(level 1, student)殘差，分析其分布，查看第48所學校的殘差表現如何。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="62" data-path="縱向研究數據-longitudinal-data-1.html"><a href="縱向研究數據-longitudinal-data-1.html"><i class="fa fa-check"></i><b>62</b> 縱向研究數據 longitudinal data 1</a><ul>
<li class="chapter" data-level="62.1" data-path="縱向研究數據-longitudinal-data-1.html"><a href="縱向研究數據-longitudinal-data-1.html#固定測量時刻-fixed-occasions"><i class="fa fa-check"></i><b>62.1</b> 固定測量時刻 fixed occasions</a><ul>
<li class="chapter" data-level="62.1.1" data-path="縱向研究數據-longitudinal-data-1.html"><a href="縱向研究數據-longitudinal-data-1.html#缺失值-missing-data"><i class="fa fa-check"></i><b>62.1.1</b> 缺失值 Missing data</a></li>
</ul></li>
<li class="chapter" data-level="62.2" data-path="縱向研究數據-longitudinal-data-1.html"><a href="縱向研究數據-longitudinal-data-1.html#不固定測量時刻-variable-occasions"><i class="fa fa-check"></i><b>62.2</b> 不固定測量時刻 variable occasions</a></li>
<li class="chapter" data-level="62.3" data-path="縱向研究數據-longitudinal-data-1.html"><a href="縱向研究數據-longitudinal-data-1.html#預測軌跡-predicting-trajectories"><i class="fa fa-check"></i><b>62.3</b> 預測軌跡 predicting trajectories</a></li>
<li class="chapter" data-level="62.4" data-path="縱向研究數據-longitudinal-data-1.html"><a href="縱向研究數據-longitudinal-data-1.html#practical-05-hier"><i class="fa fa-check"></i><b>62.4</b> Practical 05-Hier</a></li>
</ul></li>
<li class="chapter" data-level="63" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html"><i class="fa fa-check"></i><b>63</b> 縱向研究數據 longitudinal data 2</a><ul>
<li class="chapter" data-level="63.1" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html#邊際結構-marginal-structures"><i class="fa fa-check"></i><b>63.1</b> 邊際結構 marginal structures</a><ul>
<li class="chapter" data-level="63.1.1" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html#隨機截距模型"><i class="fa fa-check"></i><b>63.1.1</b> 隨機截距模型</a></li>
<li class="chapter" data-level="63.1.2" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html#隨機系數模型"><i class="fa fa-check"></i><b>63.1.2</b> 隨機系數模型</a></li>
</ul></li>
<li class="chapter" data-level="63.2" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html#矩陣記法"><i class="fa fa-check"></i><b>63.2</b> 矩陣記法</a></li>
<li class="chapter" data-level="63.3" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html#混合效應模型的一般化公式"><i class="fa fa-check"></i><b>63.3</b> 混合效應模型的一般化公式</a></li>
<li class="chapter" data-level="63.4" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html#其他可選擇的方差協方差矩陣特徵"><i class="fa fa-check"></i><b>63.4</b> 其他可選擇的方差協方差矩陣特徵</a></li>
<li class="chapter" data-level="63.5" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html#其他要點評論"><i class="fa fa-check"></i><b>63.5</b> 其他要點評論</a></li>
<li class="chapter" data-level="63.6" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html#不平衡數據"><i class="fa fa-check"></i><b>63.6</b> 不平衡數據</a></li>
<li class="chapter" data-level="63.7" data-path="縱向研究數據-longitudinal-data-2.html"><a href="縱向研究數據-longitudinal-data-2.html#practical-06-hier"><i class="fa fa-check"></i><b>63.7</b> Practical 06-Hier</a></li>
</ul></li>
<li class="chapter" data-level="64" data-path="縱向研究數據-longitudinal-data-3.html"><a href="縱向研究數據-longitudinal-data-3.html"><i class="fa fa-check"></i><b>64</b> 縱向研究數據 longitudinal data 3</a><ul>
<li class="chapter" data-level="64.1" data-path="縱向研究數據-longitudinal-data-3.html"><a href="縱向研究數據-longitudinal-data-3.html#第一層級的異質性-level-1-heterogeneity"><i class="fa fa-check"></i><b>64.1</b> 第一層級的異質性 level 1 heterogeneity</a></li>
<li class="chapter" data-level="64.2" data-path="縱向研究數據-longitudinal-data-3.html"><a href="縱向研究數據-longitudinal-data-3.html#第二層級異質性-level-2-heterogeneity"><i class="fa fa-check"></i><b>64.2</b> 第二層級異質性 level 2 heterogeneity</a></li>
<li class="chapter" data-level="64.3" data-path="縱向研究數據-longitudinal-data-3.html"><a href="縱向研究數據-longitudinal-data-3.html#分析策略-1"><i class="fa fa-check"></i><b>64.3</b> 分析策略</a><ul>
<li class="chapter" data-level="64.3.1" data-path="縱向研究數據-longitudinal-data-3.html"><a href="縱向研究數據-longitudinal-data-3.html#模型選擇和建模步驟"><i class="fa fa-check"></i><b>64.3.1</b> 模型選擇和建模步驟</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="65" data-path="generalized-estimating-equation.html"><a href="generalized-estimating-equation.html"><i class="fa fa-check"></i><b>65</b> Generalized Estimating Equation</a></li>
<li class="chapter" data-level="66" data-path="cluster-analysisunsupervised-learning-聚類分析.html"><a href="cluster-analysisunsupervised-learning-聚類分析.html"><i class="fa fa-check"></i><b>66</b> Cluster analysis/unsupervised learning 聚類分析</a><ul>
<li class="chapter" data-level="66.1" data-path="cluster-analysisunsupervised-learning-聚類分析.html"><a href="cluster-analysisunsupervised-learning-聚類分析.html#聚類分析過程"><i class="fa fa-check"></i><b>66.1</b> 聚類分析過程</a><ul>
<li class="chapter" data-level="66.1.1" data-path="cluster-analysisunsupervised-learning-聚類分析.html"><a href="cluster-analysisunsupervised-learning-聚類分析.html#連續型變量-continuous-variables-in-cluster-analysis"><i class="fa fa-check"></i><b>66.1.1</b> 連續型變量 continuous variables in cluster analysis</a></li>
<li class="chapter" data-level="66.1.2" data-path="cluster-analysisunsupervised-learning-聚類分析.html"><a href="cluster-analysisunsupervised-learning-聚類分析.html#二分類或者分類型變量之間的距離-distances-for-binarycategorical-variables"><i class="fa fa-check"></i><b>66.1.2</b> 二分類或者分類型變量之間的距離 distances for binary/categorical variables</a></li>
<li class="chapter" data-level="66.1.3" data-path="cluster-analysisunsupervised-learning-聚類分析.html"><a href="cluster-analysisunsupervised-learning-聚類分析.html#定義分類方法"><i class="fa fa-check"></i><b>66.1.3</b> 定義分類方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="67" data-path="missing-data-1.html"><a href="missing-data-1.html"><i class="fa fa-check"></i><b>67</b> Missing data 1</a></li>
<li class="chapter" data-level="68" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html"><i class="fa fa-check"></i><b>68</b> Principal Component Analysis 主成分分析</a><ul>
<li class="chapter" data-level="68.1" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html#數據有相關性時產生的問題"><i class="fa fa-check"></i><b>68.1</b> 數據有相關性時產生的問題</a></li>
<li class="chapter" data-level="68.2" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html#最大化方差等價於最大化數據點到新座標軸投影projection的長度"><i class="fa fa-check"></i><b>68.2</b> 最大化方差等價於最大化數據點到新座標軸<strong>“投影(projection)”</strong>的長度</a></li>
<li class="chapter" data-level="68.3" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html#數學推導"><i class="fa fa-check"></i><b>68.3</b> 數學推導</a><ul>
<li class="chapter" data-level="68.3.1" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html#超越對稱矩陣奇異值分解-singular-value-decomposition-svd"><i class="fa fa-check"></i><b>68.3.1</b> 超越對稱矩陣：奇異值分解 (singular value decomposition, SVD)</a></li>
</ul></li>
<li class="chapter" data-level="68.4" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html#主成分分析數據實例"><i class="fa fa-check"></i><b>68.4</b> 主成分分析數據實例</a></li>
<li class="chapter" data-level="68.5" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html#在pca圖形中加入補充變量和補充個體-supplementary-elements"><i class="fa fa-check"></i><b>68.5</b> 在PCA圖形中加入補充變量和補充個體 (supplementary elements)</a><ul>
<li class="chapter" data-level="68.5.1" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html#展示分類輔助性變量和個體的關係"><i class="fa fa-check"></i><b>68.5.1</b> 展示分類輔助性變量和個體的關係</a></li>
</ul></li>
<li class="chapter" data-level="68.6" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html#cluster-analysispca-practical"><i class="fa fa-check"></i><b>68.6</b> Cluster analysis/PCA practical</a><ul>
<li class="chapter" data-level="68.6.1" data-path="principal-component-analysis-主成分分析.html"><a href="principal-component-analysis-主成分分析.html#使用的數據和簡單背景知識"><i class="fa fa-check"></i><b>68.6.1</b> 使用的數據和簡單背景知識</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="69" data-path="missing-data-2.html"><a href="missing-data-2.html"><i class="fa fa-check"></i><b>69</b> Missing data 2</a></li>
<li class="chapter" data-level="70" data-path="further-issues.html"><a href="further-issues.html"><i class="fa fa-check"></i><b>70</b> Further issues</a></li>
<li class="part"><span><b>X 生存分析 Survival Analysis</b></span></li>
<li class="chapter" data-level="71" data-path="生存分析入門.html"><a href="生存分析入門.html"><i class="fa fa-check"></i><b>71</b> 生存分析入門</a><ul>
<li class="chapter" data-level="71.1" data-path="生存分析入門.html"><a href="生存分析入門.html#什麼是生存分析"><i class="fa fa-check"></i><b>71.1</b> 什麼是生存分析</a></li>
<li class="chapter" data-level="71.2" data-path="生存分析入門.html"><a href="生存分析入門.html#生存數據在哪裏"><i class="fa fa-check"></i><b>71.2</b> 生存數據在哪裏</a></li>
<li class="chapter" data-level="71.3" data-path="生存分析入門.html"><a href="生存分析入門.html#生存數據分析之前要理清楚的問題"><i class="fa fa-check"></i><b>71.3</b> 生存數據分析之前要理清楚的問題</a></li>
<li class="chapter" data-level="71.4" data-path="生存分析入門.html"><a href="生存分析入門.html#生存數據的左右截尾"><i class="fa fa-check"></i><b>71.4</b> 生存數據的左右截尾</a><ul>
<li class="chapter" data-level="71.4.1" data-path="生存分析入門.html"><a href="生存分析入門.html#左側截尾數據-left-truncation"><i class="fa fa-check"></i><b>71.4.1</b> 左側截尾數據 left-truncation</a></li>
</ul></li>
<li class="chapter" data-level="71.5" data-path="生存分析入門.html"><a href="生存分析入門.html#初步分析生存數據"><i class="fa fa-check"></i><b>71.5</b> 初步分析生存數據</a></li>
<li class="chapter" data-level="71.6" data-path="生存分析入門.html"><a href="生存分析入門.html#初步描述生存數據"><i class="fa fa-check"></i><b>71.6</b> 初步描述生存數據</a><ul>
<li class="chapter" data-level="71.6.1" data-path="生存分析入門.html"><a href="生存分析入門.html#生存方程"><i class="fa fa-check"></i><b>71.6.1</b> 生存方程</a></li>
<li class="chapter" data-level="71.6.2" data-path="生存分析入門.html"><a href="生存分析入門.html#風險度方程"><i class="fa fa-check"></i><b>71.6.2</b> 風險度方程</a></li>
<li class="chapter" data-level="71.6.3" data-path="生存分析入門.html"><a href="生存分析入門.html#概率密度方程"><i class="fa fa-check"></i><b>71.6.3</b> 概率密度方程</a></li>
<li class="chapter" data-level="71.6.4" data-path="生存分析入門.html"><a href="生存分析入門.html#各方程之間的關系"><i class="fa fa-check"></i><b>71.6.4</b> 各方程之間的關系</a></li>
</ul></li>
<li class="chapter" data-level="71.7" data-path="生存分析入門.html"><a href="生存分析入門.html#生存時間的參數分布"><i class="fa fa-check"></i><b>71.7</b> 生存時間的參數分布</a><ul>
<li class="chapter" data-level="71.7.1" data-path="生存分析入門.html"><a href="生存分析入門.html#exponentialdist"><i class="fa fa-check"></i><b>71.7.1</b> 指數分布</a></li>
<li class="chapter" data-level="71.7.2" data-path="生存分析入門.html"><a href="生存分析入門.html#weibulldist"><i class="fa fa-check"></i><b>71.7.2</b> Weibull 分布</a></li>
</ul></li>
<li class="chapter" data-level="71.8" data-path="生存分析入門.html"><a href="生存分析入門.html#極大似然法估計"><i class="fa fa-check"></i><b>71.8</b> 極大似然法估計</a></li>
<li class="chapter" data-level="71.9" data-path="生存分析入門.html"><a href="生存分析入門.html#practical-survival-01"><i class="fa fa-check"></i><b>71.9</b> Practical Survival 01</a><ul>
<li class="chapter" data-level="71.9.1" data-path="生存分析入門.html"><a href="生存分析入門.html#生存分析的時間尺度"><i class="fa fa-check"></i><b>71.9.1</b> 生存分析的時間尺度</a></li>
<li class="chapter" data-level="71.9.2" data-path="生存分析入門.html"><a href="生存分析入門.html#擬合最簡單的指數分布生存數據"><i class="fa fa-check"></i><b>71.9.2</b> 擬合最簡單的指數分布生存數據</a></li>
<li class="chapter" data-level="71.9.3" data-path="生存分析入門.html"><a href="生存分析入門.html#探索服從-weibull-分布時風險度方程的曲線"><i class="fa fa-check"></i><b>71.9.3</b> 探索服從 Weibull 分布時風險度方程的曲線</a></li>
<li class="chapter" data-level="71.9.4" data-path="生存分析入門.html"><a href="生存分析入門.html#探索-對數邏輯-log-logistic-分布時風險度方程曲線會有哪些特性"><i class="fa fa-check"></i><b>71.9.4</b> 探索 對數邏輯 (log-logistic) 分布時，風險度方程曲線會有哪些特性？</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="72" data-path="nonparametric.html"><a href="nonparametric.html"><i class="fa fa-check"></i><b>72</b> 非參數法分析生存數據</a><ul>
<li class="chapter" data-level="72.1" data-path="nonparametric.html"><a href="nonparametric.html#生存分析中的非參數分析法"><i class="fa fa-check"></i><b>72.1</b> 生存分析中的非參數分析法</a></li>
<li class="chapter" data-level="72.2" data-path="nonparametric.html"><a href="nonparametric.html#kaplan-meier-法分析生存方程"><i class="fa fa-check"></i><b>72.2</b> Kaplan-Meier 法分析生存方程</a><ul>
<li class="chapter" data-level="72.2.1" data-path="nonparametric.html"><a href="nonparametric.html#當數據中沒有刪失值"><i class="fa fa-check"></i><b>72.2.1</b> 當數據中沒有刪失值</a></li>
<li class="chapter" data-level="72.2.2" data-path="nonparametric.html"><a href="nonparametric.html#當數據中有刪失值"><i class="fa fa-check"></i><b>72.2.2</b> 當數據中有刪失值</a></li>
</ul></li>
<li class="chapter" data-level="72.3" data-path="nonparametric.html"><a href="nonparametric.html#kaplan-meier-數據的不確定性"><i class="fa fa-check"></i><b>72.3</b> Kaplan-Meier 數據的不確定性</a></li>
<li class="chapter" data-level="72.4" data-path="nonparametric.html"><a href="nonparametric.html#另一種非參數法分析-生命表格估計"><i class="fa fa-check"></i><b>72.4</b> 另一種非參數法分析 – 生命表格估計</a></li>
<li class="chapter" data-level="72.5" data-path="nonparametric.html"><a href="nonparametric.html#兩組之間生存概率的比較"><i class="fa fa-check"></i><b>72.5</b> 兩組之間生存概率的比較</a><ul>
<li class="chapter" data-level="72.5.1" data-path="nonparametric.html"><a href="nonparametric.html#the-log-rank-test"><i class="fa fa-check"></i><b>72.5.1</b> The log rank test</a></li>
</ul></li>
<li class="chapter" data-level="72.6" data-path="nonparametric.html"><a href="nonparametric.html#計算累積風險度-cumulative-hazard"><i class="fa fa-check"></i><b>72.6</b> 計算累積風險度 cumulative hazard</a></li>
<li class="chapter" data-level="72.7" data-path="nonparametric.html"><a href="nonparametric.html#practical-02---survival-analysis"><i class="fa fa-check"></i><b>72.7</b> Practical 02 - survival analysis</a></li>
</ul></li>
<li class="chapter" data-level="73" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html"><i class="fa fa-check"></i><b>73</b> 生存數據中的回歸模型</a><ul>
<li class="chapter" data-level="73.1" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html#生存數據的似然方程"><i class="fa fa-check"></i><b>73.1</b> 生存數據的似然方程</a></li>
<li class="chapter" data-level="73.2" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html#如何加入解釋變量"><i class="fa fa-check"></i><b>73.2</b> 如何加入解釋變量</a></li>
<li class="chapter" data-level="73.3" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html#指數模型-exponential-model"><i class="fa fa-check"></i><b>73.3</b> 指數模型 exponential model</a></li>
<li class="chapter" data-level="73.4" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html#weibull-分布"><i class="fa fa-check"></i><b>73.4</b> Weibull 分布</a></li>
<li class="chapter" data-level="73.5" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html#weibull-和-指數模型的比較"><i class="fa fa-check"></i><b>73.5</b> Weibull 和 指數模型的比較</a><ul>
<li class="chapter" data-level="73.5.1" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html#繪圖法"><i class="fa fa-check"></i><b>73.5.1</b> 繪圖法</a></li>
<li class="chapter" data-level="73.5.2" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html#統計檢驗法"><i class="fa fa-check"></i><b>73.5.2</b> 統計檢驗法</a></li>
</ul></li>
<li class="chapter" data-level="73.6" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html#多於-1-個解釋變量的參數模型"><i class="fa fa-check"></i><b>73.6</b> 多於 1 個解釋變量的參數模型</a></li>
<li class="chapter" data-level="73.7" data-path="生存數據中的回歸模型.html"><a href="生存數據中的回歸模型.html#practical-survival-03"><i class="fa fa-check"></i><b>73.7</b> Practical Survival 03</a></li>
</ul></li>
<li class="chapter" data-level="74" data-path="cox-比例風險模型.html"><a href="cox-比例風險模型.html"><i class="fa fa-check"></i><b>74</b> Cox 比例風險模型</a><ul>
<li class="chapter" data-level="74.1" data-path="cox-比例風險模型.html"><a href="cox-比例風險模型.html#該用半參數模型還是用全參數模型"><i class="fa fa-check"></i><b>74.1</b> 該用半參數模型還是用全參數模型</a></li>
</ul></li>
<li class="chapter" data-level="75" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html"><i class="fa fa-check"></i><b>75</b> 分析策略和模型檢查 Model checking-survival analysis</a><ul>
<li class="chapter" data-level="75.1" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#生存分析策略"><i class="fa fa-check"></i><b>75.1</b> 生存分析策略</a></li>
<li class="chapter" data-level="75.2" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#針對臨床實驗"><i class="fa fa-check"></i><b>75.2</b> 針對臨床實驗</a></li>
<li class="chapter" data-level="75.3" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#針對觀察性研究"><i class="fa fa-check"></i><b>75.3</b> 針對觀察性研究</a></li>
<li class="chapter" data-level="75.4" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#模型檢查的要點"><i class="fa fa-check"></i><b>75.4</b> 模型檢查的要點</a></li>
<li class="chapter" data-level="75.5" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#比例風險假設的檢查-check-the-proportional-hazard-assumtion"><i class="fa fa-check"></i><b>75.5</b> 比例風險假設的檢查 check the proportional hazard assumtion</a><ul>
<li class="chapter" data-level="75.5.1" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#比例風險檢查的統計檢驗法"><i class="fa fa-check"></i><b>75.5.1</b> 比例風險檢查的統計檢驗法</a></li>
<li class="chapter" data-level="75.5.2" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#用-schoenfeld-殘差繪圖"><i class="fa fa-check"></i><b>75.5.2</b> 用 Schoenfeld 殘差繪圖</a></li>
</ul></li>
<li class="chapter" data-level="75.6" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#評價模型擬合的其他有趣方法"><i class="fa fa-check"></i><b>75.6</b> 評價模型擬合的其他有趣方法</a><ul>
<li class="chapter" data-level="75.6.1" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#martingale-殘差-assessing-the-functional-form-of-continuous-variables"><i class="fa fa-check"></i><b>75.6.1</b> Martingale 殘差-assessing the functional form of continuous variables</a></li>
<li class="chapter" data-level="75.6.2" data-path="分析策略和模型檢查-model-checking-survival-analysis.html"><a href="分析策略和模型檢查-model-checking-survival-analysis.html#deviance-偏差殘差-identifying-individuals-for-whom-the-model-does-not-provide-a-good-fit"><i class="fa fa-check"></i><b>75.6.2</b> Deviance 偏差殘差 – identifying individuals for whom the model does not provide a good fit</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="76" data-path="競爭風險模型-competing-risk.html"><a href="競爭風險模型-competing-risk.html"><i class="fa fa-check"></i><b>76</b> 競爭風險模型 competing risk</a><ul>
<li class="chapter" data-level="76.1" data-path="競爭風險模型-competing-risk.html"><a href="競爭風險模型-competing-risk.html#cause-specific-hazard"><i class="fa fa-check"></i><b>76.1</b> Cause-specific hazard</a><ul>
<li class="chapter" data-level="76.1.1" data-path="競爭風險模型-competing-risk.html"><a href="競爭風險模型-competing-risk.html#cause-specific-hazards-models"><i class="fa fa-check"></i><b>76.1.1</b> Cause-specific hazards models</a></li>
</ul></li>
<li class="chapter" data-level="76.2" data-path="競爭風險模型-competing-risk.html"><a href="競爭風險模型-competing-risk.html#cumulative-incidence-function"><i class="fa fa-check"></i><b>76.2</b> Cumulative incidence function</a></li>
<li class="chapter" data-level="76.3" data-path="競爭風險模型-competing-risk.html"><a href="競爭風險模型-competing-risk.html#subdistribution-hazard---fine-and-gray-model"><i class="fa fa-check"></i><b>76.3</b> Subdistribution hazard - Fine and Gray model</a><ul>
<li class="chapter" data-level="76.3.1" data-path="競爭風險模型-competing-risk.html"><a href="競爭風險模型-competing-risk.html#subdistribution-hazard-model"><i class="fa fa-check"></i><b>76.3.1</b> Subdistribution hazard model</a></li>
</ul></li>
<li class="chapter" data-level="76.4" data-path="競爭風險模型-competing-risk.html"><a href="競爭風險模型-competing-risk.html#multi-state-models"><i class="fa fa-check"></i><b>76.4</b> Multi-state models</a><ul>
<li class="chapter" data-level="76.4.1" data-path="競爭風險模型-competing-risk.html"><a href="競爭風險模型-competing-risk.html#the-markov-model"><i class="fa fa-check"></i><b>76.4.1</b> The Markov model</a></li>
<li class="chapter" data-level="76.4.2" data-path="競爭風險模型-competing-risk.html"><a href="競爭風險模型-competing-risk.html#cox-proportional-hazards-model-for-transition-intensities"><i class="fa fa-check"></i><b>76.4.2</b> Cox proportional hazards model for transition intensities</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="77" data-path="生存分析的其他手段.html"><a href="生存分析的其他手段.html"><i class="fa fa-check"></i><b>77</b> 生存分析的其他手段</a><ul>
<li class="chapter" data-level="77.1" data-path="生存分析的其他手段.html"><a href="生存分析的其他手段.html#分層cox生存分析-stratified-cox-proportional-hazards-model"><i class="fa fa-check"></i><b>77.1</b> 分層Cox生存分析 stratified Cox proportional hazards model</a></li>
<li class="chapter" data-level="77.2" data-path="生存分析的其他手段.html"><a href="生存分析的其他手段.html#加速失效死亡模型-accelerated-failure-time-aft-model"><i class="fa fa-check"></i><b>77.2</b> 加速失效(死亡)模型 Accelerated failure time (AFT) model</a><ul>
<li class="chapter" data-level="77.2.1" data-path="生存分析的其他手段.html"><a href="生存分析的其他手段.html#詳細推導"><i class="fa fa-check"></i><b>77.2.1</b> 詳細推導</a></li>
<li class="chapter" data-level="77.2.2" data-path="生存分析的其他手段.html"><a href="生存分析的其他手段.html#再詳細推導"><i class="fa fa-check"></i><b>77.2.2</b> 再詳細推導</a></li>
<li class="chapter" data-level="77.2.3" data-path="生存分析的其他手段.html"><a href="生存分析的其他手段.html#風險比例模型ph和加速失效死亡模型aft的比較"><i class="fa fa-check"></i><b>77.2.3</b> 風險比例模型(PH)和加速失效（死亡）模型(AFT)的比較</a></li>
<li class="chapter" data-level="77.2.4" data-path="生存分析的其他手段.html"><a href="生存分析的其他手段.html#weibull-模型也是一種-aft-模型"><i class="fa fa-check"></i><b>77.2.4</b> Weibull 模型也是一種 AFT 模型</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="78" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><i class="fa fa-check"></i><b>78</b> 時間依存變量 Time-dependent variables 和脆弱模型 frailty model</a><ul>
<li class="chapter" data-level="78.1" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#時間依存變量指的是什麼"><i class="fa fa-check"></i><b>78.1</b> 時間依存變量指的是什麼</a></li>
<li class="chapter" data-level="78.2" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#extended-cox-model-把cox模型擴展開去"><i class="fa fa-check"></i><b>78.2</b> Extended Cox model 把Cox模型擴展開去</a><ul>
<li class="chapter" data-level="78.2.1" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#練習題-exercise-8.1"><i class="fa fa-check"></i><b>78.2.1</b> 練習題 exercise 8.1</a></li>
<li class="chapter" data-level="78.2.2" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#解答"><i class="fa fa-check"></i><b>78.2.2</b> 解答</a></li>
</ul></li>
<li class="chapter" data-level="78.3" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#時間依存變量數據的結構"><i class="fa fa-check"></i><b>78.3</b> 時間依存變量數據的結構</a><ul>
<li class="chapter" data-level="78.3.1" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#值得注意的點"><i class="fa fa-check"></i><b>78.3.1</b> 值得注意的點</a></li>
</ul></li>
<li class="chapter" data-level="78.4" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#frailty-models-脆弱模型"><i class="fa fa-check"></i><b>78.4</b> Frailty Models (脆弱模型?)</a><ul>
<li class="chapter" data-level="78.4.1" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#individual-frailty-model"><i class="fa fa-check"></i><b>78.4.1</b> Individual frailty model</a></li>
<li class="chapter" data-level="78.4.2" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#application-to-a-weibull-model"><i class="fa fa-check"></i><b>78.4.2</b> Application to a Weibull model</a></li>
<li class="chapter" data-level="78.4.3" data-path="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html"><a href="時間依存變量-time-dependent-variables-和脆弱模型-frailty-model.html#shared-frailty-model"><i class="fa fa-check"></i><b>78.4.3</b> Shared frailty model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="79" data-path="時間事件數據的高級分析法.html"><a href="時間事件數據的高級分析法.html"><i class="fa fa-check"></i><b>79</b> 時間事件數據的高級分析法</a></li>
<li class="chapter" data-level="80" data-path="貝葉斯生存分析-bayesian-survival-analysis.html"><a href="貝葉斯生存分析-bayesian-survival-analysis.html"><i class="fa fa-check"></i><b>80</b> 貝葉斯生存分析 Bayesian Survival Analysis</a></li>
<li class="part"><span><b>XI 貝葉斯統計學 Bayesian Statistics</b></span></li>
<li class="chapter" data-level="81" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html"><i class="fa fa-check"></i><b>81</b> 爲什麼我們要用貝葉斯統計學方法？</a><ul>
<li class="chapter" data-level="81.1" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html#氨甲喋呤-methotrexate-在系統性硬皮病-systematic-sclerosis-ssc-中的療效"><i class="fa fa-check"></i><b>81.1</b> 氨甲喋呤 (methotrexate) 在系統性硬皮病 (systematic sclerosis, SSc) 中的療效</a><ul>
<li class="chapter" data-level="81.1.1" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html#背景資料-ssc-trial"><i class="fa fa-check"></i><b>81.1.1</b> 背景資料-SSc trial</a></li>
<li class="chapter" data-level="81.1.2" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html#概率論者分析結果"><i class="fa fa-check"></i><b>81.1.2</b> 概率論者分析結果</a></li>
<li class="chapter" data-level="81.1.3" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html#貝葉斯統計分析結果"><i class="fa fa-check"></i><b>81.1.3</b> 貝葉斯統計分析結果</a></li>
</ul></li>
<li class="chapter" data-level="81.2" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html#example-the-great-trial"><i class="fa fa-check"></i><b>81.2</b> Example: The GREAT trial</a><ul>
<li class="chapter" data-level="81.2.1" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html#background-great-trial"><i class="fa fa-check"></i><b>81.2.1</b> Background (GREAT trial)</a></li>
<li class="chapter" data-level="81.2.2" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html#試驗結果"><i class="fa fa-check"></i><b>81.2.2</b> 試驗結果</a></li>
<li class="chapter" data-level="81.2.3" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html#經典統計學分析方法"><i class="fa fa-check"></i><b>81.2.3</b> 經典統計學分析方法</a></li>
<li class="chapter" data-level="81.2.4" data-path="爲什麼我們要用貝葉斯統計學方法.html"><a href="爲什麼我們要用貝葉斯統計學方法.html#貝葉斯統計學分析方法"><i class="fa fa-check"></i><b>81.2.4</b> 貝葉斯統計學分析方法</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="82" data-path="MC-estimation.html"><a href="MC-estimation.html"><i class="fa fa-check"></i><b>82</b> 蒙特卡羅估計和預測 Mente Carlo estimation and prediction</a><ul>
<li class="chapter" data-level="82.1" data-path="MC-estimation.html"><a href="MC-estimation.html#起源"><i class="fa fa-check"></i><b>82.1</b> 起源</a></li>
<li class="chapter" data-level="82.2" data-path="MC-estimation.html"><a href="MC-estimation.html#百分比的統計學推斷-inference-on-proportions"><i class="fa fa-check"></i><b>82.2</b> 百分比的統計學推斷 inference on proportions</a><ul>
<li class="chapter" data-level="82.2.1" data-path="MC-estimation.html"><a href="MC-estimation.html#example-new-drug"><i class="fa fa-check"></i><b>82.2.1</b> Example: New Drug</a></li>
<li class="chapter" data-level="82.2.2" data-path="MC-estimation.html"><a href="MC-estimation.html#beta-分布"><i class="fa fa-check"></i><b>82.2.2</b> Beta 分布</a></li>
<li class="chapter" data-level="82.2.3" data-path="MC-estimation.html"><a href="MC-estimation.html#作出預測"><i class="fa fa-check"></i><b>82.2.3</b> 作出預測</a></li>
<li class="chapter" data-level="82.2.4" data-path="MC-estimation.html"><a href="MC-estimation.html#example-新藥表現預測"><i class="fa fa-check"></i><b>82.2.4</b> Example: 新藥表現預測</a></li>
</ul></li>
<li class="chapter" data-level="82.3" data-path="MC-estimation.html"><a href="MC-estimation.html#蒙特卡羅估計"><i class="fa fa-check"></i><b>82.3</b> 蒙特卡羅估計</a><ul>
<li class="chapter" data-level="82.3.1" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法估計概率分佈尾側累積概率面積"><i class="fa fa-check"></i><b>82.3.1</b> 用蒙特卡羅法估計概率分佈尾側累積概率(面積)</a></li>
<li class="chapter" data-level="82.3.2" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法計算預測概率分佈"><i class="fa fa-check"></i><b>82.3.2</b> 用蒙特卡羅法計算預測概率分佈</a></li>
</ul></li>
<li class="chapter" data-level="82.4" data-path="MC-estimation.html"><a href="MC-estimation.html#蒙特卡羅法分析軟件-openbugs-jags"><i class="fa fa-check"></i><b>82.4</b> 蒙特卡羅法分析軟件 OpenBUGS / JAGS</a><ul>
<li class="chapter" data-level="82.4.1" data-path="MC-estimation.html"><a href="MC-estimation.html#用-openbugs-分析投擲硬幣數據"><i class="fa fa-check"></i><b>82.4.1</b> 用 OpenBUGS 分析投擲硬幣數據</a></li>
<li class="chapter" data-level="82.4.2" data-path="MC-estimation.html"><a href="MC-estimation.html#用-openbugs-對藥物臨牀試驗的結果做預測"><i class="fa fa-check"></i><b>82.4.2</b> 用 OpenBUGS 對藥物臨牀試驗的結果做預測</a></li>
<li class="chapter" data-level="82.4.3" data-path="MC-estimation.html"><a href="MC-estimation.html#用蒙特卡羅法計算一個臨牀試驗的統計效能-allow-uncertainty-in-power-calculation"><i class="fa fa-check"></i><b>82.4.3</b> 用蒙特卡羅法計算一個臨牀試驗的統計效能 allow uncertainty in power calculation</a></li>
</ul></li>
<li class="chapter" data-level="82.5" data-path="MC-estimation.html"><a href="MC-estimation.html#practical-bayesian-statistics-02"><i class="fa fa-check"></i><b>82.5</b> Practical Bayesian Statistics 02</a></li>
</ul></li>
<li class="chapter" data-level="83" data-path="共軛先驗概率-conjugate-priors.html"><a href="共軛先驗概率-conjugate-priors.html"><i class="fa fa-check"></i><b>83</b> 共軛先驗概率 Conjugate priors</a><ul>
<li class="chapter" data-level="83.1" data-path="共軛先驗概率-conjugate-priors.html"><a href="共軛先驗概率-conjugate-priors.html#貝葉斯推斷的基礎"><i class="fa fa-check"></i><b>83.1</b> 貝葉斯推斷的基礎</a></li>
<li class="chapter" data-level="83.2" data-path="共軛先驗概率-conjugate-priors.html"><a href="共軛先驗概率-conjugate-priors.html#二項分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>83.2</b> 二項分布(似然)數據的共軛先驗概率</a><ul>
<li class="chapter" data-level="83.2.1" data-path="共軛先驗概率-conjugate-priors.html"><a href="共軛先驗概率-conjugate-priors.html#事後概率分布預測"><i class="fa fa-check"></i><b>83.2.1</b> 事後概率分布預測</a></li>
</ul></li>
<li class="chapter" data-level="83.3" data-path="共軛先驗概率-conjugate-priors.html"><a href="共軛先驗概率-conjugate-priors.html#正態分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>83.3</b> 正態分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="83.4" data-path="共軛先驗概率-conjugate-priors.html"><a href="共軛先驗概率-conjugate-priors.html#泊淞分布似然數據的共軛先驗概率"><i class="fa fa-check"></i><b>83.4</b> 泊淞分布(似然)數據的共軛先驗概率</a></li>
<li class="chapter" data-level="83.5" data-path="共軛先驗概率-conjugate-priors.html"><a href="共軛先驗概率-conjugate-priors.html#共軛先驗概率分布的總結"><i class="fa fa-check"></i><b>83.5</b> 共軛先驗概率分布的總結</a></li>
<li class="chapter" data-level="83.6" data-path="共軛先驗概率-conjugate-priors.html"><a href="共軛先驗概率-conjugate-priors.html#BayesPrac03"><i class="fa fa-check"></i><b>83.6</b> Practical Bayesian Statistics 03</a></li>
</ul></li>
<li class="chapter" data-level="84" data-path="MCMC-methods.html"><a href="MCMC-methods.html"><i class="fa fa-check"></i><b>84</b> 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言</a><ul>
<li class="chapter" data-level="84.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#markov-chain-monte-carlo-馬爾可夫鏈蒙特卡羅算法"><i class="fa fa-check"></i><b>84.1</b> Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法</a><ul>
<li class="chapter" data-level="84.1.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#爲什麼我們需要用計算機模擬算法simulation-methods來進行貝葉斯統計推斷"><i class="fa fa-check"></i><b>84.1.1</b> 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？</a></li>
<li class="chapter" data-level="84.1.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#Gibbs-sampling"><i class="fa fa-check"></i><b>84.1.2</b> 吉布斯採樣</a></li>
<li class="chapter" data-level="84.1.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#初始值-initial-values"><i class="fa fa-check"></i><b>84.1.3</b> 初始值 initial values</a></li>
</ul></li>
<li class="chapter" data-level="84.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#使用-mcmc-時需要考慮的一些問題"><i class="fa fa-check"></i><b>84.2</b> 使用 MCMC 時需要考慮的一些問題</a><ul>
<li class="chapter" data-level="84.2.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#收斂時間"><i class="fa fa-check"></i><b>84.2.1</b> 收斂時間</a></li>
<li class="chapter" data-level="84.2.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#模型效率-efficiency-of-mcmc"><i class="fa fa-check"></i><b>84.2.2</b> 模型效率 efficiency of MCMC</a></li>
</ul></li>
<li class="chapter" data-level="84.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#bugs-軟件"><i class="fa fa-check"></i><b>84.3</b> BUGS 軟件</a></li>
<li class="chapter" data-level="84.4" data-path="MCMC-methods.html"><a href="MCMC-methods.html#圖形模型-statistical-graphical-models---directed-acyclic-graphs-dags"><i class="fa fa-check"></i><b>84.4</b> 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)</a><ul>
<li class="chapter" data-level="84.4.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#條件獨立的概念-conditional-independence-concept"><i class="fa fa-check"></i><b>84.4.1</b> 條件獨立的概念 conditional independence concept</a></li>
</ul></li>
<li class="chapter" data-level="84.5" data-path="MCMC-methods.html"><a href="MCMC-methods.html#bugs-language"><i class="fa fa-check"></i><b>84.5</b> BUGS language</a><ul>
<li class="chapter" data-level="84.5.1" data-path="MCMC-methods.html"><a href="MCMC-methods.html#節點的種類-types-of-nodes"><i class="fa fa-check"></i><b>84.5.1</b> 節點的種類 types of nodes</a></li>
<li class="chapter" data-level="84.5.2" data-path="MCMC-methods.html"><a href="MCMC-methods.html#分布的標記法"><i class="fa fa-check"></i><b>84.5.2</b> 分布的標記法</a></li>
<li class="chapter" data-level="84.5.3" data-path="MCMC-methods.html"><a href="MCMC-methods.html#arrays-and-loops"><i class="fa fa-check"></i><b>84.5.3</b> Arrays and loops</a></li>
<li class="chapter" data-level="84.5.4" data-path="MCMC-methods.html"><a href="MCMC-methods.html#常用的方程"><i class="fa fa-check"></i><b>84.5.4</b> 常用的方程</a></li>
</ul></li>
<li class="chapter" data-level="84.6" data-path="MCMC-methods.html"><a href="MCMC-methods.html#爲bugs-model模型準備格式正確的數據"><i class="fa fa-check"></i><b>84.6</b> 爲BUGS model模型準備格式正確的數據</a></li>
<li class="chapter" data-level="84.7" data-path="MCMC-methods.html"><a href="MCMC-methods.html#practical-bayesian-statistics-04"><i class="fa fa-check"></i><b>84.7</b> Practical Bayesian Statistics 04</a></li>
</ul></li>
<li class="chapter" data-level="85" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html"><i class="fa fa-check"></i><b>85</b> 建模和模型的檢查</a><ul>
<li class="chapter" data-level="85.1" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#BayesianLM"><i class="fa fa-check"></i><b>85.1</b> 簡單線性回歸模型</a></li>
<li class="chapter" data-level="85.2" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#children-in-the-gambia"><i class="fa fa-check"></i><b>85.2</b> Children in the Gambia</a><ul>
<li class="chapter" data-level="85.2.1" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#岡比亞兒童數據模型"><i class="fa fa-check"></i><b>85.2.1</b> 岡比亞兒童數據模型</a></li>
<li class="chapter" data-level="85.2.2" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#bugs-model-for-gambia-example"><i class="fa fa-check"></i><b>85.2.2</b> BUGS model for Gambia example</a></li>
<li class="chapter" data-level="85.2.3" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#data-file-for-the-gambia-example"><i class="fa fa-check"></i><b>85.2.3</b> Data file for the Gambia example</a></li>
<li class="chapter" data-level="85.2.4" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#初始值文件-initial-value-files"><i class="fa fa-check"></i><b>85.2.4</b> 初始值文件 initial value files</a></li>
<li class="chapter" data-level="85.2.5" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#給岡比亞兒童體重數據的貝葉斯模型檢查收斂-mcmc-check-1"><i class="fa fa-check"></i><b>85.2.5</b> 給岡比亞兒童體重數據的貝葉斯模型檢查收斂 (MCMC check 1)</a></li>
<li class="chapter" data-level="85.2.6" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#岡比亞兒童體重數據的貝葉斯統計學推斷結果"><i class="fa fa-check"></i><b>85.2.6</b> 岡比亞兒童體重數據的貝葉斯統計學推斷結果</a></li>
<li class="chapter" data-level="85.2.7" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量-effective-sample-size-mcmc-check-2"><i class="fa fa-check"></i><b>85.2.7</b> 檢查岡比亞兒童體重數據貝葉斯模型的有效樣本量 effective sample size (MCMC check 2)</a></li>
<li class="chapter" data-level="85.2.8" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#檢查模型擬合程度-checking-model-fit-for-the-gambia-example"><i class="fa fa-check"></i><b>85.2.8</b> 檢查模型擬合程度 checking model fit for the Gambia example</a></li>
<li class="chapter" data-level="85.2.9" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#tdreplacegaussian"><i class="fa fa-check"></i><b>85.2.9</b> 其他的替代模型 alternative model with t-errors</a></li>
</ul></li>
<li class="chapter" data-level="85.3" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#貝葉斯統計模型的比較-bayesian-model-comparison"><i class="fa fa-check"></i><b>85.3</b> 貝葉斯統計模型的比較 Bayesian model comparison</a><ul>
<li class="chapter" data-level="85.3.1" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#deviance-information-criterion-dic"><i class="fa fa-check"></i><b>85.3.1</b> Deviance Information Criterion (DIC)</a></li>
<li class="chapter" data-level="85.3.2" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#岡比亞兒童體重數據模型比較"><i class="fa fa-check"></i><b>85.3.2</b> 岡比亞兒童體重數據模型比較</a></li>
</ul></li>
<li class="chapter" data-level="85.4" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#practical-bayesian-statistics-05"><i class="fa fa-check"></i><b>85.4</b> Practical Bayesian Statistics 05</a><ul>
<li class="chapter" data-level="85.4.1" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#增加年齡二次方項-adding-age-squared"><i class="fa fa-check"></i><b>85.4.1</b> 增加年齡二次方項 adding age squared</a></li>
<li class="chapter" data-level="85.4.2" data-path="建模和模型的檢查.html"><a href="建模和模型的檢查.html#增加年齡和性別的交互作用項-adding-an-interaction-term"><i class="fa fa-check"></i><b>85.4.2</b> 增加年齡和性別的交互作用項 adding an interaction term</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="86" data-path="不同實驗研究設計時適用的貝葉斯模型.html"><a href="不同實驗研究設計時適用的貝葉斯模型.html"><i class="fa fa-check"></i><b>86</b> 不同實驗/研究設計時適用的貝葉斯模型</a><ul>
<li class="chapter" data-level="86.1" data-path="不同實驗研究設計時適用的貝葉斯模型.html"><a href="不同實驗研究設計時適用的貝葉斯模型.html#隊列研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>86.1</b> 隊列研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="86.2" data-path="不同實驗研究設計時適用的貝葉斯模型.html"><a href="不同實驗研究設計時適用的貝葉斯模型.html#病例對照研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>86.2</b> 病例對照研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="86.3" data-path="不同實驗研究設計時適用的貝葉斯模型.html"><a href="不同實驗研究設計時適用的貝葉斯模型.html#橫斷面研究設計時的貝葉斯模型"><i class="fa fa-check"></i><b>86.3</b> 橫斷面研究設計時的貝葉斯模型</a></li>
<li class="chapter" data-level="86.4" data-path="不同實驗研究設計時適用的貝葉斯模型.html"><a href="不同實驗研究設計時適用的貝葉斯模型.html#把不同實驗設計的數據用貝葉斯模型連接起來"><i class="fa fa-check"></i><b>86.4</b> 把不同實驗設計的數據用貝葉斯模型連接起來</a><ul>
<li class="chapter" data-level="86.4.1" data-path="不同實驗研究設計時適用的貝葉斯模型.html"><a href="不同實驗研究設計時適用的貝葉斯模型.html#linking-sub-models-throug-common-parameters"><i class="fa fa-check"></i><b>86.4.1</b> Linking sub-models throug common parameters</a></li>
</ul></li>
<li class="chapter" data-level="86.5" data-path="不同實驗研究設計時適用的貝葉斯模型.html"><a href="不同實驗研究設計時適用的貝葉斯模型.html#practical-bayesian-statistics-06"><i class="fa fa-check"></i><b>86.5</b> Practical Bayesian Statistics 06</a><ul>
<li class="chapter" data-level="86.5.1" data-path="不同實驗研究設計時適用的貝葉斯模型.html"><a href="不同實驗研究設計時適用的貝葉斯模型.html#the-great-trial"><i class="fa fa-check"></i><b>86.5.1</b> The GREAT Trial</a></li>
<li class="chapter" data-level="86.5.2" data-path="不同實驗研究設計時適用的貝葉斯模型.html"><a href="不同實驗研究設計時適用的貝葉斯模型.html#吸煙與癌症"><i class="fa fa-check"></i><b>86.5.2</b> 吸煙與癌症</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="87" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html"><i class="fa fa-check"></i><b>87</b> 貝葉斯廣義線性回歸</a><ul>
<li class="chapter" data-level="87.1" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html#如何在bugs語言中描述分類型變量"><i class="fa fa-check"></i><b>87.1</b> 如何在BUGS語言中描述分類型變量</a><ul>
<li class="chapter" data-level="87.1.1" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html#啞變量的數據矩陣"><i class="fa fa-check"></i><b>87.1.1</b> 啞變量的數據矩陣</a></li>
<li class="chapter" data-level="87.1.2" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html#雙重索引bugs語言標記法"><i class="fa fa-check"></i><b>87.1.2</b> 雙重索引BUGS語言標記法</a></li>
</ul></li>
<li class="chapter" data-level="87.2" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html#邏輯回歸-bayesian-logistic-regression"><i class="fa fa-check"></i><b>87.2</b> 邏輯回歸 Bayesian Logistic Regression</a><ul>
<li class="chapter" data-level="87.2.1" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html#邏輯回歸模型中回歸系數的含義"><i class="fa fa-check"></i><b>87.2.1</b> 　邏輯回歸模型中回歸系數的含義</a></li>
<li class="chapter" data-level="87.2.2" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html#低出生體重數據-1"><i class="fa fa-check"></i><b>87.2.2</b> 低出生體重數據</a></li>
</ul></li>
<li class="chapter" data-level="87.3" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html#貝葉斯泊鬆回歸-bayesian-poisson-regression"><i class="fa fa-check"></i><b>87.3</b> 貝葉斯泊鬆回歸 Bayesian Poisson Regression</a></li>
<li class="chapter" data-level="87.4" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html#glm-in-a-bayesian-way"><i class="fa fa-check"></i><b>87.4</b> GLM in a Bayesian way</a></li>
<li class="chapter" data-level="87.5" data-path="貝葉斯廣義線性回歸.html"><a href="貝葉斯廣義線性回歸.html#Bayesian-practical07"><i class="fa fa-check"></i><b>87.5</b> Practical Bayesian Statistics 07</a></li>
</ul></li>
<li class="chapter" data-level="88" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html"><i class="fa fa-check"></i><b>88</b> 貝葉斯等級回歸模型</a><ul>
<li class="chapter" data-level="88.1" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#關於等級迴歸模型"><i class="fa fa-check"></i><b>88.1</b> 關於等級迴歸模型</a></li>
<li class="chapter" data-level="88.2" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#多層數據在模型中可能要用到的前提條件"><i class="fa fa-check"></i><b>88.2</b> 多層數據在模型中可能要用到的前提條件</a><ul>
<li class="chapter" data-level="88.2.1" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#參數是相同的-identical-parameters"><i class="fa fa-check"></i><b>88.2.1</b> 參數是相同的 (identical parameters)</a></li>
<li class="chapter" data-level="88.2.2" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#參數是獨立的-independent-parameters"><i class="fa fa-check"></i><b>88.2.2</b> 參數是獨立的 (independent parameters)</a></li>
<li class="chapter" data-level="88.2.3" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#參數是可交換的-exchangeable-parameters"><i class="fa fa-check"></i><b>88.2.3</b> 參數是可交換的 (exchangeable parameters)</a></li>
</ul></li>
<li class="chapter" data-level="88.3" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#抗抑鬱臨牀試驗實例"><i class="fa fa-check"></i><b>88.3</b> 抗抑鬱臨牀試驗實例</a><ul>
<li class="chapter" data-level="88.3.1" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#縱向數據"><i class="fa fa-check"></i><b>88.3.1</b> 縱向數據</a></li>
<li class="chapter" data-level="88.3.2" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#hamd-example"><i class="fa fa-check"></i><b>88.3.2</b> HAMD example</a></li>
<li class="chapter" data-level="88.3.3" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#貝葉斯簡單線性迴歸模型"><i class="fa fa-check"></i><b>88.3.3</b> 貝葉斯簡單線性迴歸模型</a></li>
<li class="chapter" data-level="88.3.4" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#貝葉斯等級線性回歸隨機截距模型"><i class="fa fa-check"></i><b>88.3.4</b> 貝葉斯等級線性回歸–隨機截距模型</a></li>
<li class="chapter" data-level="88.3.5" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#貝葉斯等級線性回歸模型隨機截距和隨機斜率模型"><i class="fa fa-check"></i><b>88.3.5</b> 貝葉斯等級線性回歸模型–隨機截距和隨機斜率模型</a></li>
<li class="chapter" data-level="88.3.6" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#hamd-數據不同模型結果的比較"><i class="fa fa-check"></i><b>88.3.6</b> HAMD 數據不同模型結果的比較</a></li>
<li class="chapter" data-level="88.3.7" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#hamd-數據實例結果的解釋"><i class="fa fa-check"></i><b>88.3.7</b> HAMD 數據實例結果的解釋</a></li>
</ul></li>
<li class="chapter" data-level="88.4" data-path="貝葉斯等級回歸模型.html"><a href="貝葉斯等級回歸模型.html#practical-bayesian-statistics-08"><i class="fa fa-check"></i><b>88.4</b> Practical Bayesian Statistics 08</a></li>
</ul></li>
<li class="chapter" data-level="89" data-path="再訪-mcmc.html"><a href="再訪-mcmc.html"><i class="fa fa-check"></i><b>89</b> 再訪 MCMC</a><ul>
<li class="chapter" data-level="89.1" data-path="再訪-mcmc.html"><a href="再訪-mcmc.html#metropolis-hastings-algorithm"><i class="fa fa-check"></i><b>89.1</b> Metropolis-Hastings algorithm</a></li>
<li class="chapter" data-level="89.2" data-path="再訪-mcmc.html"><a href="再訪-mcmc.html#適應階段-adaptive-phase"><i class="fa fa-check"></i><b>89.2</b> 適應階段 adaptive phase</a></li>
</ul></li>
<li class="chapter" data-level="90" data-path="貝葉斯和概率論的比較.html"><a href="貝葉斯和概率論的比較.html"><i class="fa fa-check"></i><b>90</b> 貝葉斯和概率論的比較</a><ul>
<li class="chapter" data-level="90.1" data-path="貝葉斯和概率論的比較.html"><a href="貝葉斯和概率論的比較.html#兩種方法的不同點總覽"><i class="fa fa-check"></i><b>90.1</b> 兩種方法的不同點總覽</a></li>
<li class="chapter" data-level="90.2" data-path="貝葉斯和概率論的比較.html"><a href="貝葉斯和概率論的比較.html#亞組分析-subgroup-analysis"><i class="fa fa-check"></i><b>90.2</b> 亞組分析 subgroup analysis</a></li>
<li class="chapter" data-level="90.3" data-path="貝葉斯和概率論的比較.html"><a href="貝葉斯和概率論的比較.html#多重比較問題-multiple-comparisons"><i class="fa fa-check"></i><b>90.3</b> 多重比較問題 multiple comparisons</a></li>
</ul></li>
<li class="part"><span><b>XII 因果推斷 Causal Inference</b></span></li>
<li class="chapter" data-level="91" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html"><i class="fa fa-check"></i><b>91</b> Causal Languages 因果推斷的語法</a><ul>
<li class="chapter" data-level="91.1" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#當我們在談論因果推斷的時候我們在談論什麼"><i class="fa fa-check"></i><b>91.1</b> 當我們在談論因果推斷的時候，我們在談論什麼？</a></li>
<li class="chapter" data-level="91.2" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#傳統的統計學方法"><i class="fa fa-check"></i><b>91.2</b> 傳統的統計學方法</a><ul>
<li class="chapter" data-level="91.2.1" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#初步分析"><i class="fa fa-check"></i><b>91.2.1</b> 初步分析</a></li>
<li class="chapter" data-level="91.2.2" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#混雜"><i class="fa fa-check"></i><b>91.2.2</b> 混雜</a></li>
<li class="chapter" data-level="91.2.3" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#以共變量爲條件-conditioning-on-covariates"><i class="fa fa-check"></i><b>91.2.3</b> 以共變量爲條件 conditioning on covariates</a></li>
</ul></li>
<li class="chapter" data-level="91.3" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#更加正規的方法"><i class="fa fa-check"></i><b>91.3</b> 更加正規的方法</a><ul>
<li class="chapter" data-level="91.3.1" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#因果推斷使用的語言"><i class="fa fa-check"></i><b>91.3.1</b> 因果推斷使用的語言</a></li>
<li class="chapter" data-level="91.3.2" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#因果推斷的被估計量-causal-estimands"><i class="fa fa-check"></i><b>91.3.2</b> 因果推斷的被估計量 causal estimands</a></li>
<li class="chapter" data-level="91.3.3" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#鑑定因果推斷時的前提假設-assumptions-for-identification"><i class="fa fa-check"></i><b>91.3.3</b> 鑑定因果推斷時的前提假設 assumptions for identification</a></li>
<li class="chapter" data-level="91.3.4" data-path="causal-languages-因果推斷的語法.html"><a href="causal-languages-因果推斷的語法.html#鑑定-identification"><i class="fa fa-check"></i><b>91.3.4</b> 鑑定 identification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="92" data-path="graphical-models-因果推斷的圖形模型.html"><a href="graphical-models-因果推斷的圖形模型.html"><i class="fa fa-check"></i><b>92</b> Graphical Models 因果推斷的圖形模型</a><ul>
<li class="chapter" data-level="92.1" data-path="graphical-models-因果推斷的圖形模型.html"><a href="graphical-models-因果推斷的圖形模型.html#統計學中的有向無環圖"><i class="fa fa-check"></i><b>92.1</b> 統計學中的有向無環圖</a><ul>
<li class="chapter" data-level="92.1.1" data-path="graphical-models-因果推斷的圖形模型.html"><a href="graphical-models-因果推斷的圖形模型.html#dag-和條件獨立性-conditional-independence"><i class="fa fa-check"></i><b>92.1.1</b> DAG 和條件獨立性 conditional independence</a></li>
<li class="chapter" data-level="92.1.2" data-path="graphical-models-因果推斷的圖形模型.html"><a href="graphical-models-因果推斷的圖形模型.html#dag-圖的術語"><i class="fa fa-check"></i><b>92.1.2</b> DAG 圖的術語</a></li>
<li class="chapter" data-level="92.1.3" data-path="graphical-models-因果推斷的圖形模型.html"><a href="graphical-models-因果推斷的圖形模型.html#阻斷通路-blocking-paths"><i class="fa fa-check"></i><b>92.1.3</b> 阻斷通路 blocking paths</a></li>
<li class="chapter" data-level="92.1.4" data-path="graphical-models-因果推斷的圖形模型.html"><a href="graphical-models-因果推斷的圖形模型.html#以對撞因子爲條件-conditioning-on-a-collider"><i class="fa fa-check"></i><b>92.1.4</b> 以對撞因子爲條件 conditioning on a collider</a></li>
</ul></li>
<li class="chapter" data-level="92.2" data-path="graphical-models-因果推斷的圖形模型.html"><a href="graphical-models-因果推斷的圖形模型.html#以非對撞爲條件-conditioning-on-a-non-collider"><i class="fa fa-check"></i><b>92.2</b> 以非對撞爲條件 conditioning on a non-collider</a><ul>
<li class="chapter" data-level="92.2.1" data-path="graphical-models-因果推斷的圖形模型.html"><a href="graphical-models-因果推斷的圖形模型.html#條件的總結"><i class="fa fa-check"></i><b>92.2.1</b> 條件的總結</a></li>
<li class="chapter" data-level="92.2.2" data-path="graphical-models-因果推斷的圖形模型.html"><a href="graphical-models-因果推斷的圖形模型.html#d-分離-d-separation"><i class="fa fa-check"></i><b>92.2.2</b> D 分離 d-separation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="93" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><i class="fa fa-check"></i><b>93</b> Regression Methods with continuous outcomes 結果變量爲連續型變量</a><ul>
<li class="chapter" data-level="93.1" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#用於對連續型結果變量做因果推斷的被估計量"><i class="fa fa-check"></i><b>93.1</b> 用於對連續型結果變量做因果推斷的被估計量</a></li>
<li class="chapter" data-level="93.2" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#鑑定-identification---revision"><i class="fa fa-check"></i><b>93.2</b> 鑑定 identification - revision</a><ul>
<li class="chapter" data-level="93.2.1" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#條件因果均差-conditional-causal-mean-difference"><i class="fa fa-check"></i><b>93.2.1</b> 條件因果均差 conditional causal mean difference</a></li>
<li class="chapter" data-level="93.2.2" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#簡單分類型條件變量-c-的-ace"><i class="fa fa-check"></i><b>93.2.2</b> 簡單分類型條件變量 <span class="math inline">\(C\)</span> 的 ACE</a></li>
<li class="chapter" data-level="93.2.3" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#簡單連續型條件變量-c-的ace"><i class="fa fa-check"></i><b>93.2.3</b> 簡單連續型條件變量 <span class="math inline">\(C\)</span> 的ACE</a></li>
</ul></li>
<li class="chapter" data-level="93.3" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#通過線性回歸模型來估計-ace"><i class="fa fa-check"></i><b>93.3</b> 通過線性回歸模型來估計 ACE</a><ul>
<li class="chapter" data-level="93.3.1" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#條件因果均值差"><i class="fa fa-check"></i><b>93.3.1</b> 條件因果均值差</a></li>
<li class="chapter" data-level="93.3.2" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#效應修正-effect-modification-和-交互作用-interaction"><i class="fa fa-check"></i><b>93.3.2</b> 效應修正 effect modification 和 交互作用 interaction</a></li>
<li class="chapter" data-level="93.3.3" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#分類型條件變量的平均因果效應-ace"><i class="fa fa-check"></i><b>93.3.3</b> 分類型條件變量的平均因果效應 (ACE)</a></li>
<li class="chapter" data-level="93.3.4" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#positivity-非零性"><i class="fa fa-check"></i><b>93.3.4</b> Positivity 非零性</a></li>
<li class="chapter" data-level="93.3.5" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#連續型變量的平均因果效應"><i class="fa fa-check"></i><b>93.3.5</b> 連續型變量的平均因果效應</a></li>
</ul></li>
<li class="chapter" data-level="93.4" data-path="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html"><a href="regression-methods-with-continuous-outcomes-結果變量爲連續型變量.html#practical03---causal-inference"><i class="fa fa-check"></i><b>93.4</b> Practical03 - causal inference</a></li>
</ul></li>
<li class="chapter" data-level="94" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><i class="fa fa-check"></i><b>94</b> Regression Methods with binary outcomes 結果變量爲二分類變量</a><ul>
<li class="chapter" data-level="94.1" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#二分類結果變量的因果被估計量-causal-estimand"><i class="fa fa-check"></i><b>94.1</b> 二分類結果變量的因果被估計量 (causal estimand):</a><ul>
<li class="chapter" data-level="94.1.1" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#比值比的不可壓縮性-non-collapsibility-of-the-odds-ratio"><i class="fa fa-check"></i><b>94.1.1</b> 比值比的不可壓縮性 non-collapsibility of the odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="94.2" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#鑑定-identification---conditional-effects"><i class="fa fa-check"></i><b>94.2</b> 鑑定 identification - conditional effects</a></li>
<li class="chapter" data-level="94.3" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#鑑定-identification---marginal-effects"><i class="fa fa-check"></i><b>94.3</b> 鑑定 identification - marginal effects</a><ul>
<li class="chapter" data-level="94.3.1" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#marginal-causal-risk-difference-ace"><i class="fa fa-check"></i><b>94.3.1</b> Marginal causal risk difference (ACE)</a></li>
<li class="chapter" data-level="94.3.2" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#marginal-causal-log-risk-ratio"><i class="fa fa-check"></i><b>94.3.2</b> Marginal causal log risk ratio</a></li>
</ul></li>
<li class="chapter" data-level="94.4" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#通過邏輯回歸估計這些被估計量"><i class="fa fa-check"></i><b>94.4</b> 通過邏輯回歸估計這些被估計量</a></li>
<li class="chapter" data-level="94.5" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#average-causaltreatment-effect-in-the-exposedtreated-atet"><i class="fa fa-check"></i><b>94.5</b> Average causal/treatment effect in the exposed/treated (ATET)</a></li>
<li class="chapter" data-level="94.6" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#practical04---causal-inference"><i class="fa fa-check"></i><b>94.6</b> Practical04 - causal inference</a><ul>
<li class="chapter" data-level="94.6.1" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#在stata裡打開數據初步分析和熟悉數據"><i class="fa fa-check"></i><b>94.6.1</b> 在STATA裡打開數據，初步分析和熟悉數據</a></li>
<li class="chapter" data-level="94.6.2" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#用標準邏輯回歸模型分析-rfa-暴露-和-dodp-結果-之間的關係"><i class="fa fa-check"></i><b>94.6.2</b> 用標準邏輯回歸模型分析 <code>rfa</code> (暴露) 和 <code>dodp</code> (結果) 之間的關係</a></li>
<li class="chapter" data-level="94.6.3" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#比較上面a和b兩個邏輯回歸模型的結果你認為混雜因素對暴露和結果的關係的影響是怎樣的"><i class="fa fa-check"></i><b>94.6.3</b> 比較上面(a)和(b)兩個邏輯回歸模型的結果，你認為混雜因素對暴露和結果的關係的影響是怎樣的？</a></li>
<li class="chapter" data-level="94.6.4" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#在怎樣的前提假設條件下上面模型-b-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>94.6.4</b> 在怎樣的前提假設條件下，上面模型 (b) 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="94.6.5" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#在前面提出的所有前提假設都滿足的情況下請給模型-b-的回歸係數賦予一個因果效應的解釋"><i class="fa fa-check"></i><b>94.6.5</b> 在前面提出的所有前提假設都滿足的情況下，請給模型 (b) 的回歸係數賦予一個因果效應的解釋。</a></li>
<li class="chapter" data-level="94.6.6" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#用-stata-的-teffects-ra-擬合上面兩個模型"><i class="fa fa-check"></i><b>94.6.6</b> 用 STATA 的 <code>teffects ra</code> 擬合上面兩個模型</a></li>
<li class="chapter" data-level="94.6.7" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#在怎樣的假設前提條件下前一步擬合的模型-b-結果中的-ate-可以被賦予因果關係的解釋"><i class="fa fa-check"></i><b>94.6.7</b> 在怎樣的假設前提條件下，前一步擬合的模型 (b) 結果中的 ATE 可以被賦予因果關係的解釋？</a></li>
<li class="chapter" data-level="94.6.8" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答有什麼不同"><i class="fa fa-check"></i><b>94.6.8</b> 前一問和你擬合完簡單的邏輯回歸之後做的模型假設的回答，有什麼不同？</a></li>
<li class="chapter" data-level="94.6.9" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#用因果關係語言解釋-teffects-ra-擬合的模型-b-的結果"><i class="fa fa-check"></i><b>94.6.9</b> 用因果關係語言解釋 <code>teffects ra</code> 擬合的模型 (b) 的結果</a></li>
<li class="chapter" data-level="94.6.10" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#如果模型中加入-age-gender-smoke-nodules-mets-duration-primary-等和預後相關但是和決定療法並不太有關係的變量結果會有什麼不同呢"><i class="fa fa-check"></i><b>94.6.10</b> 如果模型中加入 <code>age, gender, smoke, nodules, mets, duration, primary</code> 等和預後相關但是和決定療法並不太有關係的變量，結果會有什麼不同呢？</a></li>
<li class="chapter" data-level="94.6.11" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#如果再向模型中加入和暴露變量相關和預後沒什麼關係的變量-coag結果該怎麼解讀"><i class="fa fa-check"></i><b>94.6.11</b> 如果再向模型中加入和暴露變量相關，和預後沒什麼關係的變量 <code>coag</code>，結果該怎麼解讀？</a></li>
<li class="chapter" data-level="94.6.12" data-path="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html"><a href="regression-methods-with-binary-outcomes-結果變量爲二分類變量.html#使用-atet-的選項重新擬合上面的因果效應模型解釋結果發生的變化並作出相應的結論"><i class="fa fa-check"></i><b>94.6.12</b> 使用 <code>atet</code> 的選項重新擬合上面的因果效應模型，解釋結果發生的變化，並作出相應的結論。</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="95" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html"><i class="fa fa-check"></i><b>95</b> Prospensity Score 傾向性評分</a><ul>
<li class="chapter" data-level="95.0.1" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#關於條件可置換性"><i class="fa fa-check"></i><b>95.0.1</b> 關於條件可置換性</a></li>
<li class="chapter" data-level="95.1" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#怎樣使用傾向性評分"><i class="fa fa-check"></i><b>95.1</b> 怎樣使用傾向性評分</a><ul>
<li class="chapter" data-level="95.1.1" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#分層法-stratification"><i class="fa fa-check"></i><b>95.1.1</b> 分層法 stratification</a></li>
<li class="chapter" data-level="95.1.2" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#配對法-matching"><i class="fa fa-check"></i><b>95.1.2</b> 配對法 matching</a></li>
<li class="chapter" data-level="95.1.3" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#回歸模型校正法-adjustment"><i class="fa fa-check"></i><b>95.1.3</b> 回歸模型校正法 adjustment</a></li>
</ul></li>
<li class="chapter" data-level="95.2" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#practical05---causal-inference"><i class="fa fa-check"></i><b>95.2</b> Practical05 - causal inference</a><ul>
<li class="chapter" data-level="95.2.1" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#初步熟悉數據內容"><i class="fa fa-check"></i><b>95.2.1</b> 初步熟悉數據內容</a></li>
<li class="chapter" data-level="95.2.2" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#把連續型變量以分類型數據的形式放入模型中"><i class="fa fa-check"></i><b>95.2.2</b> 把連續型變量以分類型數據的形式放入模型中:</a></li>
<li class="chapter" data-level="95.2.3" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#用相同的模型結構估計每個人的傾向性評分"><i class="fa fa-check"></i><b>95.2.3</b> 用相同的模型結構估計每個人的傾向性評分</a></li>
<li class="chapter" data-level="95.2.4" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#用-ps-評分來把對象分層-stratification"><i class="fa fa-check"></i><b>95.2.4</b> 用 PS 評分來把對象分層 stratification</a></li>
<li class="chapter" data-level="95.2.5" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#用配對法計算-ace"><i class="fa fa-check"></i><b>95.2.5</b> 用配對法計算 ACE</a></li>
<li class="chapter" data-level="95.2.6" data-path="prospensity-score-傾向性評分.html"><a href="prospensity-score-傾向性評分.html#模型校正-ps"><i class="fa fa-check"></i><b>95.2.6</b> 模型校正 PS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="96" data-path="inverse-probability-weighted-estimation-and-doubly-robust-methods.html"><a href="inverse-probability-weighted-estimation-and-doubly-robust-methods.html"><i class="fa fa-check"></i><b>96</b> Inverse probability weighted estimation and doubly robust methods</a></li>
<li class="chapter" data-level="97" data-path="causal-mediation-analysis.html"><a href="causal-mediation-analysis.html"><i class="fa fa-check"></i><b>97</b> Causal mediation analysis</a></li>
<li class="part"><span><b>XIII Statistical Methods in Epidemiology</b></span></li>
<li class="chapter" data-level="98" data-path="crude-and-stratified-rate-ratios.html"><a href="crude-and-stratified-rate-ratios.html"><i class="fa fa-check"></i><b>98</b> Crude and stratified rate ratios</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>参考文献</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">本书由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">醫學統計學</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="MCMC-methods" class="section level1">
<h1><span class="header-section-number">第 84 章</span> 馬爾可夫鏈蒙特卡羅MCMC，圖形模型，BUGS語言</h1>
<div id="markov-chain-monte-carlo-馬爾可夫鏈蒙特卡羅算法" class="section level2">
<h2><span class="header-section-number">84.1</span> Markov Chain Monte Carlo 馬爾可夫鏈蒙特卡羅算法</h2>
<div id="爲什麼我們需要用計算機模擬算法simulation-methods來進行貝葉斯統計推斷" class="section level3">
<h3><span class="header-section-number">84.1.1</span> 爲什麼我們需要用計算機模擬算法(simulation methods)來進行貝葉斯統計推斷？</h3>
<p>貝葉斯統計推斷是圍繞着事後概率分佈進行的:</p>
<p><span class="math display">\[
p(\mathbf{\theta}|x) \propto p(x|\mathbf{\theta})\times p(\mathbf{\theta})
\]</span></p>
<p>其中，<span class="math inline">\(\mathbf{\theta}\)</span> 常常是一個很長的參數向量(vector of parameters) <span class="math inline">\(\mathbf{\theta} = \{ \theta_1, \theta_2, \dots, \theta_k \}\)</span>，其中似然<span class="math inline">\(p(x|\mathbf{\theta})\)</span>和先驗概率分佈<span class="math inline">\(p(\mathbf{\theta})\)</span>一般都能找到相應的計算式，或者叫做<strong>閉合解形式(closed form)</strong>。可惜事後概率分佈 <span class="math inline">\(p(\mathbf{\theta}|x)\)</span>就沒有這麼幸運，你會常常碰見<strong>無法在數學上獲得解析解的情況(analytically untractable)</strong>。</p>
<p>此時，我們又希望能夠獲得</p>
<ul>
<li>某個或者某些參數的事後概率分布 <span class="math inline">\(p(\theta_i | x) = \int\int\dots\int p(\mathbf{\theta}|x)d\mathbf{\theta_{(-i)}}\)</span> (where <span class="math inline">\(\mathbf{\theta_{(-i)}}\)</span> denotes the vector of <span class="math inline">\(\theta\)</span>s excluding <span class="math inline">\(\theta_i\)</span>)。</li>
<li>計算某個或者某些參數的事後概率分布的數學性質，特徵值如均值 <span class="math inline">\(= \int\theta_i p(\theta_i | x)d\theta_i\)</span>，或者尾部的概率面積(tail areas) <span class="math inline">\(=\int_T^\infty p(\theta_i |x)d\theta_i\)</span>等等。</li>
</ul>
<p>我們無法獲得解析解 (analytical solution/closed solution) 的情況下，可以求助於數學上的數值解 (numerical solution/intergration)。</p>
<p>第二章 (<a href="MC-estimation.html#MC-estimation">82</a>) 我們已經見識過了蒙特卡羅模擬法可以用來從先驗概率分布，或者從<strong>閉合解形式(closed form)</strong>的事後概率分布中採樣計算的過程。如果我們可以把人類不可能完成的任務，也交給計算機來對無法獲取閉合解的事後概率分布做蒙特卡羅樣本採集的話，那麼貝葉斯統計學推斷就可以被推廣到幾乎任何一種模型，任何一種試驗設計中。</p>
<p>所以，我們的目的是希望從無法獲得閉合解形式的多維(多變量)事後概率分布<span class="math inline">\(p(\mathbf{\theta}|x)\)</span>中採集樣本做計算機模擬實驗(simulation)。但是，現實中從這樣的事後概率分布中採集<strong>相互獨立(independent)</strong>的樣本，是不容易的一件事。反其道行之，科學家發現，從事後概率分布<strong>有依賴性的馬爾可夫鏈式樣本採集(dependent sampling from a Markov chain)</strong>，作爲一種穩態分布(stationary/equilibrium distribution)卻相對容易。</p>
<p>一連串的隨機變量 <span class="math inline">\(\theta^{(0)},\theta^{(1)},\theta^{(2)},\cdots\)</span> 形成的<a href="https://en.wikipedia.org/wiki/Markov_chain">馬爾可夫鏈</a>，其重點在於 <span class="math inline">\(\theta^{(i + 1)} \sim p(\theta|\theta^{(i)}\)</span>，也就是在 <span class="math inline">\(\theta^{(i)}\)</span> 的條件下 <span class="math inline">\(\theta^{(i+1)}\)</span> 和它之前的樣本 <span class="math inline">\(\theta^{(i - 1)},\cdots,\theta^{(0)}\)</span>是獨立的。這樣的馬爾科夫鏈式採樣，需要特殊的方法來進行。<a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm">美特羅波利斯-海斯廷斯(Metroplis-Hastings)算法(algorithm)</a>是其中的一種。而<a href="https://en.wikipedia.org/wiki/Gibbs_sampling">吉布斯(Gibbs)採樣法</a>是 Metropolis-Hastings 算法的一種特殊形態。吉布斯採樣法是從<strong>全條件分布(full conditional distributions)</strong>中產生一串馬爾科夫鏈的算法。我們下面來看看吉布斯採樣法的特徵和使用方法，其詳細的算法我們過後再來討論。</p>
</div>
<div id="Gibbs-sampling" class="section level3">
<h3><span class="header-section-number">84.1.2</span> 吉布斯採樣</h3>
<p>假設，現在我們在給定了數據 <span class="math inline">\(x\)</span> 之後，我們需要在關於它的一個未知參數的向量中<span class="math inline">\(\mathbf{\theta} = (\theta_1, \theta_2, \dots,\theta_k)\)</span>採集事後概率分布樣本。那麼吉布斯採樣法的具體過程描述如下：</p>
<ol style="list-style-type: decimal">
<li>把未知參數向量分成不同的成分，最簡單的就是每個元素爲一個部分 <span class="math inline">\(\mathbf{\theta} = (\theta_1, \theta_2, \dots,\theta_k)\)</span>；</li>
<li>給每個部分/參數選取一個起始值(starting/initial values) <span class="math inline">\(\theta_1^{(0)},\theta_2^{(0)},\dots,\theta_k^{(0)}\)</span>；</li>
<li>然後:<br>從<span class="math inline">\(p(\theta_1|\theta_2^{(0)},\theta_3^{(0)},\dots,\theta_k^{(0)},x)\)</span>中採集 <span class="math inline">\(\theta_1^{(1)}\)</span><br>從<span class="math inline">\(p(\theta_2|\theta_1^{(1)},\theta_3^{(0)},\dots,\theta_k^{(0)},x)\)</span>中採集<span class="math inline">\(\theta_2^{(1)}\)</span><br><span class="math inline">\(\vdots\)</span><br>從<span class="math inline">\(p(\theta_k|\theta_1^{(1)},\theta_2^{(1)},\dots,\theta_{k-1}^{(0)},x)\)</span>中採集<span class="math inline">\(\theta_k^{(1)}\)</span></li>
<li>重復第3步 <span class="math inline">\(N\)</span> 次，我們就可以獲得一串參數的事後分布樣本 <span class="math inline">\(\mathbf{\theta}^{(0)},\mathbf{\theta}^{(1)},\dots,\mathbf{\theta}^{(N)}\)</span>。當 <span class="math inline">\(N\rightarrow\infty\)</span> 我們就獲得了多維事後概率分布的一個樣本 <span class="math inline">\(p(\mathbf{\theta}|x)\)</span>。</li>
</ol>
<p>用只有兩個位置參數的向量來解釋就是：<span class="math inline">\(k = 2, \text{ i.e. } \mathbf{\theta} = (\theta_1, \theta_2)\)</span>。下圖 <a href="MCMC-methods.html#fig:gibbssampling">84.1</a> 展示了對兩個未知參數進行吉布斯採樣的一個過程：當我們先設定一組起始值 <span class="math inline">\(\mathbf{\theta}^{(0)}\)</span>，之後從<span class="math inline">\(p(\theta_1|\theta_2^{(0)}, x)\)</span>中採集<span class="math inline">\(\theta_1^{(1)}\)</span>，然後再從 <span class="math inline">\(p(\theta_2|\theta_1^{(1)}, x)\)</span>中採集<span class="math inline">\(\theta_2^{(1)}\)</span>，這樣就獲得了樣本 <span class="math inline">\(\mathbf{\theta}^{(1)}\)</span>。然後再重復相同搞得過程採集接下來的參數樣本。</p>
<div class="figure" style="text-align: center"><span id="fig:gibbssampling"></span>
<img src="img/gibbs_sampling.png" alt="Gibbs sampling with k = 2." width="80%" />
<p class="caption">
圖 84.1: Gibbs sampling with k = 2.
</p>
</div>
<p>利用馬爾科夫鏈的性質，可以被證明的是當採樣達到無窮大 <span class="math inline">\(N\rightarrow\infty\)</span>，無論起始樣本 <span class="math inline">\((\theta_1^{(0)},\theta_2^{(0)},\dots,\theta_k^{(0)})\)</span> 如何採樣，最終產生的事後概率樣本 <span class="math inline">\(\mathbf{\theta}^{(0)},\mathbf{\theta}^{(1)},\dots,\mathbf{\theta}^{(N)}\)</span> 將會收斂成爲真實的事後概率分布 <span class="math inline">\(p(\mathbf{\theta}|y)\)</span>，所以確保了重復這個過程的次數是無窮大時，起初的一部分采样，<span class="math inline">\(N_0\)</span>可作爲初始樣本，並且因爲通常一開始的採樣過程是不穩定的，而把他們從總體事後概率分布樣本中刨除，這個過程被叫做 burn in。最終可獲得樣本量爲 <span class="math inline">\(N-N_0\)</span> 的事後概率分布樣本。</p>
<p>我们需要指出的是，這一採集事後概率分布樣本的方法之所以有用，是因爲條件事後概率分布(conditional posterior sampling)的採集，要比全事後概率分布(full posterior sampling)的採集要容易得多。否則，我們爲啥不直接從全事後概率分布中採樣呢。</p>
<p>簡單地說，比如我們需要同時對正態分布數據似然的均值，和方差兩個未知參數進行事後概率分布樣本的採集，兩個未知參數的事後概率分布需要用到復雜的微積分推導過程，但是我們知道已知均值時方差的事後概率分布，或者是已知方差時均值的事後概率分布，它們都比兩個未知參數時的計算和推導要簡單明了得多。</p>
<p>接下來我們來討論一下使用MCMC在貝葉斯統計學推斷中的實際應用和一些技巧。</p>
</div>
<div id="初始值-initial-values" class="section level3">
<h3><span class="header-section-number">84.1.3</span> 初始值 initial values</h3>
<p>MCMC過程需要對所有的未知參數先給出起始值(initial/starting values)。我們在使用BUGS進行貝葉斯統計學推斷時，可以利用先驗概率分布對各個未知參數隨機產生各自的起始值，但是這要建立在先驗概率分布是含有有價值的信息的前提下(informative priors)，如果我們只有一些聊勝於無的先驗概率分布(vague priors)，隨機從這樣的分布中產生起始值的話，很可能導致計算機選取很不恰當的起始值使得模型需要花很長的時間才能收斂，有些時候甚至導致計算機崩潰。這時候，統計學家的經驗是我們最好人爲地給模型中的未知參數設定幾個“合理”的起始值(separate reasonable initial values lists)，以防止不收斂或者計算機崩潰的情況出現。同時，我們也發現用戶如果給模型提供合理的起始值，也有助於鑑別模型收斂(convergence checking)。</p>
<p>在 BUGS 語言中，起始值可以直接寫在模型中，也可以寫在另外一個獨立的文件裏。需要明確指出的是，這些起始值是用來輔助 MCMC 採樣的，<strong>起始值並不是先验概率(initial values are not priors)</strong>。</p>
</div>
</div>
<div id="使用-mcmc-時需要考慮的一些問題" class="section level2">
<h2><span class="header-section-number">84.2</span> 使用 MCMC 時需要考慮的一些問題</h2>
<p>在使用 MCMC 時有兩個主要的問題需要我們思考：</p>
<ol style="list-style-type: decimal">
<li>收斂時間：MCMC採集的樣本 <span class="math inline">\(\{\mathbf{\theta}^{(t)}\}\)</span>，需要多久時間能夠到達或者接近事後概率分布 <span class="math inline">\(p(\mathbf{\theta}|x)\)</span>。</li>
<li>效率：從採集的樣本 <span class="math inline">\(\mathbf{\theta}^{(t)}\)</span> 中估計的參數是否在事後概率分布 <span class="math inline">\(p(\mathbf{\theta}|x)\)</span> 中真的有效 (how well are functionals of <span class="math inline">\(p(\mathbf{\theta}|x)\)</span> estimated from <span class="math inline">\(\{\mathbf{\theta}^{(t)}\}\)</span>)。</li>
</ol>
<div id="收斂時間" class="section level3">
<h3><span class="header-section-number">84.2.1</span> 收斂時間</h3>
<p>收斂時間，是我們關心的最主要的問題之一，我們在進行 MCMC 時要花多長時間才能使採集的樣本達到或者接近(數學上叫做收斂)真是的事後概率分布呢？換句話說，我們需要從採集的樣本中刨除掉多少一開始採集的不穩定的樣本呢(how do we know the number of “burn-in” iterations)？可以說沒有人能準確地給出一個答案。所以在檢查MCMC採樣是否收斂時，我們需要格外的小心。很多時候，沒有人能夠給出100%確定的答案說一條MCMC鏈達到了收斂，但是幸運地是，我們能準確地判斷沒有成功收斂的 MCMC 鏈。</p>
<p>檢查MCMC是否收斂，最常用的方法是視覺檢查，作出MCMC鏈式圖來輔助我們診斷。我們建議，使用多個不同的起始值，產生多個不同的 MCMC 樣本鏈來輔助診斷。當然，除了視覺診斷，另外還存在一些比較鏈內(within)和鏈間(between)方差的方法來進行收斂診斷的手段。但是，沒有哪種方法是萬無一失的。在 R 裏面，有一個很強大的包 <a href="https://cran.r-project.org/doc/Rnews/Rnews_2006-1.pdf#page=7"><code>coda</code></a>，它被設計來把OpenBUGS的輸出結果 (output) 轉變成爲輸入對象 (input object)，利用R來便利地進行模型分析和診斷。許多對模型收斂程度的診斷，都會認爲未知參數的起始值是相對事後概率分布來說過度離散的。所以，建議在提供起始值的時候，每一個未知參數的起始值，都盡量爲每一個MCMC鏈給出幾個<strong>“合理”但差異較大(plausible but widely differing initial values)</strong>的起始值。</p>
<p>評估MCMC的收斂與否，一個比較實用的手段是雙保險的方法: 就是既從圖形視覺上來診斷產生的MCMC樣本鏈的收斂程度，也通過統計檢驗方法對收斂作收斂與否的統計學分析。當某些模型含有衆多的未知的參數的時候，你想對每一個未知參數的事後概率分佈的MCMC採樣是否收斂進行分析和檢驗可能是不太實際的，此時的常見手段是隨機選取衆多未知參數中幾個來分析其MCMC採樣結果的收斂與否。</p>
<p>我們的選擇包括：</p>
<ul>
<li>把MCMC事後概率分布採樣過程的整個歷史(history)痕跡(trace)全部繪制出來-不同起始值的同一個未知參數的MCMC鏈是否都給出了相對穩定的歷史痕跡？他們是否有合理的相互重疊(overlapping)？</li>
<li>檢查自我相關程度(autocorrelation)-過高的自相關暗示收斂過程較慢。(high autocorrelation is a symtom of slow convergence)。</li>
<li>看Gelman-Rubin收斂統計量-它通過比較MCMC鏈內方差(within variability)和鏈間方差(between variability)來評估MCMC鏈是否達到收斂。</li>
</ul>
<div id="視覺檢驗方法" class="section level4">
<h4><span class="header-section-number">84.2.1.1</span> 視覺檢驗方法</h4>
<p>視覺檢驗方法是一種十分有效的輔助鑑別MCMC樣本鏈是否收斂的手段。常用的方法是使用幾個不同，且合理的起始值進行MCMC採樣運算，看他們是否最終都收斂到相同的位置。通常我們會把採集的 <span class="math inline">\(\theta^{(i)}\)</span> 樣本和 <span class="math inline">\(i\)</span> (也就是採樣次數) 做圖，如果順利達到收斂，圖形應該顯示爲隨機出現在一條直線上下附近的散點圖。</p>
<p>在BUGS軟件裏，通常有兩種方法可以供用戶查看未知參數的MCMC樣本鏈的歷史痕跡(history trace)：</p>
<ol style="list-style-type: decimal">
<li>實時觀察MCMC樣本採集的歷史痕跡。 (只能在windows下進行，需要用到OpenBUGS的窗口)</li>
<li>MCMC樣本採集結束以後把採集的未知參數事後樣本的歷史痕跡一次性全部繪制出來。</li>
</ol>
<p>繪制歷史痕跡時用不同顏色來表示不同起始值的MCMC鏈會更加有助於我們在圖形上識別出MCMC鏈是否分別都達到了令人滿意的模型收斂，互相的重疊程度也能一目了然。</p>
<p>至於(Brooks-)Gelman-Rubin (BGR)診斷收斂統計量，它的使用前提是必須使用合理且差異較大的不同起始值（至少兩個）。</p>
</div>
</div>
<div id="模型效率-efficiency-of-mcmc" class="section level3">
<h3><span class="header-section-number">84.2.2</span> 模型效率 efficiency of MCMC</h3>
<p>一旦你認爲MCMC採集的樣本鏈已經達到收斂於事後概率分布。接下來要做的是繼續MCMC樣本採集，採集的事後概率分布樣本越多，事後概率推斷就越精確。通常一個表現良好的事後概率分布，我們的經驗是4000個左右的獨立樣本產生的95%可信區間能夠給出94%-96%實際的事後概率分布(actual posterior probability) <span class="citation">(Raftery and Lewis <a href="#ref-Raftery92howmany">1992</a>)</span>。但是實際上MCMC採集的樣本鏈是高度自相關的(autocorrelated)，因此實際有效的樣本量會少於真實的樣本量。(effective sample size &lt; actual sample size)</p>
<p>計算事後概率分布對未知參數的估計的精確度的方法之一，是給每一個未知參數計算蒙特卡羅標準誤(Monte Carlo standard error)。它是對MCMC樣本參數均值和真實事後均值之間差的估計(estimate of the difference between the mean of the sampled values, which we are using as our estimate of the posterior mean for each parameter, and the true posterior mean.)。</p>
<p>MCSE (Monte Carlo Standard Error) 等於未知參數的事後樣本均值的標準誤。此時，事後樣本均值被當做是事後期望值的理論取值的一個估計 (an estimate of the theoretical posterior expectation) <span class="math inline">\(E(\theta|y)\)</span>。</p>
<p>如果採集的樣本是相互獨立的，那麼<span class="math inline">\(\text{MCSE}^{ind} = \frac{s}{\sqrt{N}}\)</span> 其中，<span class="math inline">\(s = \text{posterior SD}\)</span> 參數<span class="math inline">\(\theta\)</span>的事後樣本標準差，<span class="math inline">\(N\)</span> 是採集的事後樣本的樣本量。但是我們真正能採集到的樣本是自相關樣本(autocorrelated samples)，自相關樣本的<span class="math inline">\(\text{MCSE}^{ac} &gt; \text{MCSE}^{ind}\)</span>。</p>
<p>一個有自相關的MCMC鏈的<strong>有效樣本量 (effective sample size)</strong><span class="math inline">\(N^*\)</span>可以這樣估計：</p>
<p><span class="math display">\[
N^* = (\frac{s}{\text{MCSE}^{ac}})^2
\]</span></p>
<p>所以，如果：</p>
<ul>
<li><span class="math inline">\(\text{MCSE}^{ac} \approx 0.05s \Rightarrow N^* \approx 1/0.05^2 = 400\)</span>;</li>
<li><span class="math inline">\(\text{MCSE}^{ac} \approx 0.015s \Rightarrow N^* \approx 1/0.015^2 = 4444\)</span>;</li>
<li><span class="math inline">\(\text{MCSE}^{ac} \approx 0.01s \Rightarrow N^* \approx 1/0.01^2 = 10000\)</span>;</li>
</ul>
<p>由事後樣本的標準差和蒙特卡羅標準誤之間的關系可見，基本上MCMC鏈達到收斂以後，你需要重復MCMC採樣的次數，也就是採集的事後分布樣本量的大小要使得蒙特卡羅標準誤小於事後樣本標準差的1/100才能基本滿足要求。未知參數的事後估計和總結也就是要建立在有效樣本量至少爲10000或更多的基礎之上。</p>
</div>
</div>
<div id="bugs-軟件" class="section level2">
<h2><span class="header-section-number">84.3</span> BUGS 軟件</h2>
<p>你完全可以另闢蹊徑在STATA或者R裏面寫下吉布斯採樣的算法，但是這並不簡單。幸好，許多軟件已經能夠幫助我們規避掉寫吉布斯採樣算法這一複雜的過程。</p>
<p>BUGS全稱是 <strong>B</strong>ayesian inference <strong>U</strong>sing <strong>G</strong>ibbs <strong>S</strong>ampling。它是用來描述貝葉斯統計學模型的計算機語言。有三種流行的統計學軟件都使用BUGS語言來描述貝葉斯統計學模型，他們分別是 WinBUGS，OpenBUGS，和 JAGS。他們的語法十分接近R的語法，甚至可以直接在R的環境下運行(正如我這本書中在R裏連接OpenBUGS運算貝葉斯統計推斷一樣)。</p>
<p>WinBUGS 1.4.3是一個穩定的貝葉斯統計學軟件，但是它已經不再更新，也沒有再跟進開發。也正如其名字暗示的那樣，它能且只能運行在瘟倒死(windows)機器上。你可以從它的網站上下載並免費使用之: <a href="https://www.mrc-bsu.cam.ac.uk/software/bugs/the-bugs-project-winbugs/" class="uri">https://www.mrc-bsu.cam.ac.uk/software/bugs/the-bugs-project-winbugs/</a>。</p>
<p>OpenBUGS是開源的，且能夠在Linux機器上無縫運行。它也有自己的GUI(只有在瘟倒死上才有的功能)，讓你實現用鼠標點擊也能完成貝葉斯統計學分析。它的主要網站是<a href="http://www.openbugs.net/w/Downloads" class="uri">http://www.openbugs.net/w/Downloads</a>。</p>
<p>JAGS的全稱是 <strong>J</strong>ust <strong>A</strong>nother <strong>G</strong>ibbs <strong>S</strong>ampler，開發者是 <a href="https://martynplummer.wordpress.com/jags/">Martyn Plummer</a>。它沒有任何GUI，只能通過命令行來執行運算。</p>
<p>其他著名的軟件還有 <a href="http://mc-stan.org/">Stan</a>。它也是開源的自由軟件。</p>
</div>
<div id="圖形模型-statistical-graphical-models---directed-acyclic-graphs-dags" class="section level2">
<h2><span class="header-section-number">84.4</span> 圖形模型 statistical graphical models - Directed Acyclic Graphs (DAGs)</h2>
<p>在統計學模型中我們常常默認指定一些隨機變量之間的邏輯關系，這樣的邏輯關系可以用圖形來表示：</p>
<ul>
<li><strong>節點 nodes</strong>：用來表示變量(variables)；</li>
<li><strong>連接線 links</strong>：用來表示變量之間的邏輯依賴關系(dependence association)。</li>
</ul>
<p><strong>帶方向的連接線 (directed links)</strong>被用來表示邏輯依賴關系的方向(natural ordering of the dependence association)。 其實這連接線所帶的方向本身就是回歸模型中表示預測變量和結果變量之間的依賴關系。貝葉斯統計學中常用的有向無環圖 (directed acyclic graphs, DAGs)，是我們常用的輔助建立貝葉斯模型的示意圖。</p>
<p>例如一個描述吸煙，肥胖和心髒病發病可能的關系的的有向無環圖如下圖 <a href="MCMC-methods.html#fig:DAGS-bayesian">84.2</a>。途中帶方向的連線（箭頭）表示預測變量和結果變量之間的依賴關系。</p>
<div class="figure" style="text-align: center"><span id="fig:DAGS-bayesian"></span>
<img src="img/heartDAG.png" alt="DAG for heart disease example" width="60%" />
<p class="caption">
圖 84.2: DAG for heart disease example
</p>
</div>
<div id="條件獨立的概念-conditional-independence-concept" class="section level3">
<h3><span class="header-section-number">84.4.1</span> 條件獨立的概念 conditional independence concept</h3>
<p>在概率論入門(Chapter <a href="intro.html#intro">1</a>)中學習過獨立的概念：</p>
<p><span class="math display">\[
p(Y,X) = p(Y)p(X)
\]</span></p>
<p>我們說 <span class="math inline">\(X,Y\)</span> 以條件 <span class="math inline">\(Z\)</span> 獨立如果他們滿足：</p>
<p><span class="math display">\[
p(X,Y|Z) = p(Y|Z)p(X|Z)
\]</span></p>
<p>條件獨立的關系可以用下面的有向無環圖 <a href="MCMC-methods.html#fig:DAGS-condind">84.3</a> 來表示：</p>
<div class="figure" style="text-align: center"><span id="fig:DAGS-condind"></span>
<img src="img/conditionalindependence.png" alt="DAG for conditional independence" width="60%" />
<p class="caption">
圖 84.3: DAG for conditional independence
</p>
</div>
<p><strong>基因型例子 genotype example:</strong>如果 <span class="math inline">\(X,Y\)</span> 分別是同一個家庭中的兩個孩子的基因型，<span class="math inline">\(Z\)</span>是其父母的基因型。那麼兩個孩子之間的基因型就是以父母的基因型爲條件獨立的關系: <span class="math inline">\(p(X,Y|Z) = p(Y|Z)p(X|Z)\)</span>。如果沒有父母親基因型的條件，兩個孩子的基因型就不互相獨立，而是相關的（很顯然因爲他們是親兄弟/妹）。</p>
<p>在有向無環圖的術語中，一個變量的Parent(父/母)指的是有向連線指向該變量的最近的那個變量，反過來這個被指向的變量就被叫做Child(子)。所以如果從變量 <span class="math inline">\(\alpha\)</span> 存在指向 <span class="math inline">\(\beta\)</span> 的箭頭連線，那麼 <span class="math inline">\(\alpha\)</span> 被叫做 <span class="math inline">\(\beta\)</span> 的父/母(parent)，<span class="math inline">\(\beta\)</span> 被叫做 <span class="math inline">\(\alpha\)</span> 的子(child)。</p>
<p><strong>硬幣例子 coin example:</strong>如果一枚硬幣正面朝上或者反面朝上的概率分別是 <span class="math inline">\(p(H), p(T)\)</span>，那麼令 <span class="math inline">\(p(H) = \theta = 1 - p(T)\)</span>，如果兩次投擲硬幣試驗的結果分別是 <span class="math inline">\(X, Y\)</span>，那麼 <span class="math inline">\(X,Y\)</span> 就是以 <span class="math inline">\(\theta\)</span> 爲條件的獨立事件: <span class="math inline">\(p(X,Y|\theta) = p(Y|\theta)p(X|\theta)\)</span>。這裏的 <span class="math inline">\(\theta\)</span> 在貝葉斯統計學的環境下不是固定不變的，而是一個隨機的未知參數。</p>
<p>條件獨立是一個十分重要的概念，因爲它爲<span class="math inline">\(X,Y,Z\)</span>三個未知參數的聯合分布(joint distribution)提供了十分有用的因式分解理論依據：</p>
<p><span class="math display">\[
p(X,Y,Z)  = p(Y|Z)p(X|Z)p(Z)
\]</span></p>
<p>因爲，即使使用計算機進行模擬實驗 (simulation)，從條件分布<span class="math inline">\(p(Y|Z), p(X|Z)\)</span>中採集事後概率分布樣本，也比從 <span class="math inline">\(p(X,Y,Z)\)</span> 中直接採集樣本要容易進行得多。</p>
<p>一般地，一個含有許多個變量節點(nodes)的向量的聯合分布可以寫作：</p>
<p><span class="math display">\[
p(V) = \prod_{v\in V} p(v|\text{parents}[v])
\]</span></p>
<p>下圖<a href="MCMC-methods.html#fig:DAGS-complex">84.4</a>給出的一個較爲復雜的 DAG 模型，其實它沒有看起來那麼復雜，有了條件獨立的概念，我們可以方便地把它的聯合分布進行因式分解：</p>
<p><span class="math display">\[
p(V) = p(A)p(F)p(B|A)p(C|A)p(E|A,F)p(D|B,C)
\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:DAGS-complex"></span>
<img src="img/complexDAG.png" alt="More complex DAG for conditional independence" width="80%" />
<p class="caption">
圖 84.4: More complex DAG for conditional independence
</p>
</div>
<p>BUGS軟件也是利用這一概念來進行復雜的事後概率分布模型的計算，例如上述的模型中，</p>
<p><span class="math display">\[
p(E|A,B,C,D,F) = p(E|A,F)
\]</span></p>
</div>
</div>
<div id="bugs-language" class="section level2">
<h2><span class="header-section-number">84.5</span> BUGS language</h2>
<p>在 BUGS 軟件提供的手冊裏有對 BUGS 語言更加詳盡的介紹，這裏我們只是對其精要部分做簡單概括的介紹。</p>
<div id="節點的種類-types-of-nodes" class="section level3">
<h3><span class="header-section-number">84.5.1</span> 節點的種類 types of nodes</h3>
<p>在 BUGS 環境下，每個變量或者參數都被叫做一個節點。它主要被分爲兩類：</p>
<ul>
<li><strong>隨機節點 (stochastic nodes)：</strong>需要我們給出它們分布的描述。一個波浪線 <code>~</code> 被用來幫助我們描述這些隨機節點的分布，例如 <code>r ~ dunif(a, b)</code> 的含義就是，在區間 <span class="math inline">\([a,b]\)</span> 內，<span class="math inline">\(r\)</span>服從均一分布。</li>
<li><strong>邏輯節點 (logical nodes)：</strong>則表示的是對節點和節點之間關系的定義，它常常是一個方程，用 <code>&lt;-</code> 來輔助定義。例如，<code>m &lt;- alpha + beta*x</code> 定義的是 <span class="math inline">\(m\)</span> 和 <span class="math inline">\(alpha, beta, x\)</span> 節點之間的數學關系。</li>
</ul>
</div>
<div id="分布的標記法" class="section level3">
<h3><span class="header-section-number">84.5.2</span> 分布的標記法</h3>
<p>BUGS語言中常用的分布和其對應的標記法歸納如下:</p>
<table>
<thead>
<tr class="header">
<th align="center">Expression</th>
<th align="center">Distribution</th>
<th align="center">Usage</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><code>dbin</code></td>
<td align="center">binomial</td>
<td align="center"><code>r ~ dbin(p,n)</code></td>
</tr>
<tr class="even">
<td align="center"><code>dnorm</code></td>
<td align="center">normal</td>
<td align="center"><code>x ~ dnorm(mu, tau)</code></td>
</tr>
<tr class="odd">
<td align="center"><code>dpois</code></td>
<td align="center">Poisson</td>
<td align="center"><code>r ~ dpois(lambda)</code></td>
</tr>
<tr class="even">
<td align="center"><code>dunif</code></td>
<td align="center">uniform</td>
<td align="center"><code>x ~ dunif(a, b)</code></td>
</tr>
<tr class="odd">
<td align="center"><code>dgamma</code></td>
<td align="center">gamma</td>
<td align="center"><code>x ~ dgamma(a, b)</code></td>
</tr>
</tbody>
</table>
<p>要注意的是，這裏的正態分布的參數是均值 <code>mu</code>，和精確度 precision <code>tau</code>:</p>
<p><span class="math display">\[
\text{precision} = \frac{1}{\text{variance}} = \frac{1}{sd^2}
\]</span></p>
<p>另外，在 BUGS 語言中，我們無法在指定分布時給參數使用方程，這種時候必須做的是分步驟來寫模型：</p>
<pre><code>y ~ dnorm(mu, tau); mu &lt;- a + b*x</code></pre>
<p>不能被寫作：</p>
<pre><code>y ~ dnorm(a+b*x, tau)</code></pre>
</div>
<div id="arrays-and-loops" class="section level3">
<h3><span class="header-section-number">84.5.3</span> Arrays and loops</h3>
<p>當有些模型需要有重復執行的步驟的時候，可以使用排列 (arrays) 或者循環 (loops) 的方式來寫你的BUGS模型。例如下面的代碼用來表示在長度或者人數爲 <span class="math inline">\(m\)</span> 的數據中循環相同的步驟，其中<code>n, p, r</code>都是具有相同長度的向量：</p>
<pre><code>for (i in 1:m){ # loop over m individuals
  r[i] ~ dbin(p[i], n[i]) 
  p[i] ~ dunif(0, 1)
}</code></pre>
<p>所有被包括在大括號 <code>{}</code> 裏面的命令都跟着變量 <code>i</code> 被從 <code>1</code> 開始重復相同的步驟直至第 <code>m</code> 個對象。</p>
</div>
<div id="常用的方程" class="section level3">
<h3><span class="header-section-number">84.5.4</span> 常用的方程</h3>
<p>BUGS 建立貝葉斯模型你會常用到的方程有：</p>
<ol style="list-style-type: decimal">
<li><code>p &lt;- step(x - 0.7)</code>: 當 <span class="math inline">\(x\geqslant0.7\)</span>時<span class="math inline">\(=1\)</span>，反之 <span class="math inline">\(=0\)</span>；類似這樣的方程可以拿來監測 <code>p</code> 這個節點，如果取它的均值，我們就得到 <span class="math inline">\(x\geqslant0.7\)</span> 的概率。</li>
<li><code>p &lt;- equals(x, 0.7)</code>: 當 <span class="math inline">\(x = 0.7\)</span>時<span class="math inline">\(=1\)</span>，反之 <span class="math inline">\(=0\)</span>。</li>
<li><code>tau &lt;- 1/pow(s, 2)</code>: 這是用來給變量節點 <code>s</code> 加指數方程的命令等價於 <span class="math inline">\(\tau = \frac{1}{s^2}\)</span>。</li>
<li><code>s &lt;- 1/sqrt(tau)</code>: 等價於 <span class="math inline">\(s = \frac{1}{\sqrt{\tau}}\)</span>。</li>
</ol>
<p>在BUGS手冊的 “Model Specification/Logical nodes” 章節有更多對不同方程命令的描述。</p>
<p>一般地，方程的定義要出現在 <code>&lt;-</code> 的右邊，例如 <code>totalx &lt;- sum(x[])</code>，但是並不是全部都必須如此的，例如在廣義線性回歸模型(GLM)中，鏈接方程 (link function) 是允許出現在箭頭的左邊的：</p>
<pre><code>logit(p[i]) &lt;- a +b*x[i]
log(m[i]) &lt;- c + d*y[i]</code></pre>
<p><code>mean(p[])</code>的含義是對 <code>p</code> 的所有成分取均值，如果是 <code>mean(p[m:n])</code>，則是對數列 <code>p</code> 中成分排序在 <code>m,n</code> 之間取均值，忽略掉其前後的元素。相似的概念也適用於 <code>sum(p[])</code> 命令。</p>
</div>
</div>
<div id="爲bugs-model模型準備格式正確的數據" class="section level2">
<h2><span class="header-section-number">84.6</span> 爲BUGS model模型準備格式正確的數據</h2>
<p>OpenBUGS 只能接受格式爲 R/S-plus 的，或者是整理成形狀爲長方形的文字格式數據。例如，名叫GREAT的臨牀試驗數據中，</p>
<ul>
<li>在家中接受治療的患者人數是163，其中13例死亡；</li>
<li>在醫院內接受治療的患者人數是148，其中23例死亡。</li>
</ul>
<p>這個模型可以用循環寫作：</p>
<pre><code>for(i in 1:2){ # loop through the arms
    deaths[i] ~ dbin(p[i], n[i]) # likelihood for each arm
    p[i]  ~ dbeta(alpha, beta)  # same prior for each arm
}</code></pre>
<p>這個模型的標記中， <code>deaths[i]</code> 表示第 <span class="math inline">\(i\)</span> 組對象中死亡人數，<code>n[i]</code> 則表示第 <span class="math inline">\(i\)</span> 組實驗對象中的總人數。而 <code>p[i]</code> 則代表了第 <span class="math inline">\(i\)</span> 組對象中實驗對象死亡的概率。</p>
<p>那麼這個數據應該用怎樣的語言來描述才合理呢？</p>
<p>如果用長方形格式數據，要寫作：</p>
<pre><code>n[] deaths[]
163 13
148 23
END
</code></pre>
<p>這種格式中，第一行需要給出變量名稱，每一列是變量相對應的數據，變量名稱也必須和模型中的變量名稱相匹配。在數據最後一行則需要用<code>END</code>來結束，並且接着要有一個空行。（所以在這樣的數據格式中最後一行必須是空行）</p>
<p>R/S-plus格式的數據，我們已經很熟悉了，可以寫作：</p>
<pre><code>list(n = c(163, 148), 
     deaths = c(13, 23))</code></pre>
<p>OpenBUGS同時還允許你給模型加載多個數據文件，你如果願意的話，可以把不同格式的數據混合使用，一起加載在模型裏運算。</p>
</div>
<div id="practical-bayesian-statistics-04" class="section level2">
<h2><span class="header-section-number">84.7</span> Practical Bayesian Statistics 04</h2>
<p>這一次練習題的主要目的是，通過使用OpenBUGS來思考，它是如何從非共軛模型的事後概率分布中採集MCMC樣本的。這個過程和從共軛模型的事後概率分布中採樣有哪些不同。</p>
<p>思考前一次，第三章的課後練習題裏的(Chapter <a href="共軛先驗概率-conjugate-priors.html#BayesPrac03">83.6</a>)新藥試驗的例子。還是用這個場景，但是我們這次實施8個不同的試驗，<span class="math inline">\(i = 1,\dots,8\)</span>，其中第<span class="math inline">\(i\)</span>次試驗有 <span class="math inline">\(n_i\)</span> 名患者，其中 <span class="math inline">\(y_i\)</span> 名患者的治療被認爲有顯著療效。每次試驗中的 <span class="math inline">\(n_i\)</span> 名患者都給予相同劑量<span class="math inline">\(x_i\)</span>，但是不同於其他次試驗時的使用劑量的藥物。此時我們把注意力轉到，評估治療有效百分比 <span class="math inline">\(\theta_i\)</span>，和劑量<span class="math inline">\(x_i\)</span>之間的關系上來。</p>
<p>一種方法是，我們可以對這個數據擬合一個邏輯回歸模型，在貝葉斯統計學中，邏輯回歸模型的擬合方式如下：</p>
<p><span class="math display">\[
\begin{aligned}
y_i &amp; \sim \text{Binomial}(\theta_i, n_i) \\ 
\text{logit}(\theta_i) &amp; = \beta_0 +  \beta_1 x_i
\end{aligned}
\]</span></p>
<p>其中 <span class="math inline">\(\text{logit}\)</span> 轉換是方便地把 <span class="math inline">\(0\sim1\)</span> 之間的百分比變量轉化成爲 <span class="math inline">\(-\infty, +\infty\)</span> 變量的鏈接方程。另外，貝葉斯統計學模型中，我們需要給所有模型中出現的未知參數，提供一個先驗概率分布。在上面這個模型中，我們給有效百分比 <span class="math inline">\(\theta_i\)</span> 定義了一個回歸方程式，因此，我們需要給這個回歸方程式的回歸系數(regression coefficients)指定先驗概率分布。我們先使用模糊的，沒有太多信息的先驗概率分布，例如均一分布：</p>
<p><span class="math display">\[
\begin{aligned}
\beta_0 &amp; \sim \text{Uniform}(-100, 100)\\
\beta_1 &amp; \sim \text{Uniform}(-100, 100)
\end{aligned}
\]</span></p>
<p>1.首先，用第三章練習題中的新藥試驗模型，使用 <span class="math inline">\(\text{beta}(1, 1)\)</span> 作爲 <span class="math inline">\(\theta\)</span>的先驗概率分布（已知<span class="math inline">\(\text{beta}(1, 1)\)</span>其實等價於一個均一分布）。設定監測未知參數 <code>theta</code>，執行1000次MCMC運算之後，繪制 <code>theta</code> 的歷史痕跡。</p>
<pre><code># original conjugate drug model with uniform beta(0,1) prior on theta

model{
    theta ~ dbeta(1,1)     # prior distribution
    y     ~ dbin(theta, 20)# sampling distribution for 20 observed patients
    y    &lt;- 15
}</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Step 1 check model</span>
<span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/MCdrugPractical04.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compile the model</span>
<span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># There is no need to provide initial values as </span>
<span class="co"># they are aleady provided in the model specification</span>
<span class="kw">modelGenInits</span>() <span class="co">#</span></code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;theta&quot;</span>)
<span class="kw">samplesSet</span>(parameters)</code></pre></div>
<pre><code>## monitor set for variable &#39;theta&#39;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate 1000 iterations</span>
<span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</code></pre></div>
<pre><code>## 1000 updates took 0 s</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:
chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">theta =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta&quot;</span>))

#### PLOT THE MCMC CHAINS:
<span class="kw">plot</span>(chain<span class="op">$</span>theta, <span class="dt">main=</span><span class="op">~</span>theta, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="fl">0.2</span>, <span class="fl">1.2</span>),
         <span class="dt">ylab=</span><span class="st">&quot;theta&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;iteration&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0400"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0400-1.png" alt="History plot showing 1000 samples of theta" width="80%" />
<p class="caption">
圖 84.5: History plot showing 1000 samples of theta
</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>下面我們來看題幹中的邏輯回歸模型的BUGS版本：</li>
</ol>
<pre><code>model {
       for( i in 1 : N ) { # loop thorugh experiments
            y[i] ~ dbin(theta[i],n[i])
           logit(theta[i]) &lt;- beta0 + beta1 * x[i]    
       }
       # priors
       beta0 ~ dunif(-100, 100)
       beta1 ~ dunif(-100, 100)
}</code></pre>
<p>試驗獲得觀察數據如下：</p>
<pre><code>list(y = c(1, 3, 6, 8, 11, 15, 17, 19), 
     n = c(20, 20, 20, 20, 20, 20, 20, 20), 
     x = c(30, 32, 34, 36, 38, 40, 42, 44), 
     N = 8 )</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>嘗試使用OpenBUGS來跑這個模型。記得你需要把數據加載到軟件裏面去。</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Step 1 check model</span>
<span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the data </span>
<span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compile the model</span>
<span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">1</span>) </code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate initial values </span>
<span class="kw">modelGenInits</span>() </code></pre></div>
<pre><code>## initial values generated, model initialized</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>對未知參數，也就是邏輯回歸的回歸系數 <code>beta0, beta1</code>，和第六次試驗的治療成功百分比 <code>theta[6]</code> 設定監測追蹤其採樣軌跡。試着執行1000次MCMC採樣，把這三個跟蹤的未知參數的採樣歷史軌跡繪制下來。</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;theta[6]&quot;</span>)
<span class="kw">samplesSet</span>(parameters)</code></pre></div>
<pre><code>## monitor set for variable &#39;beta0&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta1&#39;</code></pre>
<pre><code>## monitor set for variable &#39;theta[6]&#39;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate 1000 iterations</span>
<span class="kw">modelUpdate</span>(<span class="dv">1000</span>)</code></pre></div>
<pre><code>## 1000 updates took 0 s</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:
chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),
                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>),
                    <span class="dt">theta6 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta[6]&quot;</span>))

#### PLOT THE MCMC CHAINS:
<span class="kw">plot</span>(chain<span class="op">$</span>beta0[<span class="dv">1</span><span class="op">:</span><span class="dv">1000</span>], <span class="dt">main=</span><span class="st">&quot;beta0&quot;</span>, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">100</span>, <span class="dv">180</span>),
         <span class="dt">ylab=</span><span class="st">&quot;beta0&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;iteration&quot;</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0402"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0402-1.png" alt="History plot showing 1000 samples of beta0" width="80%" />
<p class="caption">
圖 84.6: History plot showing 1000 samples of beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0403"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0403-1.png" alt="History plot showing 1000 samples of beta1" width="80%" />
<p class="caption">
圖 84.7: History plot showing 1000 samples of beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0404"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0404-1.png" alt="History plot showing 1000 samples of theta[6]" width="80%" />
<p class="caption">
圖 84.8: History plot showing 1000 samples of theta[6]
</p>
</div>
<p>對這三個位置變量的採樣歷史繪制痕跡圖之後，你發現每個參數期初的一些採樣是十分不穩定的，有很大的變動(variability)。</p>
<ol start="5" style="list-style-type: decimal">
<li>接下來，我們給上面同一個邏輯回歸模型增加另一條MCMC採樣鏈，重復跑相同的模型1000次，繪制同樣是這三個未知參數的事後分布MCMC採樣歷史痕跡圖。</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Step 1 check model</span>
<span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) 
<span class="co"># Load the data </span>
<span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     
<span class="co"># compile the model with two separate chains</span>
<span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) 
<span class="co"># generate initial values </span>
<span class="kw">modelGenInits</span>() 
<span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;theta[6]&quot;</span>)
<span class="kw">samplesSet</span>(parameters)

<span class="co"># Generate 1000 iterations</span>
<span class="kw">modelUpdate</span>(<span class="dv">1000</span>)
#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:
chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),
                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>),
                    <span class="dt">theta6 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta[6]&quot;</span>))
<span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0405"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0405-1.png" alt="History plot showing 1000 samples of beta0, beta1, and theta[6]" width="80%" />
<p class="caption">
圖 84.9: History plot showing 1000 samples of beta0, beta1, and theta[6]
</p>
</div>
<p>使用兩個不同的起始值作爲MCMC的採樣起點時，每個未知參數分別獲得兩條不同顏色的歷史痕跡圖。和之前只有一條MCMC採樣鏈時一樣，採樣的起始部分(大約100次左右)都有一些不穩定的值。等到100次採樣過後，我們發現每個參數的採樣結果都趨向於比較穩定，也就是方差，變化小了很多。但是藍色鏈，紅色鏈一直到200-300次採樣之後才逐漸互相交叉重疊。下面的圖把起初的500次採樣刨除了之後重新對每個未知參數的MCMC採樣繪制歷史痕跡。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">samplesHistory</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">1</span>), <span class="dt">beg =</span> <span class="dv">501</span>, <span class="dt">ask =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0407"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0407-1.png" alt="History plot showing 1000 samples of beta0, beta1, and theta[6], iteration between 501-1000" width="80%" />
<p class="caption">
圖 84.10: History plot showing 1000 samples of beta0, beta1, and theta[6], iteration between 501-1000
</p>
</div>
<p>500-1000次之間的隨機採樣被放大了觀察之後，我們發現 <code>beta0, beta1</code> 的兩條MCMC鏈條的重疊程度並不理想，不像<code>theta[6]</code>那樣呈現令人滿意地重疊，兩條採樣鏈上下扭動，且在一些地方差異較大。</p>
<p>繪制每個參數的MCMC鏈的自相關圖 (autocorrelation)，下面的圖中只繪制了500-1000次範圍內採樣的自相關圖。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">samplesAutoC</span>(<span class="st">&quot;beta0&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">1</span>, <span class="dt">beg =</span> <span class="dv">501</span>,
             <span class="dt">ask =</span> <span class="ot">FALSE</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">lag.max =</span> <span class="dv">100</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0408081"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical040808-1.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 84.11: Autocorrelation plot for beta0
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">samplesAutoC</span>(<span class="st">&quot;beta0&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>), <span class="dv">2</span>, <span class="dt">beg =</span> <span class="dv">501</span>, 
             <span class="dt">ask =</span> <span class="ot">FALSE</span>, <span class="dt">main =</span> <span class="st">&quot;&quot;</span>, <span class="dt">lag.max =</span> <span class="dv">100</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0408082"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical040808-2.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 84.12: Autocorrelation plot for beta0
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># acf(chain$beta0, main=&quot;beta0&quot;,lwd=4,col=&quot;red&quot;, lag.max = 50)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04091"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0409-1.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 84.13: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04092"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0409-2.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 84.14: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04101"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0410-1.png" alt="Autocorrelation plot for theta[6]" width="80%" />
<p class="caption">
圖 84.15: Autocorrelation plot for theta[6]
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04102"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0410-2.png" alt="Autocorrelation plot for theta[6]" width="80%" />
<p class="caption">
圖 84.16: Autocorrelation plot for theta[6]
</p>
</div>
<p>其中 <code>theta[6]</code> 可以在視覺上認爲這些樣本基本沒有自相關。但是 <code>beta0, beta1</code> 的自相關圖提示相隔50次以上的採樣之間仍然有較強的，不能被忽視的自相關。這一點在 <code>beta0, beta1</code>各自的歷史痕跡圖中也能看出來因爲他們各自的痕跡圖提示採樣時的跳躍並不顯著，相對照的， <code>theta[6]</code>的採樣的跳躍就比較顯著，反映了這個未知參數事後概率分布採樣時的連續互相獨立性較好(near-independence of the values being sampled at consecutive iterations.)。</p>
<ol start="6" style="list-style-type: decimal">
<li>重新在OpenBUGS裏跑這個邏輯回歸模型，這一次，嘗試自己給 <code>beta0, beta1</code> 設置起始值。然後更新模型，採集MCMC鏈樣本10000次。這次嘗試同時使用繪制歷史痕跡圖（視覺檢查），和計算Brooks-Gelman-Rubin診斷參數及其圖示來判斷事後概率分布採樣是否達到收斂。你能判斷這個模型需要拋出掉多少一開始採集的樣本嗎(burn-in)？</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Step 1 check model</span>
<span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-model.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the data </span>
<span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compile the model with two separate chains</span>
<span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate initial values </span>
<span class="co"># the choice is arbitrary</span>
initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="op">-</span><span class="dv">45</span>, <span class="dt">beta1=</span><span class="dv">38</span>)
<span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="dv">60</span>, <span class="dt">beta1=</span><span class="op">-</span><span class="dv">40</span>)
<span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;theta[6]&quot;</span>)
<span class="kw">samplesSet</span>(parameters)</code></pre></div>
<pre><code>## monitor set for variable &#39;beta0&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta1&#39;</code></pre>
<pre><code>## monitor set for variable &#39;theta[6]&#39;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate 10000 iterations</span>
<span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:
chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),
                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>),
                    <span class="dt">theta6 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta[6]&quot;</span>))

#### PLOT the chain history of beta0, beta1
<span class="kw">samplesHistory</span>(<span class="st">&quot;beta0&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04111"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0411-1.png" alt="History plots based on first 10000 iterations." width="80%" />
<p class="caption">
圖 84.17: History plots based on first 10000 iterations.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">samplesHistory</span>(<span class="st">&quot;beta1&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04112"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0411-2.png" alt="History plots based on first 10000 iterations." width="80%" />
<p class="caption">
圖 84.18: History plots based on first 10000 iterations.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Let&#39;s use R2OpenBUGS to run the model again</span>
<span class="co"># Call OpenBUGS to run model</span>
<span class="co">#/home/takeshi/ドキュメント/githubprojects/LSHTMlearningnote/</span>
<span class="co"># output.dir &lt;- &quot;/backupfiles/bugsoutput/&quot;</span>
<span class="co"># drug.odir &lt;- paste(output.dir, &quot;drug-logistic-model/&quot;, sep = &quot;&quot;)</span>
<span class="co">#  pars &lt;- c(&quot;beta0&quot;, &quot;beta1&quot;)</span>
<span class="co"># drug.data &lt;- list(y = c(1, 3, 6, 8, 11, 15, 17, 19), </span>
<span class="co">#      n = c(20, 20, 20, 20, 20, 20, 20, 20), </span>
<span class="co">#      x = c(30, 32, 34, 36, 38, 40, 42, 44), </span>
<span class="co">#      N = 8 )</span>
<span class="co"># </span>
<span class="co"># </span>
<span class="co"># drug.log.sim &lt;- bugs(data = drug.data, parameters.to.save = pars,</span>
<span class="co">#                      model.file = &quot;//backupfiles/logistic-reg-model.txt&quot;, inits = list(initlist, initlist1),</span>
<span class="co">#                      n.chains = 2, n.iter = 10000,</span>
<span class="co">#                      n.burnin = 0, DIC = T, working.directory = drug.odir,</span>
<span class="co">#                      codaPkg = TRUE)</span>
<span class="co"># drug.log.sim</span>
<span class="co"># </span>
<span class="co"># postsamples &lt;- read.bugs(drug.log.sim)</span>
postsamples &lt;-<span class="st"> </span><span class="kw">buildMCMC</span>(<span class="st">&quot;*&quot;</span>)
<span class="kw">gelman.diag</span>(postsamples)</code></pre></div>
<pre><code>## Potential scale reduction factors:
## 
##          Point est. Upper C.I.
## beta0             1          1
## beta1             1          1
## theta[6]          1          1
## 
## Multivariate psrf
## 
## 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gelman.plot</span>(postsamples)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0412"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0412-1.png" alt="Brooks-Gelman-Rubin diagnostic graph" width="80%" />
<p class="caption">
圖 84.19: Brooks-Gelman-Rubin diagnostic graph
</p>
</div>
<p>從Gelman.plot的圖形可以看出，在2000次及以上的採集樣本過後，基本上可以認爲採集的樣本收斂於事後概率分布。</p>
<ol start="7" style="list-style-type: decimal">
<li>確認了你想要刨除的初始樣本量(burn-in)，繼續再進行MCMC採樣直到獲得100,000個事後概率分布樣本。此時你對獲得的事後概率分布樣本量提供的參數估計精確度滿意否？(MC_error is about 1% of the posterior SD?)嘗試報告此時獲得的參數們的事後均值，及其95%可信區間。</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate another 1000000 iterations</span>
<span class="kw">modelUpdate</span>(<span class="dv">42000</span>) </code></pre></div>
<pre><code>## 42000 updates took 1 s</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">2001</span>)
<span class="kw">print</span>(sample.statistics)</code></pre></div>
<pre><code>##              mean      sd MC_error val2.5pc   median val97.5pc start sample
## beta0    -13.8600 2.17800 0.077560 -18.3500 -13.8300   -9.7840  2001 100000
## beta1      0.3746 0.05858 0.002087   0.2650   0.3738    0.4957  2001 100000
## theta[6]   0.7514 0.04910 0.001077   0.6503   0.7532    0.8423  2001 100000</code></pre>
<p>由於 <code>beta0, beta1</code> 事後MCMC採樣的高度自相關性，我們不得不採取獲得十萬以上的事後樣本量的手段來獲取較爲精確的事後參數的均值估計。此時，<code>beta0</code>的<code>MC_error</code> 仍然也只達到事後樣本標準差的3.6% (0.077560/2.17800)。其對應的有效樣本量(effective sample size)大約是 1/(0.036^2) = 772。即使我們再繼續進行MCMC採樣達到一百萬的事後樣本量，我們也只能勉強讓MC_error達到事後標準差的1.4%(=0.02742/2.09200)，對應的有效樣本量是 1/(0.014^2) = 5102。</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate another 900000 iterations</span>
<span class="kw">modelUpdate</span>(<span class="dv">480000</span>) </code></pre></div>
<pre><code>## 480000 updates took 15 s</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">2001</span>)
<span class="kw">print</span>(sample.statistics)</code></pre></div>
<pre><code>##              mean      sd  MC_error val2.5pc   median val97.5pc start  sample
## beta0    -13.8500 2.09200 0.0274200 -18.1800 -13.7900   -9.9170  2001 1060000
## beta1      0.3743 0.05627 0.0007373   0.2685   0.3726    0.4907  2001 1060000
## theta[6]   0.7514 0.04845 0.0003782   0.6517   0.7532    0.8407  2001 1060000</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>繪制此時<code>beta0,beta1</code>的自相關圖。</li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04151"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0415-1.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 84.20: Autocorrelation plot for beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04152"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0415-2.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 84.21: Autocorrelation plot for beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04161"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0416-1.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 84.22: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04162"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0416-2.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 84.23: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0417"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0417-1.png" alt="The joint posterior distribution, scatter plot of beta0 and beta1." width="80%" />
<p class="caption">
圖 84.24: The joint posterior distribution, scatter plot of beta0 and beta1.
</p>
</div>
<p>此圖<a href="MCMC-methods.html#fig:OpenBUGSPractical0417">84.24</a>提示我們該邏輯回歸模型的截距(intercept)<code>beta0</code>，和斜率(slope)<code>beta1</code>其實是高度相關的。這導致了未知參數(兩個回歸系數)的事後概率分布樣本高度內部相關(high autocorrealtion within the samples of each individual parameter)。這是他們效率低下，需要大量的採集樣本仍然無法滿足或者達到理想的收斂的主要原因。</p>
<ol start="9" style="list-style-type: decimal">
<li>給邏輯回歸的回歸系數中心化之後的模型：我們來把兩個回歸系數的樣本中心化(centre the covariate <span class="math inline">\(x\)</span>)。在BUGS語言中可以使用<code>x[i] - mean(x[])</code>的命令來把未知參數的事後概率分布MCMC採樣過程中心化。然後我們重復一下上面的計算過程，看結果有怎樣的變化。與前者的分析比較一下收斂所需要的時間和未知參數事後估計的效率差別。</li>
</ol>
<pre><code># logistic regression model with centred covariate
model{
  for(i in 1:N){# loop through experiments
              y[i] ~ dbin(theta[i], n[i])
   logit(theta[i]) &lt;- beta0 + beta1 * (x[i] - mean(x[]))
  }
  # priors 
  beta0 ~ dunif(-100, 100)
  beta1 ~ dunif(-100, 100)
}</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Step 1 check model</span>
<span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-model-centred.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the data </span>
<span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compile the model with two separate chains</span>
<span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate initial values </span>
<span class="co"># the choice is arbitrary</span>
initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="op">-</span><span class="dv">45</span>, <span class="dt">beta1=</span><span class="dv">38</span>)
<span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="dv">60</span>, <span class="dt">beta1=</span><span class="op">-</span><span class="dv">40</span>)
<span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>, <span class="st">&quot;theta[6]&quot;</span>)
<span class="kw">samplesSet</span>(parameters)</code></pre></div>
<pre><code>## monitor set for variable &#39;beta0&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta1&#39;</code></pre>
<pre><code>## monitor set for variable &#39;theta[6]&#39;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate 10000 iterations</span>
<span class="kw">modelUpdate</span>(<span class="dv">10000</span>)</code></pre></div>
<pre><code>## 10000 updates took 0 s</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:
chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),
                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>),
                    <span class="dt">theta6 =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;theta[6]&quot;</span>))

#### PLOT the chain history of beta0, beta1
<span class="kw">samplesHistory</span>(<span class="st">&quot;beta0&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04181"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0418-1.png" alt="History plots based on first 10000 iterations with centred covariates." width="80%" />
<p class="caption">
圖 84.25: History plots based on first 10000 iterations with centred covariates.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">samplesHistory</span>(<span class="st">&quot;beta1&quot;</span>, <span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="dt">ask =</span> <span class="ot">FALSE</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04182"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0418-2.png" alt="History plots based on first 10000 iterations with centred covariates." width="80%" />
<p class="caption">
圖 84.26: History plots based on first 10000 iterations with centred covariates.
</p>
</div>
<p>用中心化之後的模型我們發現需要更多的起始樣本來達到事後概率分布的收斂(7500左右)。BGR診斷圖 <a href="MCMC-methods.html#fig:OpenBUGSPractical0419">84.27</a> 也提示我們大概在7500次之後的重復採樣才能達到收斂。所以我們決定要刨除起始7500次採集的樣本。(burn-in = 7500)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Let&#39;s use R2OpenBUGS to run the model again</span>
<span class="co"># Call OpenBUGS to run model</span>
<span class="co"># output.dir &lt;- &quot;/backupfiles/bugsoutput/&quot;</span>
<span class="co"># drug.odir &lt;- paste(output.dir, &quot;drug-logistic-model/&quot;, sep = &quot;&quot;)</span>
<span class="co">#  pars &lt;- c(&quot;beta0&quot;, &quot;beta1&quot;)</span>
<span class="co"># drug.log.sim &lt;- bugs(data = &quot;/home/takeshi/ドキュメント/githubprojects/LSHTMlearningnote//backupfiles/logistic-reg-data.txt&quot;, parameters.to.save = pars,</span>
<span class="co">#                      model.file = &quot;/home/takeshi/ドキュメント/githubprojects/LSHTMlearningnote//backupfiles/logistic-reg-model-centred.txt&quot;, inits = list(initlist, initlist1),</span>
<span class="co">#                      n.chains = 2, n.iter = 20000,</span>
<span class="co">#                      n.burnin = 0, DIC = T, working.directory = drug.odir,</span>
<span class="co">#                      codaPkg = TRUE)</span>
<span class="co"># drug.log.sim</span>
<span class="co"># </span>
<span class="co"># postsamples &lt;- read.bugs(drug.log.sim)</span>
<span class="kw">modelUpdate</span>(<span class="dv">20000</span>)</code></pre></div>
<pre><code>## 20000 updates took 0 s</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">postsamples &lt;-<span class="st"> </span><span class="kw">buildMCMC</span>(<span class="st">&quot;*&quot;</span>)

<span class="kw">gelman.diag</span>(postsamples)</code></pre></div>
<pre><code>## Potential scale reduction factors:
## 
##          Point est. Upper C.I.
## beta0             1          1
## beta1             1          1
## theta[6]          1          1
## 
## Multivariate psrf
## 
## 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">gelman.plot</span>(postsamples)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0419"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0419-1.png" alt="Brooks-Gelman-Rubin diagnostic graph" width="80%" />
<p class="caption">
圖 84.27: Brooks-Gelman-Rubin diagnostic graph
</p>
</div>
<p>刨除了起始7500次採集的樣本之後，剩餘的25000個MCMC樣本的自相關也基本都降至0，說明這時候採集的事後概率分布樣本基本上都可以認爲是相互獨立的樣本，散點圖 (Fig. <a href="MCMC-methods.html#fig:OpenBUGSPractical0423">84.32</a>)同樣支持了這一觀點。此時有效樣本量基本上約等於採集到的樣本量。</p>
<pre><code>##               mean      sd  MC_error val2.5pc    median val97.5pc start sample
## beta0    -0.002141 0.20210 0.0011980  -0.3978 -0.002367    0.3942  7501  25000
## beta1     0.374600 0.05598 0.0003554   0.2706  0.372700    0.4887  7501  25000
## theta[6]  0.751100 0.04810 0.0003154   0.6513  0.752600    0.8400  7501  25000</code></pre>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04211"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0421-1.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 84.28: Autocorrelation plot for beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04212"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0421-2.png" alt="Autocorrelation plot for beta0" width="80%" />
<p class="caption">
圖 84.29: Autocorrelation plot for beta0
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04221"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0422-1.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 84.30: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical04222"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0422-2.png" alt="Autocorrelation plot for beta1" width="80%" />
<p class="caption">
圖 84.31: Autocorrelation plot for beta1
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:OpenBUGSPractical0423"></span>
<img src="bookdown_files/figure-html/OpenBUGSPractical0423-1.png" alt="The joint posterior distribution, scatter plot of beta0 and beta1 with centred covariates." width="80%" />
<p class="caption">
圖 84.32: The joint posterior distribution, scatter plot of beta0 and beta1 with centred covariates.
</p>
</div>
<ol start="10" style="list-style-type: decimal">
<li><p>這時候我們獲得的回歸系數的事後估計的均值 <code>beta1 = 0.3746</code>，和它的95%可信區間，<code>0.2706, 0.4887</code>。它其實是藥物劑量每增加1mg，隨之增加的藥物有效百分比的對數比值比 (log-odds-ratio of a positive response per 1 mg increase in dose.)，你有沒有發現其實我們很難解釋這個變量的實際含義呢？有沒有什麼辦法可以來改善這個結果，讓它更加容易讓人明白呢？</p></li>
<li><p>想辦法在未知參數被中心的話邏輯回歸模型中增加新的語句，生成一些新的容易讓人解釋的變量，改善模型的易解釋程度。也許你可以把對數比值比轉換成比值比，你也許可以自己算一下在哪種劑量條件下可以讓95%的患者都有治療療效(ED95)：</p></li>
</ol>
<p><span class="math display">\[
\begin{aligned}
\text{logit}0.95 &amp; = \beta_0 + \beta_1(ED95 - \bar x) \\ 
\Rightarrow ED95 &amp; = (\text{logit}0.95 - \beta_0)/\beta_1 + \bar x
\end{aligned}
\]</span></p>
<pre><code># logistic regression model with centred covariate 
# and added statements
model{
  for(i in 1:N){# loop through experiments
              y[i] ~ dbin(theta[i], n[i])
   logit(theta[i]) &lt;- beta0 + beta1 * (x[i] - mean(x[]))
  }
  # priors 
  beta0 ~ dunif(-100, 100)
  beta1 ~ dunif(-100, 100)
  OR &lt;- exp(beta1) # odds ratio of positive response per 1 mg increase in dose
  ED95 &lt;- (logit(0.95) - beta0)/beta1 + mean(x[]) # dose that gives 95% of maximal response
  logit(P35) &lt;- beta0 + beta1 * (35 - mean(x[]))
}</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Step 1 check model</span>
<span class="kw">modelCheck</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-model-centred-stat.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)) </code></pre></div>
<pre><code>## model is syntactically correct</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the data </span>
<span class="kw">modelData</span>(<span class="kw">paste</span>(bugpath, <span class="st">&quot;/backupfiles/logistic-reg-data.txt&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>))     </code></pre></div>
<pre><code>## data loaded</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># compile the model with two separate chains</span>
<span class="kw">modelCompile</span>(<span class="dt">numChains =</span> <span class="dv">2</span>) </code></pre></div>
<pre><code>## model compiled</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># generate initial values </span>
<span class="co"># the choice is arbitrary</span>
initlist &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="op">-</span><span class="dv">45</span>, <span class="dt">beta1=</span><span class="dv">38</span>)
<span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist))</code></pre></div>
<pre><code>## Initializing chain 1:</code></pre>
<pre><code>## initial values loaded and chain initialized but another chain contain uninitialized variables</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">initlist1 &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">beta0=</span><span class="dv">60</span>, <span class="dt">beta1=</span><span class="op">-</span><span class="dv">40</span>)
<span class="kw">modelInits</span>(<span class="kw">bugsData</span>(initlist1))</code></pre></div>
<pre><code>## Initializing chain 2:</code></pre>
<pre><code>## model is initialized</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set monitors on nodes of interest#### SPECIFY, WHICH PARAMETERS TO TRACE:</span>
parameters &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ED95&quot;</span>, <span class="st">&quot;OR&quot;</span>, <span class="st">&quot;P35&quot;</span>, <span class="st">&quot;beta0&quot;</span>, <span class="st">&quot;beta1&quot;</span>)
<span class="kw">samplesSet</span>(parameters)</code></pre></div>
<pre><code>## monitor set for variable &#39;ED95&#39;</code></pre>
<pre><code>## monitor set for variable &#39;OR&#39;</code></pre>
<pre><code>## monitor set for variable &#39;P35&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta0&#39;</code></pre>
<pre><code>## monitor set for variable &#39;beta1&#39;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Generate 10000 iterations</span>
<span class="kw">modelUpdate</span>(<span class="dv">20000</span>)</code></pre></div>
<pre><code>## 20000 updates took 0 s</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">#### PUT THE SAMPLED VALUES IN ONE R DATA FRAME:
chain &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">ED95   =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;ED95&quot;</span>),
                    <span class="dt">OR     =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;OR&quot;</span>),
                    <span class="dt">P35    =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;P35&quot;</span>),
                    <span class="dt">beta0  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta0&quot;</span>),
                    <span class="dt">beta1  =</span> <span class="kw">samplesSample</span>(<span class="st">&quot;beta1&quot;</span>))
sample.statistics &lt;-<span class="st"> </span><span class="kw">samplesStats</span>(<span class="st">&quot;*&quot;</span>, <span class="dt">beg =</span> <span class="dv">7501</span>)
<span class="kw">print</span>(sample.statistics)</code></pre></div>
<pre><code>##            mean      sd  MC_error val2.5pc    median val97.5pc start sample
## ED95  45.050000 1.36800 0.0091440  42.7800 44.910000   48.1100  7501  25000
## OR     1.457000 0.08205 0.0005216   1.3110  1.452000    1.6300  7501  25000
## P35    0.322600 0.04981 0.0002789   0.2284  0.321300    0.4223  7501  25000
## beta0 -0.002141 0.20210 0.0011980  -0.3978 -0.002367    0.3942  7501  25000
## beta1  0.374600 0.05598 0.0003554   0.2706  0.372700    0.4887  7501  25000</code></pre>
<p>所以，藥物每增加劑量1mg，有療效的比值比是OR = 1.46 (95%CrI: 1.31, 1.63)。能夠達到95%患者都有療效的劑量是 45.05 mg (95% CrI: 42.8, 48.1 mg)。如果給予患者藥物劑量爲 35 mg，患者的疼痛能夠得到緩解(有療效)的概率是 32.3% (95% CrI: 22.8%, 42.2%)。跟着看到這裏的你是不是也覺得貝葉斯的結果和過程能夠更加豐富地回答我們想知道的問題呢？</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">#### PLOT THE DENSITY and HISTOGRAMS OF THE SAMPLED VALUES

<span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>ED95[<span class="dv">7501</span><span class="op">:</span><span class="dv">20000</span>]), <span class="dt">main =</span> <span class="st">&quot;ED95 sample 25000&quot;</span>, 
     <span class="dt">ylab =</span> <span class="st">&quot;P(ED95)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGSPractical04251"></span>
<img src="bookdown_files/figure-html/R-OpenBUGSPractical0425-1.png" alt="Posterior density plots of ED95, OR, and P35." width="80%" />
<p class="caption">
圖 84.33: Posterior density plots of ED95, OR, and P35.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>OR[<span class="dv">7501</span><span class="op">:</span><span class="dv">20000</span>]), <span class="dt">main =</span> <span class="st">&quot;OR sample 25000&quot;</span>, 
     <span class="dt">ylab =</span> <span class="st">&quot;P(OR)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGSPractical04252"></span>
<img src="bookdown_files/figure-html/R-OpenBUGSPractical0425-2.png" alt="Posterior density plots of ED95, OR, and P35." width="80%" />
<p class="caption">
圖 84.34: Posterior density plots of ED95, OR, and P35.
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">density</span>(chain<span class="op">$</span>P35[<span class="dv">7501</span><span class="op">:</span><span class="dv">20000</span>]), <span class="dt">main =</span> <span class="st">&quot;OR sample 25000&quot;</span>, 
     <span class="dt">ylab =</span> <span class="st">&quot;P(OR)&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:R-OpenBUGSPractical04253"></span>
<img src="bookdown_files/figure-html/R-OpenBUGSPractical0425-3.png" alt="Posterior density plots of ED95, OR, and P35." width="80%" />
<p class="caption">
圖 84.35: Posterior density plots of ED95, OR, and P35.
</p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Raftery92howmany">
<p>Raftery, Adrian E., and Steven Lewis. 1992. “How Many Iterations in the Gibbs Sampler?” In <em>In Bayesian Statistics 4</em>, 763–73. Oxford University Press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="共軛先驗概率-conjugate-priors.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="建模和模型的檢查.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/winterwang/LSHTMlearningnote/edit/master/12-Bayesian-stats.Rmd",
"text": "編輯"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
