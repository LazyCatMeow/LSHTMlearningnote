## 預測變量越多越好嗎

### 變量越多總是會提高模型的擬合程度 

過度擬合的實例 overfitting：下面的數據是一組關於類人猿平均腦容量和平均體重的數據。


```{r introBayes10-01, cache=TRUE}
sppnames <- c( "afarensis", "africanus", "habilis", "boisei", 
               "rudolfensis", "ergaster", "sapiens")
brainvolcc <- c(438, 452, 612, 521, 752, 871, 1350)
masskg <- c(37.0, 35.5, 34.5, 41.5, 55.5, 61.0, 53.5)
d <- data.frame( species = sppnames, brain = brainvolcc, mass = masskg)
d
```

不同種類的猿人中，體重和腦容量呈現高度相關性並不稀奇。我們更加關心的是，當考慮了體重大小之後，是否某些種類的猿人的腦容量比我們預期的要大很多？常見的解決方案是用一個把體重作為預測變量，腦容量作為結果變量的簡單線性回歸模型來描述該數據。我們現看看該數據的散點圖：


```{r introBayes10-fig01, cache=TRUE, fig.width=6, fig.height=5,  fig.cap="Average brain volume in cubic centimeters against body mass in kilograms, for six hominin species. What model best describes the relationship between brain size and body size?", fig.align='center'}
# with(d, plot(mass, brain, 
#              xlab = "body mass (kg)", 
#              ylab = "brain volumn (cc)"))
# library(ggrepel)
ggthemr('greyscale')
d %>%
  ggplot(aes(x =  mass, y = brain, 
             label = species),
           ggtheme = theme_bw()) +
  geom_point(color = rangi2) +
  geom_text_repel(size = 5) +
  labs(x = "body mass (kg)",
       y = "brain volume (cc)") +
  xlim(30, 65) + 
  theme(
    axis.text = element_text(face = "bold", 
                               color = "black",
                               size = 13),
    axis.title =element_text(face = "bold", 
                               color = "black",
                               size = 15)
  )

```



