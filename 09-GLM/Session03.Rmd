
二項分佈數據在醫學研究中很常見，例子有千千萬，下面這些只是作爲拋磚引玉：

1. 心臟搭橋手術和血管成形術兩組病人比較療效時，結果變量可以是：死亡 (是/否)；心肌梗死發作 (是/否)；
2. 機械心臟瓣膜手術結果：成功/失敗；
3. 用小鼠作不同劑量二硫化碳暴露下的毒理學實驗，結果變量是：小鼠死亡 (是/否)；
4. 隊列研究中追蹤對象中出現心肌梗死病例，結果變量是：心肌梗死發作 (是/否)。

## 彙總後/個人 (grouped / individual) 的二項分佈數據

下面的數據，來自某個毒理學實驗，不同劑量的二硫化碳暴露下小鼠的死亡數和總數的數據：

```{r  GLM-0301, echo=FALSE, cache=TRUE}
Insect <- read.table("backupfiles/INSECT.RAW", header =  FALSE, sep ="", col.names = c("dose", "n_deaths", "n_subjects"))
print(Insect)
```

很容易理解這是一個典型的彙總後二項分佈數據 (grouped binary data)。每組不同的劑量，第二列，第三列分別是死亡數和實驗總數。另外一種個人二項分佈數據 (individual binary data) 的形式是這樣的：

```{r  GLM-0302, echo=FALSE, cache=TRUE}
dose <- c(rep("49.06", 10), rep("." , 3))
death <- c(rep(1, 6), rep(0,4), rep(".", 3))
data.frame(dose, death)
```
個人二項分佈數據其實就是把每個觀察對象的事件發生與否的信息都呈現出來。通常個人二項分佈數據又被稱爲**伯努利數據**，分組型的二項分佈數據被稱爲**二項數據**。兩種表達形式，但是存儲的是一樣的數據。

## 二項分佈數據的廣義線性迴歸模型

而所有的 GLM 一樣，二項分佈的 GLM 包括三個部分：

1. 因變量的分佈 Distribution：因變量應相互獨立，且服從二項分佈 <br> $$\begin{aligned} Y_i &\sim \text{Bin}(n_i, \pi_i), i = 1, \cdots, n \\ E(Y_i) &= \mu_i = n_i\pi_i\end{aligned}$$
2. 線性預測方程 Linear predictor：第 $i$ 名觀測對象的預測變量的線性迴歸模型 <br> $$\eta_i = \alpha + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}$$
3. 鏈接方程 Link function：鏈接方程連接的是 $\mu_i = n\pi_i$ 和線性預測方程。一個二項分佈因變量數據，可以有許多種鏈接方程：
    - $\mathbf{logit}:$ $$\text{logit}(\pi) = \text{ln}(\frac{\pi}{1-\pi})$$
    - $\mathbf{probit}:$ $$\text{probit}(\pi) = \Phi^{-1}(\pi)$$
    - $\mathbf{complementary\; log-log}:$ $$\text{cloglog}(\pi) = \text{ln}\{ - \text{ln}(1-\pi) \}$$
    - $\mathbf{log:}$ $$\text{log}(\pi) = \text{ln}(\pi)$$

## 注 {#logit-or-log}

1. 概率鏈接方程 $\text{probit}$，$\Phi$ 被定義爲標準正態分佈的累積概率方程 (Section \@ref(standardNormal))： $$\Phi(z) = \text{Pr}(Z \leqslant z), \text{ for } Z\sim N(0,1)$$
2. 二項分佈數據的標準參數 (canonical parameter) $\theta_i$ 的標準鏈接方程是 $\theta_i = \text{logit}(\pi_i)$。
3. $\text{logit, probit, complementary log-log}$ 三種鏈接方程都能達到把閾值僅限於 $0 \sim 1$ 之間的因變量概率映射到線性預測方程的全實數閾值 $(-\infty,+\infty)$ 的目的。但是最後一個 $\text{log}$ 鏈接方程只能映射全部的非零負實數 $(-\infty,0)$。
4. $\text{logit, probit}$ 鏈接方程都是以 $\pi= 0.5$ 爲對稱軸左右對稱的。但是 $\text{cloglog}$ 則沒有對稱的性質。
5. 鏈接方程 $\text{log}$ 具有可以直接被解讀爲對數危險度比 (log Risk Ratio) 的優點，所以也常常在應用中見到。對數鏈接方程還有其他的優點 (非塌陷性 non-collapsibility)，但是它的最大缺點是，有時候利用這個鏈接方程的模型無法收斂 (converge)。
6. $\text{logit}$ 鏈接方程是我們最常見的，也最直觀易於理解。利用這個鏈接方程擬合的模型的迴歸係數能夠直接被理解爲對數比值比 (log Odds Ratio)。
7. 如果是個人數據 (individual data)，那麼 $n_i = 1$，$i$ 是每一個觀測對象的編碼。那麼 $Y_i = 0\text{ or }1$，代表事件發生或沒發生/成功或者失敗。如果是分組數據 (grouped data)，$i$ 是每個組的編號，$n_i$ 指的是第 $i$ 組中觀測對象的人數，$Y_i$ 是第 $i$ 組的 $n$ 名對象中事件發生的次數/成功的次數。


------------------------

### Exercise. Link functions.

推導出鏈接參數分別是

1) $\text{log}$
2) $\text{logit}$
3) $\text{complementary log-log}$

時，用參數 $\alpha, \beta_1, \cdots, \beta_p$ 表達的參數 $\pi_i=?, E(Y_i)=\mu_i=?$

**解**

1) $\text{log}$
$$
\begin{aligned}
\text{ln}(\pi_i) & = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i & = e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}} \\
            \mu_i & = n_i\pi_i = n_i e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}
\end{aligned}
$$


2) $\text{logit}$

$$
\begin{aligned}
\text{logit}(\pi_i) & = \text{ln}(\frac{\pi_i}{1-\pi_i})  \\
                    & = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i   & = \frac{e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}} \\
              \mu_i & = \frac{n_i e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}{1+e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}}
\end{aligned}
$$


3) $\text{complementary log-log}$

$$
\begin{aligned}
\text{cloglog}(\pi_i) & = \text{ln}\{ - \text{ln}(1-\pi) \} \\
                      & = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\Rightarrow \pi_i     & = 1 - e^{-e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}} \\
            \mu_i     & = n_i\pi_i = n_i(1-e^{-e^{\alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}}})
\end{aligned}
$$

----------------------------------

## 邏輯迴歸模型迴歸係數的實際意義

邏輯迴歸 (logistic regression) 的模型可以寫成是

$$
\text{logist}(\pi_i) = \text{ln}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip}
$$

假如觀察對象 $j$ 和 $i$ 兩人中，其餘的預測變量都相同，二者之間有且僅有最後一個預測變量相差一個單位：

$$
\begin{aligned}
\text{logit}(\pi_j) & = \text{ln}(\frac{\pi_j}{1-\pi_j}) = \alpha + \beta_1 x_{j1} + \beta_2 x_{j2} + \cdots + \beta_p x_{jp} \\
\text{logit}(\pi_i) & = \text{ln}(\frac{\pi_i}{1-\pi_i}) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_p x_{ip} \\
\text{Because they are} & \text{ in the same model share the same parameters, and } \\
x_{jp} & = x_{ip} + 1\\
\Rightarrow \text{logit}(\pi_j) - \text{logit}(\pi_i) & = \beta_p (x_{jp} + 1 - x_{jp}) = \beta_p \\
\Rightarrow \beta_p & =  \text{ln}(\frac{\pi_j}{1-\pi_j})  -  \text{ln}(\frac{\pi_i}{1-\pi_i})  \\
                    & = \text{ln}(\frac{\frac{\pi_j}{1-\pi_j}}{\frac{\pi_i}{1-\pi_i}}) \\
                    & = \text{ln}(\text{Odds Ratio})
\end{aligned}
$$

所以迴歸係數 $\beta_p$ 可以被理解爲是 $j$ 與 $i$ 相比較時的對數比值比 log Odds Ratio。我們只要對迴歸係數求反函數，即可求得比值比。

## 邏輯迴歸實際案例 {#BSEinfection}

一組數據如下：

其中，牲畜來自兩大羣 (group)；每羣有五個組的牲畜被飼養五種不同濃度的飼料 (dfactor)；每組牲畜我們記錄了牲畜的總數 (cattle) 以及感染了瘋牛病的牲畜數量 (infect)：

```{r  GLM-0303, echo=FALSE, cache=TRUE}
group <- c(1,1,1,1,1,2,2,2,2,2)
dfactor <- c(1,2,3,4,5,1,2,3,4,5)
cattle <- c(11,10,12,11,12,10,10,12,11,10)
infect <- c(8,7,5,3,2,10,9,8,6,4)

Cattle <- data.frame(group, dfactor, cattle, infect)
print(Cattle)
```

### 分析目的

通過對本數據的分析，回答如下的問題：

1. 考慮了牲畜來自兩羣以後，不同的飼料 (dfactor) 是否和感染瘋牛病有關？
2. 兩羣牲畜之間，飼料和瘋牛病感染之間的關係是否不同？

### 模型 1 飼料 + 羣

$$
\begin{aligned}
\text{Assume } Y_i & \sim \text{Bin} (n_i, \pi_i) \\
\text{logit}(\pi_i) & = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2}
\end{aligned}
$$

```{r  GLM-0304, message=FALSE, cache=TRUE}
Model1 <- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor, family = binomial(link = logit), data = Cattle)
summary(Model1)
epiDisplay::logistic.display(Model1)
```

於是，我們可以寫下這個邏輯迴歸的數學模型：

$$
\begin{aligned}
\text{logit}(\hat\pi_i) & = \text{ln}(\frac{\hat\pi_i}{1-\hat\pi_i})  = \hat\alpha + \hat\beta_1 x_{i1} + \hat\beta_2 x_{i2} \\
                        & = 2.1310 - 0.7874 \times \text{dfactor} + 1.3059 \times \text{group}
\end{aligned}
$$

**解讀這些參數估計的意義**

- 截距 $\hat\alpha = 2.1310$ 的含義是，當 $x_{1}, x_{2}$ 都等於零，i.e. 飼料濃度 0，在第一羣的那些牲畜感染瘋牛病的**對數比值 (log-odds)**；
- 斜率 $\hat\beta_1 = -0.7874$ 的含義是，當牲畜羣不變時，飼料濃度每增加一個單位，牲畜感染瘋牛病的**對數比值的估計變化量 (estimated increase in log odds of infection)**；
- 迴歸係數 $\hat\beta_2 = 1.3059$ 的含義是，當飼料濃度不變時，兩羣牲畜之間感染瘋牛病的**對數比值比 (log-Odds Ratio)**，所以第二羣牲畜比第一羣牲畜感染瘋牛病的比值比的估計量，以及 $95\%\text{CI}$ 的計算方法就是：<br>  $$\begin{aligned} \text{exp}(\hat\beta_2) & = \text{exp}(1.3059) = 3.69,\\ \text{ with 95% CI: } & \text{exp}(\hat\beta_2 \pm 1.96\times \text{Std.Error}_{\hat\beta_2}) \\  & = (1.48, 9.19) \end{aligned}$$

### 模型 2 增加交互作用項 飼料 $\times$ 羣

飼料濃度與瘋牛病感染之間的關係，是否因爲牲畜所在的 “羣” 不同而發生改變？

定義增加了飼料和羣交互作用項的邏輯迴歸模型：

$$
\text{logit}(\pi_i) = \alpha + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i1}\times x_{i2}
$$


```{r  GLM-0305, cache=TRUE}
Model2 <- glm(cbind(infect, cattle - infect) ~ factor(group) + dfactor + factor(group)*dfactor, family = binomial(link = logit), data = Cattle)
summary(Model2)
epiDisplay::logistic.display(Model2)
```

從輸出的報告來看，增加了交互作用項以後，在第一羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 是

$$
\text{exp}(-0.7051) = 0.49
$$

在第二羣牲畜中，飼料濃度每增加一個單位，感染瘋牛病的比值比 (OR) 變成了

$$
\text{exp}(-0.7051 - 0.2058) = 0.40
$$

通過對 $\hat\beta_3 = 0$ 的假設檢驗，就可以推斷飼料濃度和感染瘋牛病之間的關係是否因爲不同牲畜 “羣” 而不同。所以上面的報告中也已經有了交互作用項的檢驗結果 $p = 0.584$，所以，此處可以下的結論是：沒有足夠的證據證明交互作用存在。